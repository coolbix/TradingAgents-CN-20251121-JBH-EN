"""TradingAgendas-CN v1.0.0-preview FastAPI Boxend
Main Application Entry

All rights served.
Copyright (c) 2025 hsliuping. Retention of title.

This software is proprietory and conservative.
Or use of this software, via any media, is perfectly protected.
This software is proprietary and confidential. The unauthorized reproduction, distribution or use of this software through any medium is prohibited.

For commercial purposes, please contact: hsliup@163.com
Business permit counseling, contact: hsliup@163.com
"""

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import logging
import time
from datetime import datetime
from contextlib import asynccontextmanager
import asyncio
from pathlib import Path

from app.core.config import settings
from app.core.database import init_db, close_db
from app.core.logging_config import setup_logging
from app.routers import auth_db as auth, analysis, screening, queue, sse, health, favorites, config, reports, database, operation_logs, tags, tushare_init, akshare_init, baostock_init, historical_data, multi_period_sync, financial_data, news_data, social_media, internal_messages, usage_statistics, model_capabilities, cache, logs
from app.routers import sync as sync_router, multi_source_sync
from app.routers import stocks as stocks_router
from app.routers import stock_data as stock_data_router
from app.routers import stock_sync as stock_sync_router
from app.routers import multi_market_stocks as multi_market_stocks_router
from app.routers import notifications as notifications_router
from app.routers import websocket_notifications as websocket_notifications_router
from app.routers import scheduler as scheduler_router
from app.services.basics_sync_service import get_basics_sync_service
from app.services.multi_source_basics_sync_service import MultiSourceBasicsSyncService
from app.services.scheduler_service import set_scheduler_instance
from app.worker.tushare_sync_service import (
    run_tushare_basic_info_sync,
    run_tushare_quotes_sync,
    run_tushare_historical_sync,
    run_tushare_financial_sync,
    run_tushare_status_check
)
from app.worker.akshare_sync_service import (
    run_akshare_basic_info_sync,
    run_akshare_quotes_sync,
    run_akshare_historical_sync,
    run_akshare_financial_sync,
    run_akshare_status_check
)
from app.worker.baostock_sync_service import (
    run_baostock_basic_info_sync,
    run_baostock_daily_quotes_sync,
    run_baostock_historical_sync,
    run_baostock_status_check
)
#For Hong Kong and United States units read Acquire+Cache mode, no regular synchronization of tasks
# from app.worker.hk_sync_service import ...
# from app.worker.us_sync_service import ...
from app.middleware.operation_log_middleware import OperationLogMiddleware
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
from app.services.quotes_ingestion_service import QuotesIngestionService
from app.routers import paper as paper_router


def get_version() -> str:
    """Read version numbers from Version files"""
    try:
        version_file = Path(__file__).parent.parent / "VERSION"
        if version_file.exists():
            return version_file.read_text(encoding='utf-8').strip()
    except Exception:
        pass
    return "1.0.0"  #Default Version Number


async def _print_config_summary(logger):
    """Show Profile Summary"""
    try:
        logger.info("=" * 70)
        logger.info("üìã TradingAgents-CN Configuration Summary")
        logger.info("=" * 70)

        #.env file path information
        import os
        from pathlib import Path
        
        current_dir = Path.cwd()
        logger.info(f"üìÅ Current working directory: {current_dir}")
        
        #Check for possible .env file locations
        env_files_to_check = [
            current_dir / ".env",
            current_dir / "app" / ".env",
            Path(__file__).parent.parent / ".env",  #Project Root Directory
        ]
        
        logger.info("üîç Checking .env file locations:")
        env_file_found = False
        for env_file in env_files_to_check:
            if env_file.exists():
                logger.info(f"  ‚úÖ Found: {env_file} (size: {env_file.stat().st_size} bytes)")
                env_file_found = True
                #Show the front lines of the file (hidden sensitive information)
                try:
                    with open(env_file, 'r', encoding='utf-8') as f:
                        lines = f.readlines()[:5]  #First 5 lines only
                        logger.info(f"     Preview (first 5 lines):")
                        for i, line in enumerate(lines, 1):
                            #Hide rows containing sensitive information such as passwords, keys, etc.
                            if any(keyword in line.upper() for keyword in ['PASSWORD', 'SECRET', 'KEY', 'TOKEN']):
                                logger.info(f"       {i}: {line.split('=')[0]}=***")
                            else:
                                logger.info(f"       {i}: {line.strip()}")
                except Exception as e:
                    logger.warning(f"     Could not preview file: {e}")
            else:
                logger.info(f"  ‚ùå Not found: {env_file}")
        
        if not env_file_found:
            logger.warning("‚ö†Ô∏è  No .env file found in checked locations")
        
        #Pydantic Settings Configuration Loading State
        logger.info("‚öôÔ∏è  Pydantic Settings Configuration:")
        logger.info(f"  ‚Ä¢ Settings class: {settings.__class__.__name__}")
        logger.info(f"  ‚Ä¢ Config source: {getattr(settings.model_config, 'env_file', 'Not specified')}")
        logger.info(f"  ‚Ä¢ Encoding: {getattr(settings.model_config, 'env_file_encoding', 'Not specified')}")
        
        #Shows the source of some key configuration values (environmental variable vs default)
        key_settings = ['HOST', 'PORT', 'DEBUG', 'MONGODB_HOST', 'REDIS_HOST']
        logger.info("  ‚Ä¢ Key settings sources:")
        for setting_name in key_settings:
            env_var_name = setting_name
            env_value = os.getenv(env_var_name)
            config_value = getattr(settings, setting_name, None)
            if env_value is not None:
                logger.info(f"    - {setting_name}: from environment variable ({config_value})")
            else:
                logger.info(f"    - {setting_name}: using default value ({config_value})")
        
        #Environmental information
        env = "Production" if settings.is_production else "Development"
        logger.info(f"Environment: {env}")

        #Database Connections
        logger.info(f"MongoDB: {settings.MONGODB_HOST}:{settings.MONGODB_PORT}/{settings.MONGODB_DATABASE}")
        logger.info(f"Redis: {settings.REDIS_HOST}:{settings.REDIS_PORT}/{settings.REDIS_DB}")

        #Proxy Configuration
        import os
        if settings.HTTP_PROXY or settings.HTTPS_PROXY:
            logger.info("Proxy Configuration:")
            if settings.HTTP_PROXY:
                logger.info(f"  HTTP_PROXY: {settings.HTTP_PROXY}")
            if settings.HTTPS_PROXY:
                logger.info(f"  HTTPS_PROXY: {settings.HTTPS_PROXY}")
            if settings.NO_PROXY:
                #Show only the top 3 domain names
                no_proxy_list = settings.NO_PROXY.split(',')
                if len(no_proxy_list) <= 3:
                    logger.info(f"  NO_PROXY: {settings.NO_PROXY}")
                else:
                    logger.info(f"  NO_PROXY: {','.join(no_proxy_list[:3])}... ({len(no_proxy_list)} domains)")
            logger.info(f"  ‚úÖ Proxy environment variables set successfully")
        else:
            logger.info("Proxy: Not configured (direct connection)")

        #Check large model configuration
        try:
            from app.services.config_service import config_service
            config = await config_service.get_system_config()
            if config and config.llm_configs:
                enabled_llms = [llm for llm in config.llm_configs if llm.enabled]
                logger.info(f"Enabled LLMs: {len(enabled_llms)}")
                if enabled_llms:
                    for llm in enabled_llms[:3]:  #Show only first three
                        logger.info(f"  ‚Ä¢ {llm.provider}: {llm.model_name}")
                    if len(enabled_llms) > 3:
                        logger.info(f"  ‚Ä¢ ... and {len(enabled_llms) - 3} more")
                else:
                    logger.warning("‚ö†Ô∏è  No LLM enabled. Please configure at least one LLM in Web UI.")
            else:
                logger.warning("‚ö†Ô∏è  No LLM configured. Please configure at least one LLM in Web UI.")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Failed to check LLM configs: {e}")

        #Check data source configuration
        try:
            if config and config.data_source_configs:
                enabled_sources = [ds for ds in config.data_source_configs if ds.enabled]
                logger.info(f"Enabled Data Sources: {len(enabled_sources)}")
                if enabled_sources:
                    for ds in enabled_sources[:3]:  #Show only first three
                        logger.info(f"  ‚Ä¢ {ds.type.value}: {ds.name}")
                    if len(enabled_sources) > 3:
                        logger.info(f"  ‚Ä¢ ... and {len(enabled_sources) - 3} more")
            else:
                logger.info("Data Sources: Using default (AKShare)")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Failed to check data source configs: {e}")

        logger.info("=" * 70)
    except Exception as e:
        logger.error(f"Failed to print config summary: {e}")


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application of life-cycle management"""
    #Initialize on startup
    setup_logging()
    logger = logging.getLogger("app.main")

    #Verify Start Configuration
    try:
        from app.core.startup_validator import validate_startup_config
        validate_startup_config()
    except Exception as e:
        logger.error(f"Configure authentication failed:{e}")
        raise

    await init_db()

    #Configure Bridges: Write Unified Configurations to Environmental Variables for TradingAgents Core Library
    try:
        from app.core.config_bridge import bridge_config_to_env
        bridge_config_to_env()
    except Exception as e:
        logger.warning(f"The bridge failed:{e}")
        logger.warning("‚ö†Ô∏è TradingAgents will use configurations in .env files")

    # Apply dynamic settings (log_level, enable_monitoring) from ConfigProvider
    try:
        from app.services.config_provider import provider as config_provider  # local import to avoid early DB init issues
        eff = await config_provider.get_effective_system_settings()
        desired_level = str(eff.get("log_level", "INFO")).upper()
        setup_logging(log_level=desired_level)
        for name in ("webapi", "worker", "uvicorn", "fastapi"):
            logging.getLogger(name).setLevel(desired_level)
        try:
            from app.middleware.operation_log_middleware import set_operation_log_enabled
            set_operation_log_enabled(bool(eff.get("enable_monitoring", True)))
        except Exception:
            pass
    except Exception as e:
        logging.getLogger("webapi").warning(f"Failed to apply dynamic settings: {e}")

    #Show Profile Summary
    await _print_config_summary(logger)

    logger.info("TradingAgents FastAPI backend started")

    #Start-up period: If necessary, a closing snapshot of the previous trading date should be added at the break
    if settings.QUOTES_BACKFILL_ON_STARTUP:
        try:
            qi = QuotesIngestionService()
            await qi.ensure_indexes()
            await qi.backfill_last_close_snapshot_if_needed()
        except Exception as e:
            logger.warning(f"Startup backfill failed (ignored): {e}")

    #Starts a daily timed task: Configureable
    scheduler: AsyncIOScheduler | None = None
    try:
        from croniter import croniter
    except Exception:
        croniter = None  #Optional Dependencies
    try:
        scheduler = AsyncIOScheduler(timezone=settings.TIMEZONE)

        #Use multiple data source sync service (support automatic switching)
        multi_source_service = MultiSourceBasicsSyncService()

        #Determine priority data sources by TUSHARE ENABLED configuration
        #If Tushare is disabled, the system will automatically use other available data sources (AKshare/ BaoStock)
        preferred_sources = None  #None means to use default priority order

        if settings.TUSHARE_ENABLED:
            #Use Tushare first when Tushare is enabled
            preferred_sources = ["tushare", "akshare", "baostock"]
            logger.info(f"üìäSmart priority data source: Tushare > AKshare > BaoStock")
        else:
            #Use AKshare and BaoStock when Tushare is disabled
            preferred_sources = ["akshare", "baostock"]
            logger.info(f"üìä Stock Basic Information Sync Priority Data Source: AKShare > BaoStock (Tushare disabled)")

        #Try once immediately after startup.
        async def run_sync_with_sources():
            await multi_source_service.run_full_sync(force=False, preferred_sources=preferred_sources)

        asyncio.create_task(run_sync_with_sources())

        #Configure Schedule: Prioritize Cron, followed by HH:MM
        if settings.SYNC_STOCK_BASICS_ENABLED:
            if settings.SYNC_STOCK_BASICS_CRON:
                #If a cron expression is provided
                scheduler.add_job(
                    lambda: multi_source_service.run_full_sync(force=False, preferred_sources=preferred_sources),
                    CronTrigger.from_crontab(settings.SYNC_STOCK_BASICS_CRON, timezone=settings.TIMEZONE),
                    id="basics_sync_service",
                    name="ËÇ°Á•®Âü∫Á°Ä‰ø°ÊÅØÂêåÊ≠•ÔºàÂ§öÊï∞ÊçÆÊ∫êÔºâ"
                )
                logger.info(f"üìÖ Stock basics sync scheduled by CRON: {settings.SYNC_STOCK_BASICS_CRON} ({settings.TIMEZONE})")
            else:
                hh, mm = (settings.SYNC_STOCK_BASICS_TIME or "06:30").split(":")
                scheduler.add_job(
                    lambda: multi_source_service.run_full_sync(force=False, preferred_sources=preferred_sources),
                    CronTrigger(hour=int(hh), minute=int(mm), timezone=settings.TIMEZONE),
                    id="basics_sync_service",
                    name="ËÇ°Á•®Âü∫Á°Ä‰ø°ÊÅØÂêåÊ≠•ÔºàÂ§öÊï∞ÊçÆÊ∫êÔºâ"
                )
                logger.info(f"üìÖ Stock basics sync scheduled daily at {settings.SYNC_STOCK_BASICS_TIME} ({settings.TIMEZONE})")

        #Real-time database tasks (per N-s), internal self-determination period
        if settings.QUOTES_INGEST_ENABLED:
            quotes_ingestion = QuotesIngestionService()
            await quotes_ingestion.ensure_indexes()
            scheduler.add_job(
                quotes_ingestion.run_once,  # coroutine function; AsyncIOScheduler will await it
                IntervalTrigger(seconds=settings.QUOTES_INGEST_INTERVAL_SECONDS, timezone=settings.TIMEZONE),
                id="quotes_ingestion_service",
                name="ÂÆûÊó∂Ë°åÊÉÖÂÖ•Â∫ìÊúçÂä°"
            )
            logger.info(f"Real-time database mission started:{settings.QUOTES_INGEST_INTERVAL_SECONDS}s")

        #Tushare Unified Data Sync Task Configuration
        logger.info("Configure the Tushare Unified Data Sync Task...")

        #Synchronise Action
        scheduler.add_job(
            run_tushare_basic_info_sync,
            CronTrigger.from_crontab(settings.TUSHARE_BASIC_INFO_SYNC_CRON, timezone=settings.TIMEZONE),
            id="tushare_basic_info_sync",
            name="ËÇ°Á•®Âü∫Á°Ä‰ø°ÊÅØÂêåÊ≠•ÔºàTushareÔºâ",
            kwargs={"force_update": False}
        )
        if not (settings.TUSHARE_UNIFIED_ENABLED and settings.TUSHARE_BASIC_INFO_SYNC_ENABLED):
            scheduler.pause_job("tushare_basic_info_sync")
            logger.info(f"‚è∏Ô∏èTushare Basic Information Synchronization has been added but suspended:{settings.TUSHARE_BASIC_INFO_SYNC_CRON}")
        else:
            logger.info(f"Tushare Basic Information Synchronized:{settings.TUSHARE_BASIC_INFO_SYNC_CRON}")

        #Other Organiser
        scheduler.add_job(
            run_tushare_quotes_sync,
            CronTrigger.from_crontab(settings.TUSHARE_QUOTES_SYNC_CRON, timezone=settings.TIMEZONE),
            id="tushare_quotes_sync",
            name="ÂÆûÊó∂Ë°åÊÉÖÂêåÊ≠•ÔºàTushareÔºâ"
        )
        if not (settings.TUSHARE_UNIFIED_ENABLED and settings.TUSHARE_QUOTES_SYNC_ENABLED):
            scheduler.pause_job("tushare_quotes_sync")
            logger.info(f"Tushare line sync has been added but suspended:{settings.TUSHARE_QUOTES_SYNC_CRON}")
        else:
            logger.info(f"Tushare line syncs configured:{settings.TUSHARE_QUOTES_SYNC_CRON}")

        #Synchronise Action
        scheduler.add_job(
            run_tushare_historical_sync,
            CronTrigger.from_crontab(settings.TUSHARE_HISTORICAL_SYNC_CRON, timezone=settings.TIMEZONE),
            id="tushare_historical_sync",
            name="ÂéÜÂè≤Êï∞ÊçÆÂêåÊ≠•ÔºàTushareÔºâ",
            kwargs={"incremental": True}
        )
        if not (settings.TUSHARE_UNIFIED_ENABLED and settings.TUSHARE_HISTORICAL_SYNC_ENABLED):
            scheduler.pause_job("tushare_historical_sync")
            logger.info(f"Tushare's historical data sync has been added but is suspended:{settings.TUSHARE_HISTORICAL_SYNC_CRON}")
        else:
            logger.info(f"üìäTusharehistorical data synchronization configured:{settings.TUSHARE_HISTORICAL_SYNC_CRON}")

        #Financial Data Sync Task
        scheduler.add_job(
            run_tushare_financial_sync,
            CronTrigger.from_crontab(settings.TUSHARE_FINANCIAL_SYNC_CRON, timezone=settings.TIMEZONE),
            id="tushare_financial_sync",
            name="Ë¥¢Âä°Êï∞ÊçÆÂêåÊ≠•ÔºàTushareÔºâ"
        )
        if not (settings.TUSHARE_UNIFIED_ENABLED and settings.TUSHARE_FINANCIAL_SYNC_ENABLED):
            scheduler.pause_job("tushare_financial_sync")
            logger.info(f"‚è∏Ô∏èTushare Financial Data Synchronization has been added but suspended:{settings.TUSHARE_FINANCIAL_SYNC_CRON}")
        else:
            logger.info(f"Tushare financial data synchronised:{settings.TUSHARE_FINANCIAL_SYNC_CRON}")

        #Status check task
        scheduler.add_job(
            run_tushare_status_check,
            CronTrigger.from_crontab(settings.TUSHARE_STATUS_CHECK_CRON, timezone=settings.TIMEZONE),
            id="tushare_status_check",
            name="Êï∞ÊçÆÊ∫êÁä∂ÊÄÅÊ£ÄÊü•ÔºàTushareÔºâ"
        )
        if not (settings.TUSHARE_UNIFIED_ENABLED and settings.TUSHARE_STATUS_CHECK_ENABLED):
            scheduler.pause_job("tushare_status_check")
            logger.info(f"Tushare status check added but suspended:{settings.TUSHARE_STATUS_CHECK_CRON}")
        else:
            logger.info(f"Tushare status check configured:{settings.TUSHARE_STATUS_CHECK_CRON}")

        #AKShare Unified Data Sync Task Configuration
        logger.info("Configure AKShare Unified Data Synchronization...")

        #Synchronise Action
        scheduler.add_job(
            run_akshare_basic_info_sync,
            CronTrigger.from_crontab(settings.AKSHARE_BASIC_INFO_SYNC_CRON, timezone=settings.TIMEZONE),
            id="akshare_basic_info_sync",
            name="ËÇ°Á•®Âü∫Á°Ä‰ø°ÊÅØÂêåÊ≠•ÔºàAKShareÔºâ",
            kwargs={"force_update": False}
        )
        if not (settings.AKSHARE_UNIFIED_ENABLED and settings.AKSHARE_BASIC_INFO_SYNC_ENABLED):
            scheduler.pause_job("akshare_basic_info_sync")
            logger.info(f"‚è∏Ô∏èAKShare Basic Information Synchronization has been added but suspended:{settings.AKSHARE_BASIC_INFO_SYNC_CRON}")
        else:
            logger.info(f"AKShare's basic information is synchronised:{settings.AKSHARE_BASIC_INFO_SYNC_CRON}")

        #Other Organiser
        scheduler.add_job(
            run_akshare_quotes_sync,
            CronTrigger.from_crontab(settings.AKSHARE_QUOTES_SYNC_CRON, timezone=settings.TIMEZONE),
            id="akshare_quotes_sync",
            name="ÂÆûÊó∂Ë°åÊÉÖÂêåÊ≠•ÔºàAKShareÔºâ"
        )
        if not (settings.AKSHARE_UNIFIED_ENABLED and settings.AKSHARE_QUOTES_SYNC_ENABLED):
            scheduler.pause_job("akshare_quotes_sync")
            logger.info(f"The AKShare line sync has been added but suspended:{settings.AKSHARE_QUOTES_SYNC_CRON}")
        else:
            logger.info(f"The AKShare line is configured:{settings.AKSHARE_QUOTES_SYNC_CRON}")

        #Synchronise Action
        scheduler.add_job(
            run_akshare_historical_sync,
            CronTrigger.from_crontab(settings.AKSHARE_HISTORICAL_SYNC_CRON, timezone=settings.TIMEZONE),
            id="akshare_historical_sync",
            name="ÂéÜÂè≤Êï∞ÊçÆÂêåÊ≠•ÔºàAKShareÔºâ",
            kwargs={"incremental": True}
        )
        if not (settings.AKSHARE_UNIFIED_ENABLED and settings.AKSHARE_HISTORICAL_SYNC_ENABLED):
            scheduler.pause_job("akshare_historical_sync")
            logger.info(f"‚è∏Ô∏èHistoryShareSync has been added but suspended:{settings.AKSHARE_HISTORICAL_SYNC_CRON}")
        else:
            logger.info(f"AKShare's historical data synchronisation is configured:{settings.AKSHARE_HISTORICAL_SYNC_CRON}")

        #Financial Data Sync Task
        scheduler.add_job(
            run_akshare_financial_sync,
            CronTrigger.from_crontab(settings.AKSHARE_FINANCIAL_SYNC_CRON, timezone=settings.TIMEZONE),
            id="akshare_financial_sync",
            name="Ë¥¢Âä°Êï∞ÊçÆÂêåÊ≠•ÔºàAKShareÔºâ"
        )
        if not (settings.AKSHARE_UNIFIED_ENABLED and settings.AKSHARE_FINANCIAL_SYNC_ENABLED):
            scheduler.pause_job("akshare_financial_sync")
            logger.info(f"Synchronization of AKshare financial data has been added but suspended:{settings.AKSHARE_FINANCIAL_SYNC_CRON}")
        else:
            logger.info(f"üí∞AKShare ' s financial data synchronized:{settings.AKSHARE_FINANCIAL_SYNC_CRON}")

        #Status check task
        scheduler.add_job(
            run_akshare_status_check,
            CronTrigger.from_crontab(settings.AKSHARE_STATUS_CHECK_CRON, timezone=settings.TIMEZONE),
            id="akshare_status_check",
            name="Êï∞ÊçÆÊ∫êÁä∂ÊÄÅÊ£ÄÊü•ÔºàAKShareÔºâ"
        )
        if not (settings.AKSHARE_UNIFIED_ENABLED and settings.AKSHARE_STATUS_CHECK_ENABLED):
            scheduler.pause_job("akshare_status_check")
            logger.info(f"AKShare status check added but suspended:{settings.AKSHARE_STATUS_CHECK_CRON}")
        else:
            logger.info(f"AKShare status check configured:{settings.AKSHARE_STATUS_CHECK_CRON}")

        #BaoStock Unified Data Sync Task Configuration
        logger.info("Configure the BaoStock Unified Data Sync Task...")

        #Synchronise Action
        scheduler.add_job(
            run_baostock_basic_info_sync,
            CronTrigger.from_crontab(settings.BAOSTOCK_BASIC_INFO_SYNC_CRON, timezone=settings.TIMEZONE),
            id="baostock_basic_info_sync",
            name="ËÇ°Á•®Âü∫Á°Ä‰ø°ÊÅØÂêåÊ≠•ÔºàBaoStockÔºâ"
        )
        if not (settings.BAOSTOCK_UNIFIED_ENABLED and settings.BAOSTOCK_BASIC_INFO_SYNC_ENABLED):
            scheduler.pause_job("baostock_basic_info_sync")
            logger.info(f"‚è∏Ô∏è BaoStock Basic Information Synchronization has been added but suspended:{settings.BAOSTOCK_BASIC_INFO_SYNC_CRON}")
        else:
            logger.info(f"BaoStock Basic Information Synchronized:{settings.BAOSTOCK_BASIC_INFO_SYNC_CRON}")

        #DayKline Sync Task (note: BaoStock does not support real-time lines)
        scheduler.add_job(
            run_baostock_daily_quotes_sync,
            CronTrigger.from_crontab(settings.BAOSTOCK_DAILY_QUOTES_SYNC_CRON, timezone=settings.TIMEZONE),
            id="baostock_daily_quotes_sync",
            name="Êó•KÁ∫øÊï∞ÊçÆÂêåÊ≠•ÔºàBaoStockÔºâ"
        )
        if not (settings.BAOSTOCK_UNIFIED_ENABLED and settings.BAOSTOCK_DAILY_QUOTES_SYNC_ENABLED):
            scheduler.pause_job("baostock_daily_quotes_sync")
            logger.info(f"BaoStockK-line sync has been added but is suspended:{settings.BAOSTOCK_DAILY_QUOTES_SYNC_CRON}")
        else:
            logger.info(f"BaoStockKline is configured:{settings.BAOSTOCK_DAILY_QUOTES_SYNC_CRON}(Note: BaoStock does not support real time.)")

        #Synchronise Action
        scheduler.add_job(
            run_baostock_historical_sync,
            CronTrigger.from_crontab(settings.BAOSTOCK_HISTORICAL_SYNC_CRON, timezone=settings.TIMEZONE),
            id="baostock_historical_sync",
            name="ÂéÜÂè≤Êï∞ÊçÆÂêåÊ≠•ÔºàBaoStockÔºâ"
        )
        if not (settings.BAOSTOCK_UNIFIED_ENABLED and settings.BAOSTOCK_HISTORICAL_SYNC_ENABLED):
            scheduler.pause_job("baostock_historical_sync")
            logger.info(f"BaoStock historical data sync has been added but is suspended:{settings.BAOSTOCK_HISTORICAL_SYNC_CRON}")
        else:
            logger.info(f"BaoStock has been configured:{settings.BAOSTOCK_HISTORICAL_SYNC_CRON}")

        #Status check task
        scheduler.add_job(
            run_baostock_status_check,
            CronTrigger.from_crontab(settings.BAOSTOCK_STATUS_CHECK_CRON, timezone=settings.TIMEZONE),
            id="baostock_status_check",
            name="Êï∞ÊçÆÊ∫êÁä∂ÊÄÅÊ£ÄÊü•ÔºàBaoStockÔºâ"
        )
        if not (settings.BAOSTOCK_UNIFIED_ENABLED and settings.BAOSTOCK_STATUS_CHECK_ENABLED):
            scheduler.pause_job("baostock_status_check")
            logger.info(f"BaoStock status check added but suspended:{settings.BAOSTOCK_STATUS_CHECK_CRON}")
        else:
            logger.info(f"BaoStock status check configured:{settings.BAOSTOCK_STATUS_CHECK_CRON}")

        #Synchronization of news data tasking (using AKShare to synchronize all stock news)
        logger.info("Configure news synchronisation...")

        from app.worker.akshare_sync_service import get_akshare_sync_service

        async def run_news_sync():
            """Run NewsSync Tasks - Sync Self-Selected Unit News with AKShare"""
            try:
                logger.info("Starting news synchronisation.")
                service = await get_akshare_sync_service()
                result = await service.sync_news_data(
                    symbols=None,  #None + options only=True
                    max_news_per_stock=settings.NEWS_SYNC_MAX_PER_SOURCE,
                    favorites_only=True  #Synchronization of selected units only
                )
                logger.info(
                    f"News synchronised:"
                    f"Processing{result['total_processed']}It's only for self-selection."
                    f"Success{result['success_count']}Only,"
                    f"Failed{result['error_count']}Only,"
                    f"Total public information{result['news_count']}Article,"
                    f"Time-consuming{(datetime.utcnow() - result['start_time']).total_seconds():.2f}sec"
                )
            except Exception as e:
                logger.error(f"The news has failed:{e}", exc_info=True)

        #== sync, corrected by elderman == @elder man
        #The Hong Kong and United States units no longer deploy scheduled synchronization tasks using a needs-based + cache model
        logger.info("üá≠üá∞ Port Unit data are available on demand + cache mode")
        logger.info("üá∫üá∏United States share data are available on demand + cache mode")

        scheduler.add_job(
            run_news_sync,
            CronTrigger.from_crontab(settings.NEWS_SYNC_CRON, timezone=settings.TIMEZONE),
            id="news_sync",
            name="Êñ∞ÈóªÊï∞ÊçÆÂêåÊ≠•ÔºàAKShare - ‰ªÖËá™ÈÄâËÇ°Ôºâ"
        )
        if not settings.NEWS_SYNC_ENABLED:
            scheduler.pause_job("news_sync")
            logger.info(f"Synchronization of news data has been added but suspended:{settings.NEWS_SYNC_CRON}")
        else:
            logger.info(f"üì∞Syncs of news data configured (selected units only):{settings.NEWS_SYNC_CRON}")

        scheduler.start()

        #Set the scheduler instance to service so that API can manage tasks
        set_scheduler_instance(scheduler)
        logger.info("‚úÖ Scheduler service has been initiated")
    except Exception as e:
        logger.error(f"The scheduler failed:{e}", exc_info=True)
        raise  #Throw out the anomaly and stop the application.

    try:
        yield
    finally:
        #Clear on close
        if scheduler:
            try:
                scheduler.shutdown(wait=False)
                logger.info("üõë Scheduler stopped")
            except Exception as e:
                logger.warning(f"Scheduler shutdown error: {e}")

        #Close Uservice MongoDB connection
        try:
            from app.services.user_service import user_service
            user_service.close()
        except Exception as e:
            logger.warning(f"UserService cleanup error: {e}")

        await close_db()
        logger.info("TradingAgents FastAPI backend stopped")


#Create FastAPI Application
app = FastAPI(
    title="TradingAgents-CN API",
    description="ËÇ°Á•®ÂàÜÊûê‰∏éÊâπÈáèÈòüÂàóÁ≥ªÁªü API",
    version=get_version(),
    docs_url="/docs" if settings.DEBUG else None,
    redoc_url="/redoc" if settings.DEBUG else None,
    lifespan=lifespan
)

#Security middle
if not settings.DEBUG:
    app.add_middleware(
        TrustedHostMiddleware,
        allowed_hosts=settings.ALLOWED_HOSTS
    )

#CORS Middle
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)


#Operation log middle
app.add_middleware(OperationLogMiddleware)


#Requested Log Intermediate
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = time.time()

    #Skip health check and static file request logs
    if request.url.path in ["/health", "/favicon.ico"] or request.url.path.startswith("/static"):
        response = await call_next(request)
        return response

    #Record requests using webpi logger
    logger = logging.getLogger("webapi")
    logger.info(f"üîÑ {request.method} {request.url.path}- Start processing.")

    response = await call_next(request)
    process_time = time.time() - start_time

    #Recording request completed
    status_emoji = "‚úÖ" if response.status_code < 400 else "‚ùå"
    logger.info(f"{status_emoji} {request.method} {request.url.path}- Status:{response.status_code}- Time-consuming:{process_time:.3f}s")

    return response


#Global anomalies
#Request ID/Trace-ID intermediate (to be used as the outermost layer, after the function intermediate)
from app.middleware.request_id import RequestIDMiddleware
app.add_middleware(RequestIDMiddleware)

@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logging.error(f"Unhandled exception: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "error": {
                "code": "INTERNAL_SERVER_ERROR",
                "message": "Internal server error occurred",
                "request_id": getattr(request.state, "request_id", None)
            }
        }
    )


#Test End - Verify if the middle is working
@app.get("/api/test-log")
async def test_log():
    """Test if the log middle is working"""
    print("üß™ ÊµãËØïÁ´ØÁÇπË¢´Ë∞ÉÁî® - ËøôÊù°Ê∂àÊÅØÂ∫îËØ•Âá∫Áé∞Âú®ÊéßÂà∂Âè∞")
    return {"message": "ÊµãËØïÊàêÂäü", "timestamp": time.time()}

#Registration route
app.include_router(health.router, prefix="/api", tags=["health"])
app.include_router(auth.router, prefix="/api/auth", tags=["authentication"])
app.include_router(analysis.router, prefix="/api/analysis", tags=["analysis"])
app.include_router(reports.router, tags=["reports"])
app.include_router(screening.router, prefix="/api/screening", tags=["screening"])
app.include_router(queue.router, prefix="/api/queue", tags=["queue"])
app.include_router(favorites.router, prefix="/api", tags=["favorites"])
app.include_router(stocks_router.router, prefix="/api", tags=["stocks"])
app.include_router(multi_market_stocks_router.router, prefix="/api", tags=["multi-market"])
app.include_router(stock_data_router.router, tags=["stock-data"])
app.include_router(stock_sync_router.router, tags=["stock-sync"])
app.include_router(tags.router, prefix="/api", tags=["tags"])
app.include_router(config.router, prefix="/api", tags=["config"])
app.include_router(model_capabilities.router, tags=["model-capabilities"])
app.include_router(usage_statistics.router, tags=["usage-statistics"])
app.include_router(database.router, prefix="/api/system", tags=["database"])
app.include_router(cache.router, tags=["cache"])
app.include_router(operation_logs.router, prefix="/api/system", tags=["operation_logs"])
app.include_router(logs.router, prefix="/api/system", tags=["logs"])
#New: System Configure Read-only Summary
from app.routers import system_config as system_config_router
app.include_router(system_config_router.router, prefix="/api/system", tags=["system"])

#Notification module (REST + SSE)
app.include_router(notifications_router.router, prefix="/api", tags=["notifications"])

#WebSocket Notification Module (substitute SSE + Redis PubSub)
app.include_router(websocket_notifications_router.router, prefix="/api", tags=["websocket"])

#Timed Task Management
app.include_router(scheduler_router.router, tags=["scheduler"])

app.include_router(sse.router, prefix="/api/stream", tags=["streaming"])
app.include_router(sync_router.router)
app.include_router(multi_source_sync.router)
app.include_router(paper_router.router, prefix="/api", tags=["paper"])
app.include_router(tushare_init.router, prefix="/api", tags=["tushare-init"])
app.include_router(akshare_init.router, prefix="/api", tags=["akshare-init"])
app.include_router(baostock_init.router, prefix="/api", tags=["baostock-init"])
app.include_router(historical_data.router, tags=["historical-data"])
app.include_router(multi_period_sync.router, tags=["multi-period-sync"])
app.include_router(financial_data.router, tags=["financial-data"])
app.include_router(news_data.router, tags=["news-data"])
app.include_router(social_media.router, tags=["social-media"])
app.include_router(internal_messages.router, tags=["internal-messages"])


@app.get("/")
async def root():
    """Root path, return API information"""
    print("üè† Ê†πË∑ØÂæÑË¢´ËÆøÈóÆ")
    return {
        "name": "TradingAgents-CN API",
        "version": get_version(),
        "status": "running",
        "docs_url": "/docs" if settings.DEBUG else None
    }


if __name__ == "__main__":
    uvicorn.run(
        "app.main:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=settings.DEBUG,
        log_level="info",
        reload_dirs=["app"] if settings.DEBUG else None,
        reload_excludes=[
            "__pycache__",
            "*.pyc",
            "*.pyo",
            "*.pyd",
            ".git",
            ".pytest_cache",
            "*.log",
            "*.tmp"
        ] if settings.DEBUG else None,
        reload_includes=["*.py"] if settings.DEBUG else None
    )