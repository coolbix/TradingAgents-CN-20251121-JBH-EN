"""Model capability hierarchy

The definition of the capabilities level of the model, the applicable role, the feature label, etc.
For intelligent matching depth analysis and model selection.

Convergence channels support:
- Support for the 302.AI, OpenRouter, One API, etc.
- Model name format for polymer channels:   FT 0 / FT 1  (e.g. openai/gpt-4)
- The system will automatically map the capability configuration of the original plant model.
"""

from enum import IntEnum, Enum
from typing import Dict, List, Any, Tuple


class ModelCapabilityLevel(IntEnum):
    """Model capabilities level (1-5)"""
    BASIC = 1          #Base: appropriate for level 1-2 analysis, light speed
    STANDARD = 2       #Standard: appropriate for level 1-3 analysis, daily use
    ADVANCED = 3       #Advanced: suitable for level 1-4 analysis, complex reasoning
    PROFESSIONAL = 4   #Professional: appropriate for Level 1-5 analysis, Professional level analysis
    FLAGSHIP = 5       #Flagships: fit for all levels, most powerful


class ModelRole(str, Enum):
    """Model Role Type"""
    QUICK_ANALYSIS = "quick_analysis"  #Rapid analysis (data collection, tool call)
    DEEP_ANALYSIS = "deep_analysis"    #In-depth analysis (adjection, decision-making)
    BOTH = "both"                      #Both fit.


class ModelFeature(str, Enum):
    """Model characterization label"""
    TOOL_CALLING = "tool_calling"      #Support tool call (required)
    LONG_CONTEXT = "long_context"      #Support context
    REASONING = "reasoning"            #Strong reasoning.
    VISION = "vision"                  #Support visual input
    FAST_RESPONSE = "fast_response"    #Quick Response
    COST_EFFECTIVE = "cost_effective"  #Cost-effective


#Capability Level Description
CAPABILITY_DESCRIPTIONS = {
    1: "åŸºç¡€æ¨¡åž‹ - é€‚åˆå¿«é€Ÿåˆ†æžå’Œç®€å•ä»»åŠ¡ï¼Œå“åº”å¿«é€Ÿï¼Œæˆæœ¬ä½Ž",
    2: "æ ‡å‡†æ¨¡åž‹ - é€‚åˆæ—¥å¸¸åˆ†æžå’Œå¸¸è§„ä»»åŠ¡ï¼Œå¹³è¡¡æ€§èƒ½å’Œæˆæœ¬",
    3: "é«˜çº§æ¨¡åž‹ - é€‚åˆæ·±åº¦åˆ†æžå’Œå¤æ‚æŽ¨ç†ï¼Œè´¨é‡è¾ƒé«˜",
    4: "ä¸“ä¸šæ¨¡åž‹ - é€‚åˆä¸“ä¸šçº§åˆ†æžå’Œå¤šè½®è¾©è®ºï¼Œé«˜è´¨é‡è¾“å‡º",
    5: "æ——èˆ°æ¨¡åž‹ - æœ€å¼ºèƒ½åŠ›ï¼Œé€‚åˆå…¨é¢åˆ†æžå’Œå…³é”®å†³ç­–"
}


#Minimum level of capability required to analyse depth
ANALYSIS_DEPTH_REQUIREMENTS = {
    "å¿«é€Ÿ": {
        "min_capability": 1,
        "quick_model_min": 1,
        "deep_model_min": 1,
        "required_features": [ModelFeature.TOOL_CALLING],
        "description": "1çº§å¿«é€Ÿåˆ†æžï¼šä»»ä½•æ¨¡åž‹éƒ½å¯ä»¥ï¼Œä¼˜å…ˆé€‰æ‹©å¿«é€Ÿå“åº”çš„æ¨¡åž‹"
    },
    "åŸºç¡€": {
        "min_capability": 1,
        "quick_model_min": 1,
        "deep_model_min": 2,
        "required_features": [ModelFeature.TOOL_CALLING],
        "description": "2çº§åŸºç¡€åˆ†æžï¼šå¿«é€Ÿæ¨¡åž‹å¯ç”¨åŸºç¡€çº§ï¼Œæ·±åº¦æ¨¡åž‹å»ºè®®æ ‡å‡†çº§ä»¥ä¸Š"
    },
    "æ ‡å‡†": {
        "min_capability": 2,
        "quick_model_min": 1,
        "deep_model_min": 2,
        "required_features": [ModelFeature.TOOL_CALLING],
        "description": "3çº§æ ‡å‡†åˆ†æžï¼šå¿«é€Ÿæ¨¡åž‹å¯ç”¨åŸºç¡€çº§ï¼Œæ·±åº¦æ¨¡åž‹éœ€è¦æ ‡å‡†çº§ä»¥ä¸Š"
    },
    "æ·±åº¦": {
        "min_capability": 3,
        "quick_model_min": 2,
        "deep_model_min": 3,
        "required_features": [ModelFeature.TOOL_CALLING, ModelFeature.REASONING],
        "description": "4çº§æ·±åº¦åˆ†æžï¼šå¿«é€Ÿæ¨¡åž‹éœ€æ ‡å‡†çº§ï¼Œæ·±åº¦æ¨¡åž‹éœ€é«˜çº§ä»¥ä¸Šï¼Œéœ€è¦æŽ¨ç†èƒ½åŠ›"
    },
    "å…¨é¢": {
        "min_capability": 4,
        "quick_model_min": 2,
        "deep_model_min": 4,
        "required_features": [ModelFeature.TOOL_CALLING, ModelFeature.REASONING],
        "description": "5çº§å…¨é¢åˆ†æžï¼šå¿«é€Ÿæ¨¡åž‹éœ€æ ‡å‡†çº§ï¼Œæ·±åº¦æ¨¡åž‹éœ€ä¸“ä¸šçº§ä»¥ä¸Šï¼Œå¼ºæŽ¨ç†èƒ½åŠ›"
    }
}


#Default capability configuration of common models (for initialization and reference)
DEFAULT_MODEL_CAPABILITIES: Dict[str, Dict[str, Any]] = {
    #== sync, corrected by elderman == @elder man
    "qwen-turbo": {
        "capability_level": 1,
        "suitable_roles": [ModelRole.QUICK_ANALYSIS],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.FAST_RESPONSE, ModelFeature.COST_EFFECTIVE],
        "recommended_depths": ["å¿«é€Ÿ", "åŸºç¡€"],
        "performance_metrics": {"speed": 5, "cost": 5, "quality": 3},
        "description": "é€šä¹‰åƒé—®è½»é‡ç‰ˆï¼Œå¿«é€Ÿå“åº”ï¼Œé€‚åˆæ•°æ®æ”¶é›†"
    },
    "qwen-plus": {
        "capability_level": 2,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.LONG_CONTEXT],
        "recommended_depths": ["å¿«é€Ÿ", "åŸºç¡€", "æ ‡å‡†"],
        "performance_metrics": {"speed": 4, "cost": 4, "quality": 4},
        "description": "é€šä¹‰åƒé—®æ ‡å‡†ç‰ˆï¼Œå¹³è¡¡æ€§èƒ½å’Œæˆæœ¬"
    },
    "qwen-max": {
        "capability_level": 4,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.LONG_CONTEXT, ModelFeature.REASONING],
        "recommended_depths": ["æ ‡å‡†", "æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 3, "cost": 2, "quality": 5},
        "description": "é€šä¹‰åƒé—®æ——èˆ°ç‰ˆï¼Œå¼ºå¤§æŽ¨ç†èƒ½åŠ›"
    },
    "qwen3-max": {
        "capability_level": 5,
        "suitable_roles": [ModelRole.DEEP_ANALYSIS],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.LONG_CONTEXT, ModelFeature.REASONING],
        "recommended_depths": ["æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 2, "cost": 1, "quality": 5},
        "description": "é€šä¹‰åƒé—®é•¿æ–‡æœ¬ç‰ˆï¼Œè¶…é•¿ä¸Šä¸‹æ–‡"
    },
    
    # ==================== OpenAI ====================
    "gpt-3.5-turbo": {
        "capability_level": 1,
        "suitable_roles": [ModelRole.QUICK_ANALYSIS],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.FAST_RESPONSE, ModelFeature.COST_EFFECTIVE],
        "recommended_depths": ["å¿«é€Ÿ", "åŸºç¡€"],
        "performance_metrics": {"speed": 5, "cost": 5, "quality": 3},
        "description": "GPT-3.5 Turboï¼Œå¿«é€Ÿä¸”ç»æµŽ"
    },
    "gpt-4": {
        "capability_level": 3,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.REASONING],
        "recommended_depths": ["åŸºç¡€", "æ ‡å‡†", "æ·±åº¦"],
        "performance_metrics": {"speed": 3, "cost": 3, "quality": 4},
        "description": "GPT-4ï¼Œå¼ºå¤§çš„æŽ¨ç†èƒ½åŠ›"
    },
    "gpt-4-turbo": {
        "capability_level": 4,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.LONG_CONTEXT, ModelFeature.REASONING, ModelFeature.VISION],
        "recommended_depths": ["æ ‡å‡†", "æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 4, "cost": 2, "quality": 5},
        "description": "GPT-4 Turboï¼Œæ›´å¿«æ›´å¼º"
    },
    "gpt-4o-mini": {
        "capability_level": 2,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.FAST_RESPONSE, ModelFeature.COST_EFFECTIVE],
        "recommended_depths": ["å¿«é€Ÿ", "åŸºç¡€", "æ ‡å‡†"],
        "performance_metrics": {"speed": 5, "cost": 5, "quality": 3},
        "description": "GPT-4o Miniï¼Œç»æµŽå®žæƒ "
    },
    "o1-mini": {
        "capability_level": 4,
        "suitable_roles": [ModelRole.DEEP_ANALYSIS],
        "features": [ModelFeature.REASONING],
        "recommended_depths": ["æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 2, "cost": 3, "quality": 5},
        "description": "O1 Miniï¼Œå¼ºæŽ¨ç†æ¨¡åž‹"
    },
    "o1": {
        "capability_level": 5,
        "suitable_roles": [ModelRole.DEEP_ANALYSIS],
        "features": [ModelFeature.REASONING],
        "recommended_depths": ["å…¨é¢"],
        "performance_metrics": {"speed": 1, "cost": 1, "quality": 5},
        "description": "O1ï¼Œæœ€å¼ºæŽ¨ç†èƒ½åŠ›"
    },
    "o4-mini": {
        "capability_level": 4,
        "suitable_roles": [ModelRole.DEEP_ANALYSIS],
        "features": [ModelFeature.REASONING],
        "recommended_depths": ["æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 2, "cost": 3, "quality": 5},
        "description": "O4 Miniï¼Œæ–°ä¸€ä»£æŽ¨ç†æ¨¡åž‹"
    },
    
    # ==================== DeepSeek ====================
    "deepseek-chat": {
        "capability_level": 3,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.LONG_CONTEXT, ModelFeature.COST_EFFECTIVE],
        "recommended_depths": ["åŸºç¡€", "æ ‡å‡†", "æ·±åº¦"],
        "performance_metrics": {"speed": 4, "cost": 5, "quality": 4},
        "description": "DeepSeek Chatï¼Œæ€§ä»·æ¯”é«˜"
    },
    
    #== sync, corrected by elderman == @elder man
    "ernie-3.5": {
        "capability_level": 2,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING],
        "recommended_depths": ["å¿«é€Ÿ", "åŸºç¡€", "æ ‡å‡†"],
        "performance_metrics": {"speed": 4, "cost": 4, "quality": 3},
        "description": "æ–‡å¿ƒä¸€è¨€3.5ï¼Œæ ‡å‡†ç‰ˆæœ¬"
    },
    "ernie-4.0": {
        "capability_level": 3,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.REASONING],
        "recommended_depths": ["åŸºç¡€", "æ ‡å‡†", "æ·±åº¦"],
        "performance_metrics": {"speed": 3, "cost": 3, "quality": 4},
        "description": "æ–‡å¿ƒä¸€è¨€4.0ï¼Œé«˜çº§ç‰ˆæœ¬"
    },
    "ernie-4.0-turbo": {
        "capability_level": 4,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.REASONING, ModelFeature.FAST_RESPONSE],
        "recommended_depths": ["æ ‡å‡†", "æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 4, "cost": 2, "quality": 5},
        "description": "æ–‡å¿ƒä¸€è¨€4.0 Turboï¼Œæ——èˆ°ç‰ˆæœ¬"
    },
    
    #== sync, corrected by elderman == @elder man
    "glm-3-turbo": {
        "capability_level": 1,
        "suitable_roles": [ModelRole.QUICK_ANALYSIS],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.FAST_RESPONSE, ModelFeature.COST_EFFECTIVE],
        "recommended_depths": ["å¿«é€Ÿ", "åŸºç¡€"],
        "performance_metrics": {"speed": 5, "cost": 5, "quality": 3},
        "description": "æ™ºè°±GLM-3 Turboï¼Œå¿«é€Ÿç‰ˆæœ¬"
    },
    "glm-4": {
        "capability_level": 3,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.REASONING],
        "recommended_depths": ["åŸºç¡€", "æ ‡å‡†", "æ·±åº¦"],
        "performance_metrics": {"speed": 3, "cost": 3, "quality": 4},
        "description": "æ™ºè°±GLM-4ï¼Œæ ‡å‡†ç‰ˆæœ¬"
    },
    "glm-4-plus": {
        "capability_level": 4,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.LONG_CONTEXT, ModelFeature.REASONING],
        "recommended_depths": ["æ ‡å‡†", "æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 3, "cost": 2, "quality": 5},
        "description": "æ™ºè°±GLM-4 Plusï¼Œæ——èˆ°ç‰ˆæœ¬"
    },
    
    # ==================== Anthropic Claude ====================
    "claude-3-haiku": {
        "capability_level": 2,
        "suitable_roles": [ModelRole.QUICK_ANALYSIS],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.FAST_RESPONSE],
        "recommended_depths": ["å¿«é€Ÿ", "åŸºç¡€", "æ ‡å‡†"],
        "performance_metrics": {"speed": 5, "cost": 4, "quality": 3},
        "description": "Claude 3 Haikuï¼Œå¿«é€Ÿç‰ˆæœ¬"
    },
    "claude-3-sonnet": {
        "capability_level": 3,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.LONG_CONTEXT, ModelFeature.VISION],
        "recommended_depths": ["åŸºç¡€", "æ ‡å‡†", "æ·±åº¦"],
        "performance_metrics": {"speed": 4, "cost": 3, "quality": 4},
        "description": "Claude 3 Sonnetï¼Œå¹³è¡¡ç‰ˆæœ¬"
    },
    "claude-3-opus": {
        "capability_level": 4,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.LONG_CONTEXT, ModelFeature.REASONING, ModelFeature.VISION],
        "recommended_depths": ["æ ‡å‡†", "æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 3, "cost": 2, "quality": 5},
        "description": "Claude 3 Opusï¼Œæ——èˆ°ç‰ˆæœ¬"
    },
    "claude-3.5-sonnet": {
        "capability_level": 5,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.LONG_CONTEXT, ModelFeature.REASONING, ModelFeature.VISION],
        "recommended_depths": ["æ ‡å‡†", "æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 4, "cost": 2, "quality": 5},
        "description": "Claude 3.5 Sonnetï¼Œæœ€æ–°æ——èˆ°"
    },

    # ==================== Google Gemini ====================
    "gemini-pro": {
        "capability_level": 3,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.REASONING],
        "recommended_depths": ["åŸºç¡€", "æ ‡å‡†", "æ·±åº¦"],
        "performance_metrics": {"speed": 4, "cost": 4, "quality": 4},
        "description": "Gemini Proï¼Œç»å…¸ç¨³å®šç‰ˆæœ¬"
    },
    "gemini-1.5-pro": {
        "capability_level": 4,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.LONG_CONTEXT, ModelFeature.REASONING, ModelFeature.VISION],
        "recommended_depths": ["æ ‡å‡†", "æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 4, "cost": 3, "quality": 5},
        "description": "Gemini 1.5 Proï¼Œé•¿ä¸Šä¸‹æ–‡æ——èˆ°"
    },
    "gemini-1.5-flash": {
        "capability_level": 2,
        "suitable_roles": [ModelRole.QUICK_ANALYSIS],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.FAST_RESPONSE, ModelFeature.COST_EFFECTIVE],
        "recommended_depths": ["å¿«é€Ÿ", "åŸºç¡€", "æ ‡å‡†"],
        "performance_metrics": {"speed": 5, "cost": 5, "quality": 3},
        "description": "Gemini 1.5 Flashï¼Œå¿«é€Ÿå“åº”ç‰ˆæœ¬"
    },
    "gemini-2.0-flash": {
        "capability_level": 4,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.LONG_CONTEXT, ModelFeature.REASONING, ModelFeature.FAST_RESPONSE],
        "recommended_depths": ["æ ‡å‡†", "æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 5, "cost": 3, "quality": 5},
        "description": "Gemini 2.0 Flashï¼Œæ–°ä¸€ä»£å¿«é€Ÿæ——èˆ°"
    },
    "gemini-2.5-flash-lite-preview-06-17": {
        "capability_level": 2,
        "suitable_roles": [ModelRole.QUICK_ANALYSIS],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.FAST_RESPONSE, ModelFeature.COST_EFFECTIVE],
        "recommended_depths": ["å¿«é€Ÿ", "åŸºç¡€"],
        "performance_metrics": {"speed": 5, "cost": 5, "quality": 3},
        "description": "Gemini 2.5 Flash Liteï¼Œè½»é‡é¢„è§ˆç‰ˆ"
    },

    #== sync, corrected by elderman == @elder man
    "moonshot-v1-8k": {
        "capability_level": 2,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING],
        "recommended_depths": ["å¿«é€Ÿ", "åŸºç¡€", "æ ‡å‡†"],
        "performance_metrics": {"speed": 4, "cost": 4, "quality": 3},
        "description": "Moonshot V1 8Kï¼Œæ ‡å‡†ç‰ˆæœ¬"
    },
    "moonshot-v1-32k": {
        "capability_level": 3,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.LONG_CONTEXT],
        "recommended_depths": ["åŸºç¡€", "æ ‡å‡†", "æ·±åº¦"],
        "performance_metrics": {"speed": 3, "cost": 3, "quality": 4},
        "description": "Moonshot V1 32Kï¼Œé•¿ä¸Šä¸‹æ–‡ç‰ˆæœ¬"
    },
    "moonshot-v1-128k": {
        "capability_level": 4,
        "suitable_roles": [ModelRole.DEEP_ANALYSIS],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.LONG_CONTEXT, ModelFeature.REASONING],
        "recommended_depths": ["æ ‡å‡†", "æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 2, "cost": 2, "quality": 5},
        "description": "Moonshot V1 128Kï¼Œè¶…é•¿ä¸Šä¸‹æ–‡æ——èˆ°"
    },
}


def get_model_capability_badge(level: int) -> Dict[str, str]:
    """Capability Level Emblem Style"""
    badges = {
        1: {"text": "åŸºç¡€", "color": "#909399", "icon": "âš¡"},
        2: {"text": "æ ‡å‡†", "color": "#409EFF", "icon": "ðŸ“Š"},
        3: {"text": "é«˜çº§", "color": "#67C23A", "icon": "ðŸŽ¯"},
        4: {"text": "ä¸“ä¸š", "color": "#E6A23C", "icon": "ðŸ”¥"},
        5: {"text": "æ——èˆ°", "color": "#F56C6C", "icon": "ðŸ‘‘"}
    }
    return badges.get(level, badges[2])


def get_role_badge(role: ModelRole) -> Dict[str, str]:
    """Get Role Emblem Styles"""
    badges = {
        ModelRole.QUICK_ANALYSIS: {"text": "å¿«é€Ÿåˆ†æž", "color": "success", "icon": "âš¡"},
        ModelRole.DEEP_ANALYSIS: {"text": "æ·±åº¦æŽ¨ç†", "color": "warning", "icon": "ðŸ§ "},
        ModelRole.BOTH: {"text": "é€šç”¨", "color": "primary", "icon": "ðŸŽ¯"}
    }
    return badges.get(role, badges[ModelRole.BOTH])


def get_feature_badge(feature: ModelFeature) -> Dict[str, str]:
    """Fetch feature badge style"""
    badges = {
        ModelFeature.TOOL_CALLING: {"text": "å·¥å…·è°ƒç”¨", "color": "info", "icon": "ðŸ”§"},
        ModelFeature.LONG_CONTEXT: {"text": "é•¿ä¸Šä¸‹æ–‡", "color": "success", "icon": "ðŸ“š"},
        ModelFeature.REASONING: {"text": "å¼ºæŽ¨ç†", "color": "warning", "icon": "ðŸ§ "},
        ModelFeature.VISION: {"text": "è§†è§‰", "color": "primary", "icon": "ðŸ‘ï¸"},
        ModelFeature.FAST_RESPONSE: {"text": "å¿«é€Ÿ", "color": "success", "icon": "âš¡"},
        ModelFeature.COST_EFFECTIVE: {"text": "ç»æµŽ", "color": "success", "icon": "ðŸ’°"}
    }
    return badges.get(feature, {"text": str(feature), "color": "info", "icon": "âœ¨"})


#== sync, corrected by elderman == @elder man

#Default configuration of the polymer channel
AGGREGATOR_PROVIDERS = {
    "302ai": {
        "display_name": "302.AI",
        "description": "302.AI èšåˆå¹³å°ï¼Œæä¾›å¤šåŽ‚å•†æ¨¡åž‹ç»Ÿä¸€æŽ¥å£",
        "website": "https://302.ai",
        "api_doc_url": "https://doc.302.ai",
        "default_base_url": "https://api.302.ai/v1",
        "model_name_format": "{provider}/{model}",  #Example: openai/gpt-4
        "supported_providers": ["openai", "anthropic", "google", "deepseek", "qwen"]
    },
    "openrouter": {
        "display_name": "OpenRouter",
        "description": "OpenRouter èšåˆå¹³å°ï¼Œæ”¯æŒå¤šç§ AI æ¨¡åž‹",
        "website": "https://openrouter.ai",
        "api_doc_url": "https://openrouter.ai/docs",
        "default_base_url": "https://openrouter.ai/api/v1",
        "model_name_format": "{provider}/{model}",
        "supported_providers": ["openai", "anthropic", "google", "meta", "mistral"]
    },
    "oneapi": {
        "display_name": "One API",
        "description": "One API å¼€æºèšåˆå¹³å°",
        "website": "https://github.com/songquanpeng/one-api",
        "api_doc_url": "https://github.com/songquanpeng/one-api",
        "default_base_url": "http://localhost:3000/v1",  #Users are required to deploy themselves
        "model_name_format": "{model}",  #One API usually doesn't need a prefix.
        "supported_providers": ["openai", "anthropic", "google", "azure", "claude"]
    },
    "newapi": {
        "display_name": "New API",
        "description": "New API èšåˆå¹³å°",
        "website": "https://github.com/Calcium-Ion/new-api",
        "api_doc_url": "https://github.com/Calcium-Ion/new-api",
        "default_base_url": "http://localhost:3000/v1",
        "model_name_format": "{model}",
        "supported_providers": ["openai", "anthropic", "google", "azure", "claude"]
    }
}


def is_aggregator_model(model_name: str) -> bool:
    """Determines if it's a polymer channel model name

Args:
Model name: Model name

Returns:
Whether it's a polymer channel model
"""
    return "/" in model_name


def parse_aggregator_model(model_name: str) -> Tuple[str, str]:
    """Parsing polymer channel model names

Args:
Model name: Model name (e. g. openai/gpt-4)

Returns:
(provider, model)
"""
    if "/" in model_name:
        parts = model_name.split("/", 1)
        return parts[0], parts[1]
    return "", model_name

