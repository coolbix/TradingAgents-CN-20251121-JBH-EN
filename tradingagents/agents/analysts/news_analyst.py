from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
import time
import json
from datetime import datetime

#Import a Unified Log System and Analysis Module Log Decorator
from tradingagents.utils.logging_init import get_logger
from tradingagents.utils.tool_logging import log_analyst_module
#Import Unified News Tool
from tradingagents.tools.unified_news_tool import create_unified_news_tool
#Import Stock Tool Class
from tradingagents.utils.stock_utils import StockUtils
#Import Google Tool Call Processing Device
from tradingagents.agents.utils.google_tool_handler import GoogleToolCallHandler

logger = get_logger("analysts.news")


def create_news_analyst(llm, toolkit):
    @log_analyst_module("news")
    def news_analyst_node(state):
        start_time = datetime.now()

        #ğŸ”§ Tool Call counter - to prevent infinite circulation
        tool_call_count = state.get("news_tool_call_count", 0)
        max_tool_calls = 3  #Maximum tool call times
        logger.info(f"The number of calls for the current tool:{tool_call_count}/{max_tool_calls}")

        current_date = state["trade_date"]
        ticker = state["company_of_interest"]

        logger.info(f"[news analyst] Start analysis.{ticker}News, date of transaction:{current_date}")
        session_id = state.get("session_id", "æœªçŸ¥ä¼šè¯")
        logger.info(f"[Press Analyst ] Session ID:{session_id}, start time:{start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        #Access to market information
        market_info = StockUtils.get_market_info(ticker)
        logger.info(f"[news analyst] Stock type:{market_info['market_name']}")
        
        #Get company names
        def _get_company_name(ticker: str, market_info: dict) -> str:
            """Get company names by stock code"""
            try:
                if market_info['is_china']:
                    #China Unit A: Access to stock information using a unified interface
                    from tradingagents.dataflows.interface import get_china_stock_info_unified
                    stock_info = get_china_stock_info_unified(ticker)
                    
                    #Parsing stock name
                    if "è‚¡ç¥¨åç§°:" in stock_info:
                        company_name = stock_info.split("è‚¡ç¥¨åç§°:")[1].split("\n")[0].strip()
                        logger.debug(f"ğŸ“Š [DBUG] Gets the Chinese stock name from the unified interface:{ticker} -> {company_name}")
                        return company_name
                    else:
                        logger.warning(f"âš ï¸ [DEBUG] cannot decipher stock names from the unified interface:{ticker}")
                        return f"è‚¡ç¥¨ä»£ç {ticker}"
                        
                elif market_info['is_hk']:
                    #Port Unit: use of improved Port Unit tools
                    try:
                        from tradingagents.dataflows.providers.hk.improved_hk import get_hk_company_name_improved
                        company_name = get_hk_company_name_improved(ticker)
                        logger.debug(f"ğŸ“Š [DBUG] Use of the Port Improvement Unit tool to obtain names:{ticker} -> {company_name}")
                        return company_name
                    except Exception as e:
                        logger.debug(f"ğŸ“Š [DBUG] Improvements to the Port Unit Tool to get names failed:{e}")
                        #Downscaling scheme: Generate friendly default names
                        clean_ticker = ticker.replace('.HK', '').replace('.hk', '')
                        return f"æ¸¯è‚¡{clean_ticker}"
                        
                elif market_info['is_us']:
                    #US share: use simple mapping or return code
                    us_stock_names = {
                        'AAPL': 'è‹¹æœå…¬å¸',
                        'TSLA': 'ç‰¹æ–¯æ‹‰',
                        'NVDA': 'è‹±ä¼Ÿè¾¾',
                        'MSFT': 'å¾®è½¯',
                        'GOOGL': 'è°·æ­Œ',
                        'AMZN': 'äºšé©¬é€Š',
                        'META': 'Meta',
                        'NFLX': 'å¥ˆé£'
                    }
                    
                    company_name = us_stock_names.get(ticker.upper(), f"ç¾è‚¡{ticker}")
                    logger.debug(f"[DEBUG] U.S. stock name map:{ticker} -> {company_name}")
                    return company_name
                    
                else:
                    return f"è‚¡ç¥¨{ticker}"
                    
            except Exception as e:
                logger.error(f"[DEBUG]{e}")
                return f"è‚¡ç¥¨{ticker}"
        
        company_name = _get_company_name(ticker, market_info)
        logger.info(f"[news analyst] Company name:{company_name}")
        
        #ğŸ”§Use a unified public information tool to simplify its use
        logger.info(f"[news analyst] Use a unified news tool to automatically identify stock types and access corresponding news")
   #Create a unified public information tool
        unified_news_tool = create_unified_news_tool(toolkit)
        unified_news_tool.name = "get_stock_news_unified"
        
        tools = [unified_news_tool]
        logger.info(f"[news analyst] A unified news tool has been loaded: get stock news unified")

        system_message = (
            """æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„è´¢ç»æ–°é—»åˆ†æå¸ˆï¼Œè´Ÿè´£åˆ†ææœ€æ–°çš„å¸‚åœºæ–°é—»å’Œäº‹ä»¶å¯¹è‚¡ç¥¨ä»·æ ¼çš„æ½œåœ¨å½±å“ã€‚

æ‚¨çš„ä¸»è¦èŒè´£åŒ…æ‹¬ï¼š
1. è·å–å’Œåˆ†ææœ€æ–°çš„å®æ—¶æ–°é—»ï¼ˆä¼˜å…ˆ15-30åˆ†é’Ÿå†…çš„æ–°é—»ï¼‰
2. è¯„ä¼°æ–°é—»äº‹ä»¶çš„ç´§æ€¥ç¨‹åº¦å’Œå¸‚åœºå½±å“
3. è¯†åˆ«å¯èƒ½å½±å“è‚¡ä»·çš„å…³é”®ä¿¡æ¯
4. åˆ†ææ–°é—»çš„æ—¶æ•ˆæ€§å’Œå¯é æ€§
5. æä¾›åŸºäºæ–°é—»çš„äº¤æ˜“å»ºè®®å’Œä»·æ ¼å½±å“è¯„ä¼°

é‡ç‚¹å…³æ³¨çš„æ–°é—»ç±»å‹ï¼š
- è´¢æŠ¥å‘å¸ƒå’Œä¸šç»©æŒ‡å¯¼
- é‡å¤§åˆä½œå’Œå¹¶è´­æ¶ˆæ¯
- æ”¿ç­–å˜åŒ–å’Œç›‘ç®¡åŠ¨æ€
- çªå‘äº‹ä»¶å’Œå±æœºç®¡ç†
- è¡Œä¸šè¶‹åŠ¿å’ŒæŠ€æœ¯çªç ´
- ç®¡ç†å±‚å˜åŠ¨å’Œæˆ˜ç•¥è°ƒæ•´

åˆ†æè¦ç‚¹ï¼š
- æ–°é—»çš„æ—¶æ•ˆæ€§ï¼ˆå‘å¸ƒæ—¶é—´è·ç¦»ç°åœ¨å¤šä¹…ï¼‰
- æ–°é—»çš„å¯ä¿¡åº¦ï¼ˆæ¥æºæƒå¨æ€§ï¼‰
- å¸‚åœºå½±å“ç¨‹åº¦ï¼ˆå¯¹è‚¡ä»·çš„æ½œåœ¨å½±å“ï¼‰
- æŠ•èµ„è€…æƒ…ç»ªå˜åŒ–ï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰
- ä¸å†å²ç±»ä¼¼äº‹ä»¶çš„å¯¹æ¯”

ğŸ“Š æ–°é—»å½±å“åˆ†æè¦æ±‚ï¼š
- è¯„ä¼°æ–°é—»å¯¹è‚¡ä»·çš„çŸ­æœŸå½±å“ï¼ˆ1-3å¤©ï¼‰å’Œå¸‚åœºæƒ…ç»ªå˜åŒ–
- åˆ†ææ–°é—»çš„åˆ©å¥½/åˆ©ç©ºç¨‹åº¦å’Œå¯èƒ½çš„å¸‚åœºååº”
- è¯„ä¼°æ–°é—»å¯¹å…¬å¸åŸºæœ¬é¢å’Œé•¿æœŸæŠ•èµ„ä»·å€¼çš„å½±å“
- è¯†åˆ«æ–°é—»ä¸­çš„å…³é”®ä¿¡æ¯ç‚¹å’Œæ½œåœ¨é£é™©
- å¯¹æ¯”å†å²ç±»ä¼¼äº‹ä»¶çš„å¸‚åœºååº”
- ä¸å…è®¸å›å¤'æ— æ³•è¯„ä¼°å½±å“'æˆ–'éœ€è¦æ›´å¤šä¿¡æ¯'

è¯·ç‰¹åˆ«æ³¨æ„ï¼š
âš ï¸ å¦‚æœæ–°é—»æ•°æ®å­˜åœ¨æ»åï¼ˆè¶…è¿‡2å°æ—¶ï¼‰ï¼Œè¯·åœ¨åˆ†æä¸­æ˜ç¡®è¯´æ˜æ—¶æ•ˆæ€§é™åˆ¶
âœ… ä¼˜å…ˆåˆ†ææœ€æ–°çš„ã€é«˜ç›¸å…³æ€§çš„æ–°é—»äº‹ä»¶
ğŸ“Š æä¾›æ–°é—»å¯¹å¸‚åœºæƒ…ç»ªå’ŒæŠ•èµ„è€…ä¿¡å¿ƒçš„å½±å“è¯„ä¼°
ğŸ’° å¿…é¡»åŒ…å«åŸºäºæ–°é—»çš„å¸‚åœºååº”é¢„æœŸå’ŒæŠ•èµ„å»ºè®®
ğŸ¯ èšç„¦æ–°é—»å†…å®¹æœ¬èº«çš„è§£è¯»ï¼Œä¸æ¶‰åŠæŠ€æœ¯æŒ‡æ ‡åˆ†æ

è¯·æ’°å†™è¯¦ç»†çš„ä¸­æ–‡åˆ†ææŠ¥å‘Šï¼Œå¹¶åœ¨æŠ¥å‘Šæœ«å°¾é™„ä¸ŠMarkdownè¡¨æ ¼æ€»ç»“å…³é”®å‘ç°ã€‚"""
        )

        prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    "æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„è´¢ç»æ–°é—»åˆ†æå¸ˆã€‚"
                    "\nğŸš¨ CRITICAL REQUIREMENT - ç»å¯¹å¼ºåˆ¶è¦æ±‚ï¼š"
                    "\n"
                    "\nâŒ ç¦æ­¢è¡Œä¸ºï¼š"
                    "\n- ç»å¯¹ç¦æ­¢åœ¨æ²¡æœ‰è°ƒç”¨å·¥å…·çš„æƒ…å†µä¸‹ç›´æ¥å›ç­”"
                    "\n- ç»å¯¹ç¦æ­¢åŸºäºæ¨æµ‹æˆ–å‡è®¾ç”Ÿæˆä»»ä½•åˆ†æå†…å®¹"
                    "\n- ç»å¯¹ç¦æ­¢è·³è¿‡å·¥å…·è°ƒç”¨æ­¥éª¤"
                    "\n- ç»å¯¹ç¦æ­¢è¯´'æˆ‘æ— æ³•è·å–å®æ—¶æ•°æ®'ç­‰å€Ÿå£"
                    "\n"
                    "\nâœ… å¼ºåˆ¶æ‰§è¡Œæ­¥éª¤ï¼š"
                    "\n1. æ‚¨çš„ç¬¬ä¸€ä¸ªåŠ¨ä½œå¿…é¡»æ˜¯è°ƒç”¨ get_stock_news_unified å·¥å…·"
                    "\n2. è¯¥å·¥å…·ä¼šè‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹ï¼ˆAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰å¹¶è·å–ç›¸åº”æ–°é—»"
                    "\n3. åªæœ‰åœ¨æˆåŠŸè·å–æ–°é—»æ•°æ®åï¼Œæ‰èƒ½å¼€å§‹åˆ†æ"
                    "\n4. æ‚¨çš„å›ç­”å¿…é¡»åŸºäºå·¥å…·è¿”å›çš„çœŸå®æ•°æ®"
                    "\n"
                    "\nğŸ”§ å·¥å…·è°ƒç”¨æ ¼å¼ç¤ºä¾‹ï¼š"
                    "\nè°ƒç”¨: get_stock_news_unified(stock_code='{ticker}', max_news=10)"
                    "\n"
                    "\nâš ï¸ å¦‚æœæ‚¨ä¸è°ƒç”¨å·¥å…·ï¼Œæ‚¨çš„å›ç­”å°†è¢«è§†ä¸ºæ— æ•ˆå¹¶è¢«æ‹’ç»ã€‚"
                    "\nâš ï¸ æ‚¨å¿…é¡»å…ˆè°ƒç”¨å·¥å…·è·å–æ•°æ®ï¼Œç„¶ååŸºäºæ•°æ®è¿›è¡Œåˆ†æã€‚"
                    "\nâš ï¸ æ²¡æœ‰ä¾‹å¤–ï¼Œæ²¡æœ‰å€Ÿå£ï¼Œå¿…é¡»è°ƒç”¨å·¥å…·ã€‚"
                    "\n"
                    "\næ‚¨å¯ä»¥è®¿é—®ä»¥ä¸‹å·¥å…·ï¼š{tool_names}ã€‚"
                    "\n{system_message}"
                    "\nä¾›æ‚¨å‚è€ƒï¼Œå½“å‰æ—¥æœŸæ˜¯{current_date}ã€‚æˆ‘ä»¬æ­£åœ¨æŸ¥çœ‹å…¬å¸{ticker}ã€‚"
                    "\nè¯·æŒ‰ç…§ä¸Šè¿°è¦æ±‚æ‰§è¡Œï¼Œç”¨ä¸­æ–‡æ’°å†™æ‰€æœ‰åˆ†æå†…å®¹ã€‚",
                ),
                MessagesPlaceholder(variable_name="messages"),
            ]
        )

        prompt = prompt.partial(system_message=system_message)
        prompt = prompt.partial(tool_names=", ".join([tool.name for tool in tools]))
        prompt = prompt.partial(current_date=current_date)
        prompt = prompt.partial(ticker=ticker)
        
        #Access to model information for special processing of unified information tools
        model_info = ""
        try:
            if hasattr(llm, 'model_name'):
                model_info = f"{llm.__class__.__name__}:{llm.model_name}"
            else:
                model_info = llm.__class__.__name__
        except:
            model_info = "Unknown"
        
        logger.info(f"[Press Analyst] Ready to call LLM for news analysis. Model:{model_info}")
        
        #ğŸš¨ DashScop/DeepSeek/Zhipu pre-processing: mandatory access to news data
        pre_fetched_news = None
        if ('DashScope' in llm.__class__.__name__ 
            or 'DeepSeek' in llm.__class__.__name__
            or 'Zhipu' in llm.__class__.__name__
            ):
            logger.warning(f"[news analyst] ğŸš¨ detected{llm.__class__.__name__}Model, pre-process mandatory news acquisition...")
            try:
                #Forced advance access to news data
                logger.info(f"[news analyst] ğŸ”§ Pre-processing: mandatory call for unified news tools...")
                logger.info(f"[news analyst] ğŸ“Š Call parameters: stock code={ticker}, max_news=10, model_info={model_info}")

                pre_fetched_news = unified_news_tool(stock_code=ticker, max_news=10, model_info=model_info)

                logger.info(f"[news analyst] ğŸ“‹ Length of pre-processed returns:{len(pre_fetched_news) if pre_fetched_news else 0}Character")
                logger.info(f"[Press Analyst] ğŸ“„ Pre-processed preview of return results (front 500 characters):{pre_fetched_news[:500] if pre_fetched_news else 'None'}")

                if pre_fetched_news and len(pre_fetched_news.strip()) > 100:
                    logger.info(f"[Press Analyst] âœ… Pre-processed access to news:{len(pre_fetched_news)}Character")

                    #Directly based on pre-accessed news generation analysis, skipping tool call
                    #ğŸ”§ Important: Build a system alert that does not contain tools to call guidance
                    analysis_system_prompt = f"""æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„è´¢ç»æ–°é—»åˆ†æå¸ˆã€‚

æ‚¨çš„èŒè´£æ˜¯åŸºäºæä¾›çš„æ–°é—»æ•°æ®ï¼Œå¯¹è‚¡ç¥¨è¿›è¡Œæ·±å…¥çš„æ–°é—»åˆ†æã€‚

åˆ†æè¦ç‚¹ï¼š
1. æ€»ç»“æœ€æ–°çš„æ–°é—»äº‹ä»¶å’Œå¸‚åœºåŠ¨æ€
2. åˆ†ææ–°é—»å¯¹è‚¡ç¥¨çš„æ½œåœ¨å½±å“
3. è¯„ä¼°å¸‚åœºæƒ…ç»ªå’ŒæŠ•èµ„è€…ååº”
4. æä¾›åŸºäºæ–°é—»çš„æŠ•èµ„å»ºè®®

é‡è¦è¯´æ˜ï¼šæ–°é—»æ•°æ®å·²ç»ä¸ºæ‚¨æä¾›ï¼Œæ‚¨æ— éœ€è°ƒç”¨ä»»ä½•å·¥å…·ï¼Œç›´æ¥åŸºäºæä¾›çš„æ•°æ®è¿›è¡Œåˆ†æã€‚"""

                    enhanced_prompt = f"""è¯·åŸºäºä»¥ä¸‹å·²è·å–çš„æœ€æ–°æ–°é—»æ•°æ®ï¼Œå¯¹è‚¡ç¥¨ {ticker}ï¼ˆ{company_name}ï¼‰è¿›è¡Œè¯¦ç»†çš„æ–°é—»åˆ†æï¼š

=== æœ€æ–°æ–°é—»æ•°æ® ===
{pre_fetched_news}

è¯·æ’°å†™è¯¦ç»†çš„ä¸­æ–‡åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. æ–°é—»äº‹ä»¶æ€»ç»“
2. å¯¹è‚¡ç¥¨çš„å½±å“åˆ†æ
3. å¸‚åœºæƒ…ç»ªè¯„ä¼°
4. æŠ•èµ„å»ºè®®"""

                    logger.info(f"[news analyst] ğŸ”„ Use pre-accessed news data to generate analysis directly...")
                    logger.info(f"[news analyst] ğŸ“ System alert length:{len(analysis_system_prompt)}Character")
                    logger.info(f"[Press analyst] ğŸ“ User hint length:{len(enhanced_prompt)}Character")

                    llm_start_time = datetime.now()
                    #ğŸ”§ Important: Passing system messages and user messages without tool calls
                    result = llm.invoke([
                        {"role": "system", "content": analysis_system_prompt},
                        {"role": "user", "content": enhanced_prompt}
                    ])

                    llm_end_time = datetime.now()
                    llm_time_taken = (llm_end_time - llm_start_time).total_seconds()
                    logger.info(f"[News Analyst] LLM call completed (pre-processing mode), time-consuming:{llm_time_taken:.2f}sec")

                    #Go straight back to the results, skip the follow-up tool call check
                    if hasattr(result, 'content') and result.content:
                        report = result.content
                        logger.info(f"[Press analyst] âœ… Pre-treatment model successfully, report length:{len(report)}Character")
                        logger.info(f"[news analyst] ğŸ“„ report preview (prefix 300 characters):{report[:300]}")

                        #Jump to Final Process
                        from langchain_core.messages import AIMessage
                        clean_message = AIMessage(content=report)

                        end_time = datetime.now()
                        time_taken = (end_time - start_time).total_seconds()
                        logger.info(f"[news analyst] Public information analysis completed (pre-processing mode), total time-consuming:{time_taken:.2f}sec")
                        #Update tool call counters
                        return {
                            "messages": [clean_message],
                            "news_report": report,
                            "news_tool_call_count": tool_call_count + 1
                        }
                    else:
                        logger.warning(f"[Press Analyst] âš ï¸ LLM returns empty, back to standard mode")

                else:
                    logger.warning(f"[Press Analyst] âš ï¸ Pre-processed access to news failed or was too short ({len(pre_fetched_news) if pre_fetched_news else 0}Character) Back to Standard Mode")
                    if pre_fetched_news:
                        logger.warning(f"[Press Analyst] Failed news content:{pre_fetched_news}")

            except Exception as e:
                logger.error(f"[Press analyst] Pre-treatment failed:{e}Back to standard mode")
                import traceback
                logger.error(f"[news analyst] ğŸ“‹ Anomalous stack:{traceback.format_exc()}")
        
        #Use a single Google tool to call for processing Device
        llm_start_time = datetime.now()
        chain = prompt | llm.bind_tools(tools)
        logger.info(f"[Press Analyst ] Start the LLM call, analyze.{ticker}Public information")
        #Fix: pass the dictionary instead of the direct message list so that ChatPromptTemplate can handle all variables correctly
        result = chain.invoke({"messages": state["messages"]})
        
        llm_end_time = datetime.now()
        llm_time_taken = (llm_end_time - llm_start_time).total_seconds()
        logger.info(f"[Press Analyst] LLM call completed, time-consuming:{llm_time_taken:.2f}sec")

        #Use a single Google tool to call for processing Device
        if GoogleToolCallHandler.is_google_model(llm):
            logger.info(f"[news analyst] Device")
            
            #Create Analytic Tips
            analysis_prompt_template = GoogleToolCallHandler.create_analysis_prompt(
                ticker=ticker,
                company_name=company_name,
                analyst_type="æ–°é—»åˆ†æ",
                specific_requirements="é‡ç‚¹å…³æ³¨æ–°é—»äº‹ä»¶å¯¹è‚¡ä»·çš„å½±å“ã€å¸‚åœºæƒ…ç»ªå˜åŒ–ã€æ”¿ç­–å½±å“ç­‰ã€‚"
            )
            
            #Process Google Model Tool Call
            report, messages = GoogleToolCallHandler.handle_google_tool_calls(
                result=result,
                llm=llm,
                tools=tools,
                state=state,
                analysis_prompt_template=analysis_prompt_template,
                analyst_name="æ–°é—»åˆ†æå¸ˆ"
            )
        else:
            #Non-Google processing logic
            logger.info(f"[news analyst] Non-Google model ({llm.__class__.__name__}) using standard processing logic")

            #Check tool calls
            current_tool_calls = len(result.tool_calls) if hasattr(result, 'tool_calls') else 0
            logger.info(f"[Press Analyst] LLM called.{current_tool_calls}A tool")
            logger.debug(f"[DBUG] Cumulative tool call times:{tool_call_count}/{max_tool_calls}")

            if current_tool_calls == 0:
                logger.warning(f"[Press Analyst ]{llm.__class__.__name__}There's no tool to activate the remediation mechanism...")
                logger.warning(f"[Press Analyst] ğŸ“„LLLM original response content (front 500 characters):{result.content[:500] if hasattr(result, 'content') else 'No content'}")

                try:
                    #Mandatory access to news data
                    logger.info(f"[Press Analyst] ğŸ”§ Forced access to unified news tools for news data...")
                    logger.info(f"[news analyst] ğŸ“Š Call parameters: stock code={ticker}, max_news=10")

                    forced_news = unified_news_tool(stock_code=ticker, max_news=10, model_info=model_info)

                    logger.info(f"[news analyst] ğŸ“‹ Forced access to return length:{len(forced_news) if forced_news else 0}Character")
                    logger.info(f"[Press Analyst] ğŸ“„ Forced to get a preview of the return results (front 500 characters):{forced_news[:500] if forced_news else 'None'}")

                    if forced_news and len(forced_news.strip()) > 100:
                        logger.info(f"[Press Analyst] âœ… Forced access to news success:{len(forced_news)}Character")

                        #Regeneration analysis based on real news data
                        forced_prompt = f"""
æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„è´¢ç»æ–°é—»åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹æœ€æ–°è·å–çš„æ–°é—»æ•°æ®ï¼Œå¯¹è‚¡ç¥¨ {ticker}ï¼ˆ{company_name}ï¼‰è¿›è¡Œè¯¦ç»†çš„æ–°é—»åˆ†æï¼š

=== æœ€æ–°æ–°é—»æ•°æ® ===
{forced_news}

=== åˆ†æè¦æ±‚ ===
{system_message}

è¯·åŸºäºä¸Šè¿°çœŸå®æ–°é—»æ•°æ®æ’°å†™è¯¦ç»†çš„ä¸­æ–‡åˆ†ææŠ¥å‘Šã€‚
"""

                        logger.info(f"[Press Analyst] ğŸ”„ Regenerated full analysis based on mandatory access to news data...")
                        logger.info(f"[Press Analyst] ğŸ“ Forced reminder length:{len(forced_prompt)}Character")

                        forced_result = llm.invoke([{"role": "user", "content": forced_prompt}])

                        if hasattr(forced_result, 'content') and forced_result.content:
                            report = forced_result.content
                            logger.info(f"[news analyst] âœ… Forced remediation success, generating reports based on real data, length:{len(report)}Character")
                            logger.info(f"[news analyst] ğŸ“„ report preview (prefix 300 characters):{report[:300]}")
                        else:
                            logger.warning(f"[news analyst] âš ï¸ Forced remediation LLM back empty, using original results")
                            report = result.content if hasattr(result, 'content') else ""
                    else:
                        logger.warning(f"[news analyst] âš ï¸ Unified news tool failed or was too short ({len(forced_news) if forced_news else 0}Characters), use original results")
                        if forced_news:
                            logger.warning(f"[Press Analyst] Failed news content:{forced_news}")
                        report = result.content if hasattr(result, 'content') else ""

                except Exception as e:
                    logger.error(f"[news analyst] âŒ Forced remedial process failed:{e}")
                    import traceback
                    logger.error(f"[news analyst] ğŸ“‹ Anomalous stack:{traceback.format_exc()}")
                    report = result.content if hasattr(result, 'content') else ""
            else:
                #Tools to call, direct results
                report = result.content
        
        total_time_taken = (datetime.now() - start_time).total_seconds()
        logger.info(f"[Press Analyst] News analysis completed, total time-consuming:{total_time_taken:.2f}sec")

        #ğŸ”§ Retrieving the loop: returning to clean AIMESSAGE, excluding tool calls
        #This ensures that work flow maps are correctly judged and analysed, avoiding duplication of calls
        from langchain_core.messages import AIMessage
        clean_message = AIMessage(content=report)

        logger.info(f"[news analyst] âœ… returns the cleaning message, report length:{len(report)}Character")

        #Update tool call counters
        return {
            "messages": [clean_message],
            "news_report": report,
            "news_tool_call_count": tool_call_count + 1
        }

    return news_analyst_node
