#!/usr/bin/env python3
"""Stock data pre-acquisition and validation module
To validate the existence of stocks prior to the start of the analysis process and to pre-empt and cache the necessary data
"""

import re
from typing import Dict, Tuple, Optional
from datetime import datetime, timedelta

#Import Log Module
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('stock_validator')


class StockDataPreparationResult:
    """Equities Data Pre-Access Category"""

    def __init__(self, is_valid: bool, stock_code: str, market_type: str = "",
                 stock_name: str = "", error_message: str = "", suggestion: str = "",
                 has_historical_data: bool = False, has_basic_info: bool = False,
                 data_period_days: int = 0, cache_status: str = ""):
        self.is_valid = is_valid
        self.stock_code = stock_code
        self.market_type = market_type
        self.stock_name = stock_name
        self.error_message = error_message
        self.suggestion = suggestion
        self.has_historical_data = has_historical_data
        self.has_basic_info = has_basic_info
        self.data_period_days = data_period_days
        self.cache_status = cache_status

    def to_dict(self) -> Dict:
        """Convert to Dictionary Format"""
        return {
            'is_valid': self.is_valid,
            'stock_code': self.stock_code,
            'market_type': self.market_type,
            'stock_name': self.stock_name,
            'error_message': self.error_message,
            'suggestion': self.suggestion,
            'has_historical_data': self.has_historical_data,
            'has_basic_info': self.has_basic_info,
            'data_period_days': self.data_period_days,
            'cache_status': self.cache_status
        }


#Maintain backward compatibility
StockValidationResult = StockDataPreparationResult


class StockDataPreparer:
    """Pre-acquirers and certifiers for stock data"""

    def __init__(self, default_period_days: int = 30):
        self.timeout_seconds = 15  #Data acquisition timeout
        self.default_period_days = default_period_days  #Default length of historical data (days)
    
    def prepare_stock_data(self, stock_code: str, market_type: str = "auto",
                          period_days: int = None, analysis_date: str = None) -> StockDataPreparationResult:
        """Pre-acquisition and validation of stock data

Args:
Stock code: Stock code
Market type: Market type ("A" equity, "Hong Kong equity", "Auto")
period days: length of historical data (days), value when defaulting on class initialization
Analysis date: date analysed, default today

Returns:
StockDataPreparationResult: Data Preparation Results
"""
        if period_days is None:
            period_days = self.default_period_days

        if analysis_date is None:
            analysis_date = datetime.now().strftime('%Y-%m-%d')

        logger.info(f"[Data Preparation]{stock_code}(Market:{market_type}, duration:{period_days}Oh, my God.")

        #1. Basic format validation
        format_result = self._validate_format(stock_code, market_type)
        if not format_result.is_valid:
            return format_result

        #2. Automatic detection of market types
        if market_type == "auto":
            market_type = self._detect_market_type(stock_code)
            logger.debug(f"ğŸ“Š [Data Preparation] Automatic detection of market types:{market_type}")

        #3. Advance data acquisition and validation
        return self._prepare_data_by_market(stock_code, market_type, period_days, analysis_date)
    
    def _validate_format(self, stock_code: str, market_type: str) -> StockDataPreparationResult:
        """Validate stock code format"""
        stock_code = stock_code.strip()
        
        if not stock_code:
            return StockDataPreparationResult(
                is_valid=False,
                stock_code=stock_code,
                error_message="è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º",
                suggestion="è¯·è¾“å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç "
            )

        if len(stock_code) > 10:
            return StockDataPreparationResult(
                is_valid=False,
                stock_code=stock_code,
                error_message="è‚¡ç¥¨ä»£ç é•¿åº¦ä¸èƒ½è¶…è¿‡10ä¸ªå­—ç¬¦",
                suggestion="è¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æ ¼å¼"
            )
        
        #Certification format by market type
        if market_type == "Aè‚¡":
            if not re.match(r'^\d{6}$', stock_code):
                return StockDataPreparationResult(
                    is_valid=False,
                    stock_code=stock_code,
                    market_type="Aè‚¡",
                    error_message="Aè‚¡ä»£ç æ ¼å¼é”™è¯¯ï¼Œåº”ä¸º6ä½æ•°å­—",
                    suggestion="è¯·è¾“å…¥6ä½æ•°å­—çš„Aè‚¡ä»£ç ï¼Œå¦‚ï¼š000001ã€600519"
                )
        elif market_type == "æ¸¯è‚¡":
            stock_code_upper = stock_code.upper()
            hk_format = re.match(r'^\d{4,5}\.HK$', stock_code_upper)
            digit_format = re.match(r'^\d{4,5}$', stock_code)

            if not (hk_format or digit_format):
                return StockDataPreparationResult(
                    is_valid=False,
                    stock_code=stock_code,
                    market_type="æ¸¯è‚¡",
                    error_message="æ¸¯è‚¡ä»£ç æ ¼å¼é”™è¯¯",
                    suggestion="è¯·è¾“å…¥4-5ä½æ•°å­—.HKæ ¼å¼ï¼ˆå¦‚ï¼š0700.HKï¼‰æˆ–4-5ä½æ•°å­—ï¼ˆå¦‚ï¼š0700ï¼‰"
                )
        elif market_type == "ç¾è‚¡":
            if not re.match(r'^[A-Z]{1,5}$', stock_code.upper()):
                return StockDataPreparationResult(
                    is_valid=False,
                    stock_code=stock_code,
                    market_type="ç¾è‚¡",
                    error_message="ç¾è‚¡ä»£ç æ ¼å¼é”™è¯¯ï¼Œåº”ä¸º1-5ä½å­—æ¯",
                    suggestion="è¯·è¾“å…¥1-5ä½å­—æ¯çš„ç¾è‚¡ä»£ç ï¼Œå¦‚ï¼šAAPLã€TSLA"
                )
        
        return StockDataPreparationResult(
            is_valid=True,
            stock_code=stock_code,
            market_type=market_type
        )
    
    def _detect_market_type(self, stock_code: str) -> str:
        """Automatically detect market types"""
        stock_code = stock_code.strip().upper()
        
        #Unit A: 6 figures
        if re.match(r'^\d{6}$', stock_code):
            return "Aè‚¡"
        
        #Port Unit: 4-5 figures. HK or 4-5 figures
        if re.match(r'^\d{4,5}\.HK$', stock_code) or re.match(r'^\d{4,5}$', stock_code):
            return "æ¸¯è‚¡"
        
        #United States share: 1-5 letters
        if re.match(r'^[A-Z]{1,5}$', stock_code):
            return "ç¾è‚¡"
        
        return "æœªçŸ¥"

    def _get_hk_network_limitation_suggestion(self) -> str:
        """Detailed recommendations on access to port unit network restrictions"""
        suggestions = [
            "ğŸŒ æ¸¯è‚¡æ•°æ®è·å–å—åˆ°ç½‘ç»œAPIé™åˆ¶ï¼Œè¿™æ˜¯å¸¸è§çš„ä¸´æ—¶é—®é¢˜",
            "",
            "ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š",
            "1. ç­‰å¾…5-10åˆ†é’Ÿåé‡è¯•ï¼ˆAPIé™åˆ¶é€šå¸¸ä¼šè‡ªåŠ¨è§£é™¤ï¼‰",
            "2. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š",
            "3. å¦‚æœæ˜¯çŸ¥åæ¸¯è‚¡ï¼ˆå¦‚è…¾è®¯0700.HKã€é˜¿é‡Œ9988.HKï¼‰ï¼Œä»£ç æ ¼å¼é€šå¸¸æ­£ç¡®",
            "4. å¯ä»¥å°è¯•ä½¿ç”¨å…¶ä»–æ—¶é—´æ®µè¿›è¡Œåˆ†æ",
            "",
            "ğŸ“‹ å¸¸è§æ¸¯è‚¡ä»£ç æ ¼å¼ï¼š",
            "â€¢ è…¾è®¯æ§è‚¡ï¼š0700.HK",
            "â€¢ é˜¿é‡Œå·´å·´ï¼š9988.HK",
            "â€¢ ç¾å›¢ï¼š3690.HK",
            "â€¢ å°ç±³é›†å›¢ï¼š1810.HK",
            "",
            "â° å»ºè®®ç¨åé‡è¯•ï¼Œæˆ–è”ç³»æŠ€æœ¯æ”¯æŒè·å–å¸®åŠ©"
        ]
        return "\n".join(suggestions)

    def _extract_hk_stock_name(self, stock_info, stock_code: str) -> str:
        """Extracting stock names from port information to support multiple formats"""
        if not stock_info:
            return "æœªçŸ¥"

        #Process different types of return values
        if isinstance(stock_info, dict):
            #If Dictionary, try to extract names from common fields
            name_fields = ['name', 'longName', 'shortName', 'companyName', 'å…¬å¸åç§°', 'è‚¡ç¥¨åç§°']
            for field in name_fields:
                if field in stock_info and stock_info[field]:
                    name = str(stock_info[field]).strip()
                    if name and name != "æœªçŸ¥":
                        return name

            #Use stock code if the dictionary contains valid information without name fields
            if len(stock_info) > 0:
                return stock_code
            return "æœªçŸ¥"

        #Convert to String Processing
        stock_info_str = str(stock_info)

        #Method 1: Standard format.
        if "å…¬å¸åç§°:" in stock_info_str:
            lines = stock_info_str.split('\n')
            for line in lines:
                if "å…¬å¸åç§°:" in line:
                    name = line.split(':')[1].strip()
                    if name and name != "æœªçŸ¥":
                        return name

        #Method 2: Yahoo Finance Format Testing
        #Log shows: "âœ… Yahoo Finance successfully accessed information on the Port Unit: 0700.HK->TENCENT"
        if "Yahoo FinanceæˆåŠŸè·å–æ¸¯è‚¡ä¿¡æ¯" in stock_info_str:
            #Extract name from log
            if " -> " in stock_info_str:
                parts = stock_info_str.split(" -> ")
                if len(parts) > 1:
                    name = parts[-1].strip()
                    if name and name != "æœªçŸ¥":
                        return name

        #Method 3: Checking for common company names is critical Word
        company_indicators = [
            "Limited", "Ltd", "Corporation", "Corp", "Inc", "Group",
            "Holdings", "Company", "Co", "é›†å›¢", "æ§è‚¡", "æœ‰é™å…¬å¸"
        ]

        lines = stock_info_str.split('\n')
        for line in lines:
            line = line.strip()
            if any(indicator in line for indicator in company_indicators):
                #Try extracting company names
                if ":" in line:
                    potential_name = line.split(':')[-1].strip()
                    if potential_name and len(potential_name) > 2:
                        return potential_name
                elif len(line) > 2 and len(line) < 100:  #Reasonable length of company name
                    return line

        #Method 4: Use the stock code if the information appears valid but cannot be deciphered
        if len(stock_info_str) > 50 and "âŒ" not in stock_info_str:
            #The information appears to be valid, but cannot be deciphered, using code as name
            return stock_code

        return "æœªçŸ¥"

    def _prepare_data_by_market(self, stock_code: str, market_type: str,
                               period_days: int, analysis_date: str) -> StockDataPreparationResult:
        """Advance data acquisition by market type"""
        logger.debug(f"[Data Preparation]{market_type}Equities{stock_code}Prepare Data")

        try:
            if market_type == "Aè‚¡":
                return self._prepare_china_stock_data(stock_code, period_days, analysis_date)
            elif market_type == "æ¸¯è‚¡":
                return self._prepare_hk_stock_data(stock_code, period_days, analysis_date)
            elif market_type == "ç¾è‚¡":
                return self._prepare_us_stock_data(stock_code, period_days, analysis_date)
            else:
                return StockDataPreparationResult(
                    is_valid=False,
                    stock_code=stock_code,
                    market_type=market_type,
                    error_message=f"ä¸æ”¯æŒçš„å¸‚åœºç±»å‹: {market_type}",
                    suggestion="è¯·é€‰æ‹©æ”¯æŒçš„å¸‚åœºç±»å‹ï¼šAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡"
                )
        except Exception as e:
            logger.error(f"Data preparation anomaly:{e}")
            return StockDataPreparationResult(
                is_valid=False,
                stock_code=stock_code,
                market_type=market_type,
                error_message=f"æ•°æ®å‡†å¤‡è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                suggestion="è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•"
            )

    async def _prepare_data_by_market_async(self, stock_code: str, market_type: str,
                                           period_days: int, analysis_date: str) -> StockDataPreparationResult:
        """Pre-acquire data according to market type (speech version)"""
        logger.debug(f"[Data Preparation - Step ]{market_type}Equities{stock_code}Prepare Data")

        try:
            if market_type == "Aè‚¡":
                return await self._prepare_china_stock_data_async(stock_code, period_days, analysis_date)
            elif market_type == "æ¸¯è‚¡":
                return self._prepare_hk_stock_data(stock_code, period_days, analysis_date)
            elif market_type == "ç¾è‚¡":
                return self._prepare_us_stock_data(stock_code, period_days, analysis_date)
            else:
                return StockDataPreparationResult(
                    is_valid=False,
                    stock_code=stock_code,
                    market_type=market_type,
                    error_message=f"ä¸æ”¯æŒçš„å¸‚åœºç±»å‹: {market_type}",
                    suggestion="è¯·é€‰æ‹©æ”¯æŒçš„å¸‚åœºç±»å‹ï¼šAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡"
                )
        except Exception as e:
            logger.error(f"Data readiness anomaly:{e}")
            return StockDataPreparationResult(
                is_valid=False,
                stock_code=stock_code,
                market_type=market_type,
                error_message=f"æ•°æ®å‡†å¤‡è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                suggestion="è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•"
            )

    def _prepare_china_stock_data(self, stock_code: str, period_days: int,
                                 analysis_date: str) -> StockDataPreparationResult:
        """Advance acquisition of Unit A data, including database checks and automatic synchronization"""
        logger.info(f"[A unit data]{stock_code}Data (time:{period_days}Oh, my God.")

        #Calculated date range (using extended date range, consistent with Get china stock data unified)
        end_date = datetime.strptime(analysis_date, '%Y-%m-%d')

        #Fetching configuration backtrace days (consistent with Get china stock data unified)
        from app.core.config import settings
        lookback_days = getattr(settings, 'MARKET_ANALYST_LOOKBACK_DAYS', 365)

        #Use extended date range for data checking and synchronization
        extended_start_date = end_date - timedelta(days=lookback_days)
        extended_start_date_str = extended_start_date.strftime('%Y-%m-%d')
        end_date_str = end_date.strftime('%Y-%m-%d')

        logger.info(f"Actual data range:{extended_start_date_str}Present.{end_date_str} ({lookback_days}Oh, my God.")

        has_historical_data = False
        has_basic_info = False
        stock_name = "æœªçŸ¥"
        cache_status = ""
        data_synced = False

        try:
            #1. Check the availability and updating of data in the database
            logger.debug(f"Check the database.{stock_code}Data...")
            db_check_result = self._check_database_data(stock_code, extended_start_date_str, end_date_str)

            #2. Automatically trigger sync if data are non-existent or not up to date
            if not db_check_result["has_data"] or not db_check_result["is_latest"]:
                logger.warning(f"The database data are incomplete:{db_check_result['message']}")
                logger.info(f"[Unit A data]{stock_code}")

                #Sync with extended date range
                sync_result = self._trigger_data_sync_sync(stock_code, extended_start_date_str, end_date_str)
                if sync_result["success"]:
                    logger.info(f"Data sync successfully:{sync_result['message']}")
                    data_synced = True
                    cache_status += "æ•°æ®å·²åŒæ­¥; "
                else:
                    logger.warning(f"Data synchronisation failed:{sync_result['message']}")
                    #Keep trying to get data from API
            else:
                logger.info(f"The database data check has been approved:{db_check_result['message']}")
                cache_status += "æ•°æ®åº“æ•°æ®æœ€æ–°; "

            #3. Access to basic information
            logger.debug(f"[Unit A data]{stock_code}Basic information...")
            from tradingagents.dataflows.interface import get_china_stock_info_unified

            stock_info = get_china_stock_info_unified(stock_code)

            if stock_info and "âŒ" not in stock_info and "æœªèƒ½è·å–" not in stock_info:
                #Parsing stock name
                if "è‚¡ç¥¨åç§°:" in stock_info:
                    lines = stock_info.split('\n')
                    for line in lines:
                        if "è‚¡ç¥¨åç§°:" in line:
                            stock_name = line.split(':')[1].strip()
                            break

                #Check for valid stock names
                if stock_name != "æœªçŸ¥" and not stock_name.startswith(f"è‚¡ç¥¨{stock_code}"):
                    has_basic_info = True
                    logger.info(f"[Unit A data]{stock_code} - {stock_name}")
                    cache_status += "åŸºæœ¬ä¿¡æ¯å·²ç¼“å­˜; "
                else:
                    logger.warning(f"Basic information is invalid:{stock_code}")
                    return StockDataPreparationResult(
                        is_valid=False,
                        stock_code=stock_code,
                        market_type="Aè‚¡",
                        error_message=f"è‚¡ç¥¨ä»£ç  {stock_code} ä¸å­˜åœ¨æˆ–ä¿¡æ¯æ— æ•ˆ",
                        suggestion="è¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ç¡®è®¤è¯¥è‚¡ç¥¨æ˜¯å¦å·²ä¸Šå¸‚"
                    )
            else:
                logger.warning(f"No basic information is available:{stock_code}")
                return StockDataPreparationResult(
                    is_valid=False,
                    stock_code=stock_code,
                    market_type="Aè‚¡",
                    error_message=f"æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„åŸºæœ¬ä¿¡æ¯",
                    suggestion="è¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ç¡®è®¤è¯¥è‚¡ç¥¨æ˜¯å¦å·²ä¸Šå¸‚"
                )

            #4. Access to historical data (use extended date range)
            logger.debug(f"[Unit A data]{stock_code}Historical Data ({extended_start_date_str}Present.{end_date_str})...")
            from tradingagents.dataflows.interface import get_china_stock_data_unified

            historical_data = get_china_stock_data_unified(stock_code, extended_start_date_str, end_date_str)

            if historical_data and "âŒ" not in historical_data and "è·å–å¤±è´¥" not in historical_data:
                #More liberal data validity checks
                data_indicators = [
                    "å¼€ç›˜ä»·", "æ”¶ç›˜ä»·", "æœ€é«˜ä»·", "æœ€ä½ä»·", "æˆäº¤é‡",
                    "open", "close", "high", "low", "volume",
                    "æ—¥æœŸ", "date", "æ—¶é—´", "time"
                ]

                has_valid_data = (
                    len(historical_data) > 50 and  #Lower length requirement
                    any(indicator in historical_data for indicator in data_indicators)
                )

                if has_valid_data:
                    has_historical_data = True
                    logger.info(f"[Unit A data]{stock_code} ({lookback_days}Oh, my God.")
                    cache_status += f"å†å²æ•°æ®å·²ç¼“å­˜({lookback_days}å¤©); "
                else:
                    logger.warning(f"[A unit data]{stock_code}")
                    logger.debug(f"Data content preview:{historical_data[:200]}...")
                    return StockDataPreparationResult(
                        is_valid=False,
                        stock_code=stock_code,
                        market_type="Aè‚¡",
                        stock_name=stock_name,
                        has_basic_info=has_basic_info,
                        error_message=f"è‚¡ç¥¨ {stock_code} çš„å†å²æ•°æ®æ— æ•ˆæˆ–ä¸è¶³",
                        suggestion="è¯¥è‚¡ç¥¨å¯èƒ½ä¸ºæ–°ä¸Šå¸‚è‚¡ç¥¨æˆ–æ•°æ®æºæš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
                    )
            else:
                logger.warning(f"No historical data are available:{stock_code}")
                return StockDataPreparationResult(
                    is_valid=False,
                    stock_code=stock_code,
                    market_type="Aè‚¡",
                    stock_name=stock_name,
                    has_basic_info=has_basic_info,
                    error_message=f"æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„å†å²æ•°æ®",
                    suggestion="è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ•°æ®æºé…ç½®ï¼Œæˆ–ç¨åé‡è¯•"
                )

            #5. Data preparation success
            logger.info(f"Data ready:{stock_code} - {stock_name}")
            return StockDataPreparationResult(
                is_valid=True,
                stock_code=stock_code,
                market_type="Aè‚¡",
                stock_name=stock_name,
                has_historical_data=has_historical_data,
                has_basic_info=has_basic_info,
                data_period_days=lookback_days,  #Number of days to use actual data
                cache_status=cache_status.rstrip('; ')
            )

        except Exception as e:
            logger.error(f"Data preparation failed:{e}")
            import traceback
            logger.debug(f"Detailed error:{traceback.format_exc()}")
            return StockDataPreparationResult(
                is_valid=False,
                stock_code=stock_code,
                market_type="Aè‚¡",
                stock_name=stock_name,
                has_basic_info=has_basic_info,
                has_historical_data=has_historical_data,
                error_message=f"æ•°æ®å‡†å¤‡å¤±è´¥: {str(e)}",
                suggestion="è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ•°æ®æºé…ç½®"
            )

    async def _prepare_china_stock_data_async(self, stock_code: str, period_days: int,
                                             analysis_date: str) -> StockDataPreparationResult:
        """Advance acquisition of Unit A data (speech version), including database checks and automatic synchronization"""
        logger.info(f"Let's get ready.{stock_code}Data (time:{period_days}Oh, my God.")

        #Calculate Date Range
        end_date = datetime.strptime(analysis_date, '%Y-%m-%d')
        from app.core.config import settings
        lookback_days = getattr(settings, 'MARKET_ANALYST_LOOKBACK_DAYS', 365)
        extended_start_date = end_date - timedelta(days=lookback_days)
        extended_start_date_str = extended_start_date.strftime('%Y-%m-%d')
        end_date_str = end_date.strftime('%Y-%m-%d')

        logger.info(f"Actual data ranges:{extended_start_date_str}Present.{end_date_str} ({lookback_days}Oh, my God.")

        has_historical_data = False
        has_basic_info = False
        stock_name = "æœªçŸ¥"
        cache_status = ""

        try:
            #1. Check the availability and updating of data in the database
            logger.debug(f"Check the database. Medium{stock_code}Data...")
            db_check_result = self._check_database_data(stock_code, extended_start_date_str, end_date_str)

            #2. Automatically trigger synchronization (using a walk method) if the data do not exist or are not up to date
            if not db_check_result["has_data"] or not db_check_result["is_latest"]:
                logger.warning(f"The database is incomplete:{db_check_result['message']}")
                logger.info(f"ğŸ”„ [A Unit Data-Instant] Automatically triggers data synchronization:{stock_code}")

                #ğŸ”¥Sync data using a different way
                sync_result = await self._trigger_data_sync_async(stock_code, extended_start_date_str, end_date_str)
                if sync_result["success"]:
                    logger.info(f"Data sync successfully:{sync_result['message']}")
                    cache_status += "æ•°æ®å·²åŒæ­¥; "
                else:
                    logger.warning(f"âš ï¸ [A Unit Data-Instant] Data sync failed:{sync_result['message']}")
            else:
                logger.info(f"The database data check has been approved:{db_check_result['message']}")
                cache_status += "æ•°æ®åº“æ•°æ®æœ€æ–°; "

            #3. Access to basic information (synchronous operations)
            logger.debug(f"ğŸ“Š [A Unit Data - Step ]{stock_code}Basic information...")
            from tradingagents.dataflows.interface import get_china_stock_info_unified
            stock_info = get_china_stock_info_unified(stock_code)

            if stock_info and "âŒ" not in stock_info and "æœªèƒ½è·å–" not in stock_info:
                if "è‚¡ç¥¨åç§°:" in stock_info:
                    lines = stock_info.split('\n')
                    for line in lines:
                        if "è‚¡ç¥¨åç§°:" in line:
                            stock_name = line.split(':')[1].strip()
                            break

                if stock_name != "æœªçŸ¥" and not stock_name.startswith(f"è‚¡ç¥¨{stock_code}"):
                    has_basic_info = True
                    logger.info(f"Basic information acquisition success:{stock_code} - {stock_name}")
                    cache_status += "åŸºæœ¬ä¿¡æ¯å·²ç¼“å­˜; "

            #4. Access to historical data (synchronous operations)
            logger.debug(f"ğŸ“Š [A Unit Data - Step ]{stock_code}Historical Data...")
            from tradingagents.dataflows.interface import get_china_stock_data_unified
            historical_data = get_china_stock_data_unified(stock_code, extended_start_date_str, end_date_str)

            if historical_data and "âŒ" not in historical_data and "è·å–å¤±è´¥" not in historical_data:
                data_indicators = ["å¼€ç›˜ä»·", "æ”¶ç›˜ä»·", "æœ€é«˜ä»·", "æœ€ä½ä»·", "æˆäº¤é‡"]
                has_valid_data = (
                    len(historical_data) > 50 and
                    any(indicator in historical_data for indicator in data_indicators)
                )

                if has_valid_data:
                    has_historical_data = True
                    logger.info(f"âœ… [A Unit Data-Instant] Historical data acquisition success:{stock_code}")
                    cache_status += f"å†å²æ•°æ®å·²ç¼“å­˜({lookback_days}å¤©); "
                else:
                    return StockDataPreparationResult(
                        is_valid=False,
                        stock_code=stock_code,
                        market_type="Aè‚¡",
                        stock_name=stock_name,
                        has_basic_info=has_basic_info,
                        error_message=f"è‚¡ç¥¨ {stock_code} çš„å†å²æ•°æ®æ— æ•ˆæˆ–ä¸è¶³",
                        suggestion="è¯¥è‚¡ç¥¨å¯èƒ½ä¸ºæ–°ä¸Šå¸‚è‚¡ç¥¨æˆ–æ•°æ®æºæš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
                    )
            else:
                return StockDataPreparationResult(
                    is_valid=False,
                    stock_code=stock_code,
                    market_type="Aè‚¡",
                    stock_name=stock_name,
                    has_basic_info=has_basic_info,
                    error_message=f"æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„å†å²æ•°æ®",
                    suggestion="è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ•°æ®æºé…ç½®ï¼Œæˆ–ç¨åé‡è¯•"
                )

            #5. Data preparation success
            logger.info(f"Data ready:{stock_code} - {stock_name}")
            return StockDataPreparationResult(
                is_valid=True,
                stock_code=stock_code,
                market_type="Aè‚¡",
                stock_name=stock_name,
                has_historical_data=has_historical_data,
                has_basic_info=has_basic_info,
                data_period_days=lookback_days,
                cache_status=cache_status.rstrip('; ')
            )

        except Exception as e:
            logger.error(f"Data preparation failed:{e}")
            import traceback
            logger.debug(f"Detailed error:{traceback.format_exc()}")
            return StockDataPreparationResult(
                is_valid=False,
                stock_code=stock_code,
                market_type="Aè‚¡",
                stock_name=stock_name,
                has_basic_info=has_basic_info,
                has_historical_data=has_historical_data,
                error_message=f"æ•°æ®å‡†å¤‡å¤±è´¥: {str(e)}",
                suggestion="è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ•°æ®æºé…ç½®"
            )

    def _check_database_data(self, stock_code: str, start_date: str, end_date: str) -> Dict:
        """Check the existence and updating of data in the database

Returns:
Dict:   FMT 0 
"""
        try:
            from tradingagents.dataflows.cache.mongodb_cache_adapter import get_mongodb_cache_adapter

            adapter = get_mongodb_cache_adapter()
            if not adapter.use_app_cache or adapter.db is None:
                return {
                    "has_data": False,
                    "is_latest": False,
                    "record_count": 0,
                    "latest_date": None,
                    "message": "MongoDBç¼“å­˜æœªå¯ç”¨"
                }

            #Query historical data in database
            df = adapter.get_historical_data(stock_code, start_date, end_date)

            if df is None or df.empty:
                return {
                    "has_data": False,
                    "is_latest": False,
                    "record_count": 0,
                    "latest_date": None,
                    "message": "æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®"
                }

            #Check data volume
            record_count = len(df)

            #Date of acquisition of latest data
            if 'trade_date' in df.columns:
                latest_date = df['trade_date'].max()
            elif 'date' in df.columns:
                latest_date = df['date'].max()
            else:
                latest_date = None

            #Check to include the latest transaction date
            from datetime import datetime, timedelta
            today = datetime.now()

            #Get the latest trading day (consider weekends)
            recent_trade_date = today
            for i in range(5):  #Five days at most.
                check_date = today - timedelta(days=i)
                if check_date.weekday() < 5:  #Monday to Friday.
                    recent_trade_date = check_date
                    break

            recent_trade_date_str = recent_trade_date.strftime('%Y-%m-%d')

            #Determination of whether the data are up to date (a 1-day delay allowed)
            is_latest = False
            if latest_date:
                latest_date_str = str(latest_date)[:10]  #YYY-MM-DD
                latest_dt = datetime.strptime(latest_date_str, '%Y-%m-%d')
                days_diff = (recent_trade_date - latest_dt).days
                is_latest = days_diff <= 1  #1 day delay allowed

            message = f"æ‰¾åˆ°{record_count}æ¡è®°å½•ï¼Œæœ€æ–°æ—¥æœŸ: {latest_date}"
            if not is_latest:
                message += f"ï¼ˆéœ€è¦æ›´æ–°åˆ°{recent_trade_date_str}ï¼‰"

            return {
                "has_data": True,
                "is_latest": is_latest,
                "record_count": record_count,
                "latest_date": str(latest_date) if latest_date else None,
                "message": message
            }

        except Exception as e:
            logger.error(f"[Data Check] Checking database data failed:{e}")
            return {
                "has_data": False,
                "is_latest": False,
                "record_count": 0,
                "latest_date": None,
                "message": f"æ£€æŸ¥å¤±è´¥: {str(e)}"
            }

    def _trigger_data_sync_sync(self, stock_code: str, start_date: str, end_date: str) -> Dict:
        """Trigger Data Synchronization (Sync Packer)
Call the step synchronisation method in sync context

compatible with asyncio.to thread() calling:
- Create a new cycle of events if running in a line created by asyncio.to thread()
"attached to a different loop" error
"""
        import asyncio

        try:
            #Check if there is a running cycle of events
            #If yes, this indicates that we need to create a new cycle of events in the line created by Asyncio.to thread()
            try:
                running_loop = asyncio.get_running_loop()
                #There is a running cycle that indicates that run until complete cannot be used in the aniso context
                #Create a new event cycle to run in a new thread
                logger.info(f"ğŸ” [DataSync] Detecting running event cycles, creating new event cycles")
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    return loop.run_until_complete(
                        self._trigger_data_sync_async(stock_code, start_date, end_date)
                    )
                finally:
                    loop.close()
                    asyncio.set_event_loop(None)
            except RuntimeError:
                #There is no running cycle, you can securely access or create event cycle
                try:
                    loop = asyncio.get_event_loop()
                    if loop.is_closed():
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                except RuntimeError:
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                #Call the heap method
                return loop.run_until_complete(
                    self._trigger_data_sync_async(stock_code, start_date, end_date)
                )
        except Exception as e:
            logger.error(f"[Data syncs]{e}", exc_info=True)
            return {
                "success": False,
                "message": f"åŒæ­¥å¤±è´¥: {str(e)}",
                "synced_records": 0,
                "data_source": None
            }

    async def _trigger_data_sync_async(self, stock_code: str, start_date: str, end_date: str) -> Dict:
        """Trigger data synchronisation (show, according to data source priorities configured by the database)
Synchronization includes: historical, financial, real-time

Returns:
Dict:   FMT 0 
"""
        try:
            logger.info(f"[Data syncs]{stock_code}Data (History + Finance + Real Time)...")

            #Data source priorities from databases
            priority_order = self._get_data_source_priority_for_sync(stock_code)
            logger.info(f"Data source priorities:{priority_order}")

            #2. Attempt to synchronize according to priority
            last_error = None
            for data_source in priority_order:
                try:
                    logger.info(f"[Data Synchronization]{data_source}")

                    #BaoStock does not support single stock synchronization, skip
                    if data_source == "baostock":
                        logger.warning(f"BaoStock does not support single stock synchronization, skipping")
                        last_error = f"{data_source}: ä¸æ”¯æŒå•ä¸ªè‚¡ç¥¨åŒæ­¥"
                        continue

                    #Get the corresponding synchronized services from data sources
                    if data_source == "tushare":
                        from app.worker.tushare_sync_service import get_tushare_sync_service
                        service = await get_tushare_sync_service()
                    elif data_source == "akshare":
                        from app.worker.akshare_sync_service import get_akshare_sync_service
                        service = await get_akshare_sync_service()
                    else:
                        logger.warning(f"Data sources not supported:{data_source}")
                        continue

                    #Initialization Results Statistics
                    historical_records = 0
                    financial_synced = False
                    realtime_synced = False

                    #2.1 Synchronization of historical data
                    logger.info(f"Synchronize historical data...")
                    hist_result = await service.sync_historical_data(
                        symbols=[stock_code],
                        start_date=start_date,
                        end_date=end_date,
                        incremental=False  #Full Sync
                    )

                    if hist_result.get("success_count", 0) > 0:
                        historical_records = hist_result.get("total_records", 0)
                        logger.info(f"âœ… [DataSync] Historical data sync successfully:{historical_records}Article")
                    else:
                        errors = hist_result.get("errors", [])
                        error_msg = errors[0].get("error", "æœªçŸ¥é”™è¯¯") if errors else "åŒæ­¥å¤±è´¥"
                        logger.warning(f"[Data syncs]{error_msg}")

                    #2.2 Synchronization of financial data
                    logger.info(f"Synchronization of financial data...")
                    try:
                        fin_result = await service.sync_financial_data(
                            symbols=[stock_code],
                            limit=20  #Access to the latest 20 issues (approximately 5 years)
                        )

                        if fin_result.get("success_count", 0) > 0:
                            financial_synced = True
                            logger.info(f"[Data sync]")
                        else:
                            logger.warning(f"[Data sync]")
                    except Exception as e:
                        logger.warning(f"[Data Synchronization]{e}")

                    #2.3 Synchronization of real-time patterns
                    logger.info(f"[Data Synchronization]")
                    try:
                        #AKShare is better suited for real-time business for a single stock
                        if data_source == "tushare":
                            #Tushare's real-time line interface is limited, moving to AKShare
                            from app.worker.akshare_sync_service import get_akshare_sync_service
                            realtime_service = await get_akshare_sync_service()
                        else:
                            realtime_service = service

                        rt_result = await realtime_service.sync_realtime_quotes(
                            symbols=[stock_code],
                            force=True  #Enforcement, skip transaction time check
                        )

                        if rt_result.get("success_count", 0) > 0:
                            realtime_synced = True
                            logger.info(f"[Data Synchronization]")
                        else:
                            logger.warning(f"[Data Sync] Real-time line sync failed")
                    except Exception as e:
                        logger.warning(f"[Data syncs] Real-time line sync anomalies:{e}")

                    #Check sync results (at least historical data are successful)
                    if historical_records > 0:
                        message = f"ä½¿ç”¨{data_source}åŒæ­¥æˆåŠŸ: å†å²{historical_records}æ¡"
                        if financial_synced:
                            message += ", è´¢åŠ¡æ•°æ®âœ“"
                        if realtime_synced:
                            message += ", å®æ—¶è¡Œæƒ…âœ“"

                        logger.info(f"[Data Syncs]{message}")
                        return {
                            "success": True,
                            "message": message,
                            "synced_records": historical_records,
                            "data_source": data_source,
                            "historical_records": historical_records,
                            "financial_synced": financial_synced,
                            "realtime_synced": realtime_synced
                        }
                    else:
                        last_error = f"{data_source}: å†å²æ•°æ®åŒæ­¥å¤±è´¥"
                        logger.warning(f"[Data Syncs]{data_source}Synchronising failed: History data empty")
                        #Continue to try the next data source

                except Exception as e:
                    last_error = f"{data_source}: {str(e)}"
                    logger.warning(f"[Data Syncs]{data_source}Synchronization anomaly:{e}")
                    import traceback
                    logger.debug(f"Detailed error:{traceback.format_exc()}")
                    #Continue to try the next data source
                    continue

            #All data sources failed
            message = f"æ‰€æœ‰æ•°æ®æºåŒæ­¥å¤±è´¥ï¼Œæœ€åé”™è¯¯: {last_error}"
            logger.error(f"[Data Syncs]{message}")
            return {
                "success": False,
                "message": message,
                "synced_records": 0,
                "data_source": None,
                "historical_records": 0,
                "financial_synced": False,
                "realtime_synced": False
            }

        except Exception as e:
            logger.error(f"Synchronising data failed:{e}")
            import traceback
            logger.debug(f"Detailed error:{traceback.format_exc()}")
            return {
                "success": False,
                "message": f"åŒæ­¥å¤±è´¥: {str(e)}",
                "synced_records": 0,
                "data_source": None,
                "historical_records": 0,
                "financial_synced": False,
                "realtime_synced": False
            }

    def _get_data_source_priority_for_sync(self, stock_code: str) -> list:
        """Acquisition of data source priorities (for synchronization)

Returns:
list: list of data sources, in order of priority ['tushare', 'akshare', 'baostock']
"""
        try:
            from tradingagents.dataflows.cache.mongodb_cache_adapter import get_mongodb_cache_adapter

            adapter = get_mongodb_cache_adapter()
            if adapter.use_app_cache and adapter.db is not None:
                #Get priority with MongoDB adapter
                priority_order = adapter._get_data_source_priority(stock_code)
                logger.info(f"[Data source priority]{priority_order}")
                return priority_order
            else:
                logger.warning(f"MongoDB is not enabled, using default order")
                return ['tushare', 'akshare', 'baostock']

        except Exception as e:
            logger.error(f"[Data source priority]{e}")
            #Returns the default order
            return ['tushare', 'akshare', 'baostock']

    def _prepare_hk_stock_data(self, stock_code: str, period_days: int,
                              analysis_date: str) -> StockDataPreparationResult:
        """Advance access to port unit data"""
        logger.info(f"[Hong Kong Unit Data]{stock_code}Data (time:{period_days}Oh, my God.")

        #Standardized port unit code format
        if not stock_code.upper().endswith('.HK'):
            #Remove pilot 0 and complete it to four.
            clean_code = stock_code.lstrip('0') or '0'  #If it's all zeros, keep one zero.
            formatted_code = f"{clean_code.zfill(4)}.HK"
            logger.debug(f"[Hong Kong Unit Data]{stock_code} â†’ {formatted_code}")
        else:
            formatted_code = stock_code.upper()

        #Calculate Date Range
        end_date = datetime.strptime(analysis_date, '%Y-%m-%d')
        start_date = end_date - timedelta(days=period_days)
        start_date_str = start_date.strftime('%Y-%m-%d')
        end_date_str = end_date.strftime('%Y-%m-%d')

        logger.debug(f"[Port Unit data] Date range:{start_date_str} â†’ {end_date_str}")

        has_historical_data = False
        has_basic_info = False
        stock_name = "æœªçŸ¥"
        cache_status = ""

        try:
            #1. Access to basic information
            logger.debug(f"[Hong Kong Unit Data]{formatted_code}Basic information...")
            from tradingagents.dataflows.interface import get_hk_stock_info_unified

            stock_info = get_hk_stock_info_unified(formatted_code)

            if stock_info and "âŒ" not in stock_info and "æœªæ‰¾åˆ°" not in stock_info:
                #Parsing stock names - Supporting multiple formats
                stock_name = self._extract_hk_stock_name(stock_info, formatted_code)

                if stock_name and stock_name != "æœªçŸ¥":
                    has_basic_info = True
                    logger.info(f"[Hong Kong Unit Data]{formatted_code} - {stock_name}")
                    cache_status += "åŸºæœ¬ä¿¡æ¯å·²ç¼“å­˜; "
                else:
                    logger.warning(f"Basic information is invalid:{formatted_code}")
                    logger.debug(f"Information content:{stock_info[:200]}...")
                    return StockDataPreparationResult(
                        is_valid=False,
                        stock_code=formatted_code,
                        market_type="æ¸¯è‚¡",
                        error_message=f"æ¸¯è‚¡ä»£ç  {formatted_code} ä¸å­˜åœ¨æˆ–ä¿¡æ¯æ— æ•ˆ",
                        suggestion="è¯·æ£€æŸ¥æ¸¯è‚¡ä»£ç æ˜¯å¦æ­£ç¡®ï¼Œæ ¼å¼å¦‚ï¼š0700.HK"
                    )
            else:
                #Check for network restrictions
                network_error_indicators = [
                    "Too Many Requests", "Rate limited", "Connection aborted",
                    "Remote end closed connection", "ç½‘ç»œè¿æ¥", "è¶…æ—¶", "é™åˆ¶"
                ]

                is_network_issue = any(indicator in str(stock_info) for indicator in network_error_indicators)

                if is_network_issue:
                    logger.warning(f"The impact of network restrictions:{formatted_code}")
                    return StockDataPreparationResult(
                        is_valid=False,
                        stock_code=formatted_code,
                        market_type="æ¸¯è‚¡",
                        error_message=f"æ¸¯è‚¡æ•°æ®è·å–å—åˆ°ç½‘ç»œé™åˆ¶å½±å“",
                        suggestion=self._get_hk_network_limitation_suggestion()
                    )
                else:
                    logger.warning(f"Basic information is not available:{formatted_code}")
                    return StockDataPreparationResult(
                        is_valid=False,
                        stock_code=formatted_code,
                        market_type="æ¸¯è‚¡",
                        error_message=f"æ¸¯è‚¡ä»£ç  {formatted_code} å¯èƒ½ä¸å­˜åœ¨æˆ–æ•°æ®æºæš‚æ—¶ä¸å¯ç”¨",
                        suggestion="è¯·æ£€æŸ¥æ¸¯è‚¡ä»£ç æ˜¯å¦æ­£ç¡®ï¼Œæ ¼å¼å¦‚ï¼š0700.HKï¼Œæˆ–ç¨åé‡è¯•"
                    )

            #2. Access to historical data
            logger.debug(f"[Hong Kong Unit Data]{formatted_code}Historical Data ({start_date_str}Present.{end_date_str})...")
            from tradingagents.dataflows.interface import get_hk_stock_data_unified

            historical_data = get_hk_stock_data_unified(formatted_code, start_date_str, end_date_str)

            if historical_data and "âŒ" not in historical_data and "è·å–å¤±è´¥" not in historical_data:
                #More liberal data validity checks
                data_indicators = [
                    "å¼€ç›˜ä»·", "æ”¶ç›˜ä»·", "æœ€é«˜ä»·", "æœ€ä½ä»·", "æˆäº¤é‡",
                    "open", "close", "high", "low", "volume",
                    "æ—¥æœŸ", "date", "æ—¶é—´", "time"
                ]

                has_valid_data = (
                    len(historical_data) > 50 and  #Lower length requirement
                    any(indicator in historical_data for indicator in data_indicators)
                )

                if has_valid_data:
                    has_historical_data = True
                    logger.info(f"[Hong Kong Unit Data]{formatted_code} ({period_days}Oh, my God.")
                    cache_status += f"å†å²æ•°æ®å·²ç¼“å­˜({period_days}å¤©); "
                else:
                    logger.warning(f"[Hong Kong Unit Data]{formatted_code}")
                    logger.debug(f"Data content preview:{historical_data[:200]}...")
                    return StockDataPreparationResult(
                        is_valid=False,
                        stock_code=formatted_code,
                        market_type="æ¸¯è‚¡",
                        stock_name=stock_name,
                        has_basic_info=has_basic_info,
                        error_message=f"æ¸¯è‚¡ {formatted_code} çš„å†å²æ•°æ®æ— æ•ˆæˆ–ä¸è¶³",
                        suggestion="è¯¥è‚¡ç¥¨å¯èƒ½ä¸ºæ–°ä¸Šå¸‚è‚¡ç¥¨æˆ–æ•°æ®æºæš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
                    )
            else:
                #Check for network restrictions
                network_error_indicators = [
                    "Too Many Requests", "Rate limited", "Connection aborted",
                    "Remote end closed connection", "ç½‘ç»œè¿æ¥", "è¶…æ—¶", "é™åˆ¶"
                ]

                is_network_issue = any(indicator in str(historical_data) for indicator in network_error_indicators)

                if is_network_issue:
                    logger.warning(f"Access to historical data is restricted by the Internet:{formatted_code}")
                    return StockDataPreparationResult(
                        is_valid=False,
                        stock_code=formatted_code,
                        market_type="æ¸¯è‚¡",
                        stock_name=stock_name,
                        has_basic_info=has_basic_info,
                        error_message=f"æ¸¯è‚¡å†å²æ•°æ®è·å–å—åˆ°ç½‘ç»œé™åˆ¶å½±å“",
                        suggestion=self._get_hk_network_limitation_suggestion()
                    )
                else:
                    logger.warning(f"[Hong Kong Unit Data]{formatted_code}")
                    return StockDataPreparationResult(
                        is_valid=False,
                        stock_code=formatted_code,
                        market_type="æ¸¯è‚¡",
                        stock_name=stock_name,
                        has_basic_info=has_basic_info,
                        error_message=f"æ— æ³•è·å–æ¸¯è‚¡ {formatted_code} çš„å†å²æ•°æ®",
                        suggestion="æ•°æ®æºå¯èƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ"
                    )

            #3. Successful data preparation
            logger.info(f"The data are ready:{formatted_code} - {stock_name}")
            return StockDataPreparationResult(
                is_valid=True,
                stock_code=formatted_code,
                market_type="æ¸¯è‚¡",
                stock_name=stock_name,
                has_historical_data=has_historical_data,
                has_basic_info=has_basic_info,
                data_period_days=period_days,
                cache_status=cache_status.rstrip('; ')
            )

        except Exception as e:
            logger.error(f"Data preparation failed:{e}")
            return StockDataPreparationResult(
                is_valid=False,
                stock_code=formatted_code,
                market_type="æ¸¯è‚¡",
                stock_name=stock_name,
                has_basic_info=has_basic_info,
                has_historical_data=has_historical_data,
                error_message=f"æ•°æ®å‡†å¤‡å¤±è´¥: {str(e)}",
                suggestion="è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ•°æ®æºé…ç½®"
            )

    def _prepare_us_stock_data(self, stock_code: str, period_days: int,
                              analysis_date: str) -> StockDataPreparationResult:
        """Advance access to US stock data"""
        logger.info(f"Let's get ready.{stock_code}Data (time:{period_days}Oh, my God.")

        #Standardized USE code format
        formatted_code = stock_code.upper()

        #Calculate Date Range
        end_date = datetime.strptime(analysis_date, '%Y-%m-%d')
        start_date = end_date - timedelta(days=period_days)
        start_date_str = start_date.strftime('%Y-%m-%d')
        end_date_str = end_date.strftime('%Y-%m-%d')

        logger.debug(f"Date range:{start_date_str} â†’ {end_date_str}")

        has_historical_data = False
        has_basic_info = False
        stock_name = formatted_code  #The U.S. stock usually uses code as its name.
        cache_status = ""

        try:
            #1. Access to historical data (United States shares are usually directly validated through historical data)
            logger.debug(f"[United States data]{formatted_code}Historical Data ({start_date_str}Present.{end_date_str})...")

            #Import U.S. stock data provider (support for old and new paths)
            try:
                from tradingagents.dataflows.providers.us import OptimizedUSDataProvider
                provider = OptimizedUSDataProvider()
                historical_data = provider.get_stock_data(
                    formatted_code,
                    start_date_str,
                    end_date_str
                )
            except ImportError:
                from tradingagents.dataflows.providers.us.optimized import get_us_stock_data_cached
                historical_data = get_us_stock_data_cached(
                    formatted_code,
                    start_date_str,
                    end_date_str
                )

            if historical_data and "âŒ" not in historical_data and "é”™è¯¯" not in historical_data and "æ— æ³•è·å–" not in historical_data:
                #More liberal data validity checks
                data_indicators = [
                    "å¼€ç›˜ä»·", "æ”¶ç›˜ä»·", "æœ€é«˜ä»·", "æœ€ä½ä»·", "æˆäº¤é‡",
                    "Open", "Close", "High", "Low", "Volume",
                    "æ—¥æœŸ", "Date", "æ—¶é—´", "Time"
                ]

                has_valid_data = (
                    len(historical_data) > 50 and  #Lower length requirement
                    any(indicator in historical_data for indicator in data_indicators)
                )

                if has_valid_data:
                    has_historical_data = True
                    has_basic_info = True  #The U.S. stock usually doesn't get basic information alone.
                    logger.info(f"[United States stock data]{formatted_code} ({period_days}Oh, my God.")
                    cache_status = f"å†å²æ•°æ®å·²ç¼“å­˜({period_days}å¤©)"

                    #Data ready.
                    logger.info(f"Data ready:{formatted_code}")
                    return StockDataPreparationResult(
                        is_valid=True,
                        stock_code=formatted_code,
                        market_type="ç¾è‚¡",
                        stock_name=stock_name,
                        has_historical_data=has_historical_data,
                        has_basic_info=has_basic_info,
                        data_period_days=period_days,
                        cache_status=cache_status
                    )
                else:
                    logger.warning(f"[United States equity data]{formatted_code}")
                    logger.debug(f"Data content preview:{historical_data[:200]}...")
                    return StockDataPreparationResult(
                        is_valid=False,
                        stock_code=formatted_code,
                        market_type="ç¾è‚¡",
                        error_message=f"ç¾è‚¡ {formatted_code} çš„å†å²æ•°æ®æ— æ•ˆæˆ–ä¸è¶³",
                        suggestion="è¯¥è‚¡ç¥¨å¯èƒ½ä¸ºæ–°ä¸Šå¸‚è‚¡ç¥¨æˆ–æ•°æ®æºæš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
                    )
            else:
                logger.warning(f"No historical data can be obtained:{formatted_code}")
                return StockDataPreparationResult(
                    is_valid=False,
                    stock_code=formatted_code,
                    market_type="ç¾è‚¡",
                    error_message=f"ç¾è‚¡ä»£ç  {formatted_code} ä¸å­˜åœ¨æˆ–æ— æ³•è·å–æ•°æ®",
                    suggestion="è¯·æ£€æŸ¥ç¾è‚¡ä»£ç æ˜¯å¦æ­£ç¡®ï¼Œå¦‚ï¼šAAPLã€TSLAã€MSFT"
                )

        except Exception as e:
            logger.error(f"Data preparation failed:{e}")
            return StockDataPreparationResult(
                is_valid=False,
                stock_code=formatted_code,
                market_type="ç¾è‚¡",
                error_message=f"æ•°æ®å‡†å¤‡å¤±è´¥: {str(e)}",
                suggestion="è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ•°æ®æºé…ç½®"
            )




#Examples of global data preparation
_stock_preparer = None

def get_stock_preparer(default_period_days: int = 30) -> StockDataPreparer:
    """Examples of stock acquisition data preparation (single mode)"""
    global _stock_preparer
    if _stock_preparer is None:
        _stock_preparer = StockDataPreparer(default_period_days)
    return _stock_preparer


def prepare_stock_data(stock_code: str, market_type: str = "auto",
                      period_days: int = None, analysis_date: str = None) -> StockDataPreparationResult:
    """Easy function: Pre-acquisition and validation of stock data

Args:
Stock code: Stock code
Market type: Market type ("A" equity, "Hong Kong equity", "Auto")
period days: length of historical data (days), default 30 days
Analysis date: date analysed, default today

Returns:
StockDataPreparationResult: Data Preparation Results
"""
    preparer = get_stock_preparer()
    return preparer.prepare_stock_data(stock_code, market_type, period_days, analysis_date)


def is_stock_data_ready(stock_code: str, market_type: str = "auto",
                       period_days: int = None, analysis_date: str = None) -> bool:
    """Easy function: Check for stock data readiness

Args:
Stock code: Stock code
Market type: Market type ("A" equity, "Hong Kong equity", "Auto")
period days: length of historical data (days), default 30 days
Analysis date: date analysed, default today

Returns:
Bool: Data ready
"""
    result = prepare_stock_data(stock_code, market_type, period_days, analysis_date)
    return result.is_valid


def get_stock_preparation_message(stock_code: str, market_type: str = "auto",
                                 period_days: int = None, analysis_date: str = None) -> str:
    """Easy function: Get stock data ready messages

Args:
Stock code: Stock code
Market type: Market type ("A" equity, "Hong Kong equity", "Auto")
period days: length of historical data (days), default 30 days
Analysis date: date analysed, default today

Returns:
str: Data Preparation Message
"""
    result = prepare_stock_data(stock_code, market_type, period_days, analysis_date)

    if result.is_valid:
        return f"âœ… æ•°æ®å‡†å¤‡æˆåŠŸ: {result.stock_code} ({result.market_type}) - {result.stock_name}\nğŸ“Š {result.cache_status}"
    else:
        return f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {result.error_message}\nğŸ’¡ å»ºè®®: {result.suggestion}"


async def prepare_stock_data_async(stock_code: str, market_type: str = "auto",
                                   period_days: int = None, analysis_date: str = None) -> StockDataPreparationResult:
    """Offset: pre-acquisition and validation of stock data

 is dedicated to the FastAPI rectangular context to avoid a cycle of incident conflict

Args:
Stock code: Stock code
Market type: Market type ("A" equity, "Hong Kong equity", "Auto")
period days: length of historical data (days), default 30 days
Analysis date: date analysed, default today

Returns:
StockDataPreparationResult: Data Preparation Results
"""
    preparer = get_stock_preparer()

    #Use an in-house method using a different version
    if period_days is None:
        period_days = preparer.default_period_days

    if analysis_date is None:
        from datetime import datetime
        analysis_date = datetime.now().strftime('%Y-%m-%d')

    logger.info(f"[Data Preparation-Step ] Start preparing stock data:{stock_code}(Market:{market_type}, duration:{period_days}Oh, my God.")

    #1. Basic format validation (synchronous operations)
    format_result = preparer._validate_format(stock_code, market_type)
    if not format_result.is_valid:
        return format_result

    #2. Automatic detection of market types
    if market_type == "auto":
        market_type = preparer._detect_market_type(stock_code)
        logger.debug(f"ğŸ“Š [Data Preparation - Step ] Automatic detection of market types:{market_type}")

    #3. Pre-acquire data and validate them (using a walker version)
    return await preparer._prepare_data_by_market_async(stock_code, market_type, period_days, analysis_date)


#Keep a backward compatible alias
StockValidator = StockDataPreparer
get_stock_validator = get_stock_preparer
validate_stock_exists = prepare_stock_data
is_stock_valid = is_stock_data_ready
get_stock_validation_message = get_stock_preparation_message
