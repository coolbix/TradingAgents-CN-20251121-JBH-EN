#!/usr/bin/env python3
"""Optimized data acquisition tool for Unit A
Integrated cache strategy and Tushare data interface to improve data acquisition efficiency
"""

import os
import time
import random
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

from typing import Optional, Dict, Any
from .cache import get_cache
from tradingagents.config.config_manager import config_manager

from tradingagents.config.runtime_settings import get_float, get_timezone_name
#Import Log Module
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('agents')

#Import MongoDB cache adapter
from .cache.mongodb_cache_adapter import get_mongodb_cache_adapter, get_stock_data_with_fallback, get_financial_data_with_fallback


class OptimizedChinaDataProvider:
    """Optimized A unit data provider - integrated cache and Tushare data interface"""

    def __init__(self):
        self.cache = get_cache()
        self.config = config_manager.load_settings()
        self.last_api_call = 0
        self.min_api_interval = get_float("TA_CHINA_MIN_API_INTERVAL_SECONDS", "ta_china_min_api_interval_seconds", 0.5)

        logger.info(f"Optimizing the initialization of the data provider for Unit A")

    def _wait_for_rate_limit(self):
        """Waiting for API Limit"""
        current_time = time.time()
        time_since_last_call = current_time - self.last_api_call

        if time_since_last_call < self.min_api_interval:
            wait_time = self.min_api_interval - time_since_last_call
            time.sleep(wait_time)

        self.last_api_call = time.time()

    def _format_financial_data_to_fundamentals(self, financial_data: Dict[str, Any], symbol: str) -> str:
        """Convert MongoDB financial data into basic face analysis format"""
        try:
            #Extracting key financial indicators
            revenue = financial_data.get('total_revenue', 'N/A')
            net_profit = financial_data.get('net_profit', 'N/A')
            total_assets = financial_data.get('total_assets', 'N/A')
            total_equity = financial_data.get('total_equity', 'N/A')
            report_period = financial_data.get('report_period', 'N/A')

            #Formatting value (add thousands if numbers, otherwise show original values)
            def format_number(value):
                if isinstance(value, (int, float)):
                    return f"{value:,.2f}"
                return str(value)

            revenue_str = format_number(revenue)
            net_profit_str = format_number(net_profit)
            total_assets_str = format_number(total_assets)
            total_equity_str = format_number(total_equity)

            #Calculation of financial ratios
            roe = 'N/A'
            if isinstance(net_profit, (int, float)) and isinstance(total_equity, (int, float)) and total_equity != 0:
                roe = f"{(net_profit / total_equity * 100):.2f}%"

            roa = 'N/A'
            if isinstance(net_profit, (int, float)) and isinstance(total_assets, (int, float)) and total_assets != 0:
                roa = f"{(net_profit / total_assets * 100):.2f}%"

            #Format Output
            fundamentals_report = f"""
# {symbol} Âü∫Êú¨Èù¢Êï∞ÊçÆÂàÜÊûê

## üìä Ë¥¢Âä°Ê¶ÇÂÜµ
- **Êä•ÂëäÊúü**: {report_period}
- **Ëê•‰∏öÊî∂ÂÖ•**: {revenue_str} ÂÖÉ
- **ÂáÄÂà©Ê∂¶**: {net_profit_str} ÂÖÉ
- **ÊÄªËµÑ‰∫ß**: {total_assets_str} ÂÖÉ
- **ËÇ°‰∏úÊùÉÁõä**: {total_equity_str} ÂÖÉ

## üìà Ë¥¢Âä°ÊØîÁéá
- **ÂáÄËµÑ‰∫ßÊî∂ÁõäÁéá(ROE)**: {roe}
- **ÊÄªËµÑ‰∫ßÊî∂ÁõäÁéá(ROA)**: {roa}

## üìù Êï∞ÊçÆËØ¥Êòé
- Êï∞ÊçÆÊù•Ê∫ê: MongoDBË¥¢Âä°Êï∞ÊçÆÂ∫ì
- Êõ¥Êñ∞Êó∂Èó¥: {datetime.now(ZoneInfo(get_timezone_name())).strftime('%Y-%m-%d %H:%M:%S')}
- Êï∞ÊçÆÁ±ªÂûã: ÂêåÊ≠•Ë¥¢Âä°Êï∞ÊçÆ
"""
            return fundamentals_report.strip()

        except Exception as e:
            logger.warning(f"Financial data formatted failed:{e}")
            return f"# {symbol} Âü∫Êú¨Èù¢Êï∞ÊçÆ\n\n‚ùå Êï∞ÊçÆÊ†ºÂºèÂåñÂ§±Ë¥•: {str(e)}"

    def get_stock_data(self, symbol: str, start_date: str, end_date: str,
                      force_refresh: bool = False) -> str:
        """Get A-unit data - Prioritize Cache

Args:
symbol: stock code (6-digit)
Start date: Start date (YYYYY-MM-DD)
End date: End Date (YYYYY-MM-DD)
source refresh: whether to forcibly refresh the cache

Returns:
Formatted stock data string
"""
        logger.info(f"For unit A data:{symbol} ({start_date}Present.{end_date})")

        #1. Preferably try to get it from MongoDB (if TA USE APP CACHE is enabled)
        if not force_refresh:
            adapter = get_mongodb_cache_adapter()
            if adapter.use_app_cache:
                df = adapter.get_historical_data(symbol, start_date, end_date)
                if df is not None and not df.empty:
                    logger.info(f"[Data source: MongoDB]{symbol} ({len(df)}(on file)")
                    return df.to_string()

        #2. Check file caches (unless mandatory updating)
        if not force_refresh:
            cache_key = self.cache.find_cached_stock_data(
                symbol=symbol,
                start_date=start_date,
                end_date=end_date,
                data_source="unified"  #Harmonization of data sources (Tushare/AKshare/BaoStock)
            )

            if cache_key:
                cached_data = self.cache.load_stock_data(cache_key)
                if cached_data:
                    logger.info(f"‚ö° [Data Source: File Cache] Loads Unit A data from the cache:{symbol}")
                    return cached_data

        #Cache pending, retrieve from UDI
        logger.info(f"üåê [Data source: API call]{symbol}")

        try:
            #API restricted processing
            self._wait_for_rate_limit()

            #Call the unified data source interface (default Tushare to support backup data sources)
            from .data_source_manager import get_china_stock_data_unified

            formatted_data = get_china_stock_data_unified(
                symbol=symbol,
                start_date=start_date,
                end_date=end_date
            )

            #Check for success
            if "‚ùå" in formatted_data or "ÈîôËØØ" in formatted_data:
                logger.error(f"Data source API call failed:{symbol}")
                #Try fetching data from old caches
                old_cache = self._try_get_old_cache(symbol, start_date, end_date)
                if old_cache:
                    logger.info(f"[Data source: expired cache]{symbol}")
                    return old_cache

                #Generate backup data
                logger.warning(f"‚ö†Ô∏è [data source: backup data] Generate secondary data:{symbol}")
                return self._generate_fallback_data(symbol, start_date, end_date, "Êï∞ÊçÆÊ∫êAPIË∞ÉÁî®Â§±Ë¥•")

            #Save to Cache
            self.cache.save_stock_data(
                symbol=symbol,
                data=formatted_data,
                start_date=start_date,
                end_date=end_date,
                data_source="unified"  #Use of harmonized data source identifiers
            )

            logger.info(f"‚úÖ [Data source: API call successfully] Unit A data acquisition success:{symbol}")
            return formatted_data

        except Exception as e:
            error_msg = f"TushareÊï∞ÊçÆÊé•Âè£Ë∞ÉÁî®ÂºÇÂ∏∏: {str(e)}"
            logger.error(f"‚ùå {error_msg}")

            #Try fetching data from old caches
            old_cache = self._try_get_old_cache(symbol, start_date, end_date)
            if old_cache:
                logger.info(f"Use of expired cache data:{symbol}")
                return old_cache

            #Generate backup data
            return self._generate_fallback_data(symbol, start_date, end_date, error_msg)

    def get_fundamentals_data(self, symbol: str, force_refresh: bool = False) -> str:
        """Get A Basic Data - Prioritize Cache

Args:
symbol: stock code
source refresh: whether to forcibly refresh the cache

Returns:
Formatting Basic Data Strings
"""
        logger.info(f"For basic data on Unit A:{symbol}")

        #1. Prioritize attempts to obtain financial data from MongoDB (if TA USE APP CACHE is enabled)
        if not force_refresh:
            adapter = get_mongodb_cache_adapter()
            if adapter.use_app_cache:
                financial_data = adapter.get_financial_data(symbol)
                if financial_data:
                    logger.info(f"Using MongoDB financial data:{symbol}")
                    #Conversion of financial data into basic face analysis format
                    return self._format_financial_data_to_fundamentals(financial_data, symbol)

        #2. Check file caches (unless mandatory updating)
        if not force_refresh:
            #Find Basic Data Cache
            for metadata_file in self.cache.metadata_dir.glob(f"*_meta.json"):
                try:
                    import json
                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)

                    if (metadata.get('symbol') == symbol and
                        metadata.get('data_type') == 'fundamentals' and
                        metadata.get('market_type') == 'china'):

                        cache_key = metadata_file.stem.replace('_meta', '')
                        if self.cache.is_cache_valid(cache_key, symbol=symbol, data_type='fundamentals'):
                            cached_data = self.cache.load_stock_data(cache_key)
                            if cached_data:
                                logger.info(f"‚ö° [Data Source: File Cache] Loads Basic A Stock Data from Cache:{symbol}")
                                return cached_data
                except Exception:
                    continue

        #Cache uncut, generate basic face analysis
        logger.debug(f"üîç [Data Source: Generating Analysis] Generating Basic Analysis of Unit A:{symbol}")

        try:
            #Basic analysis only requires basic information, not complete historical transaction data
            #Access to basic stock information (name of company, current price, etc.)
            stock_basic_info = self._get_stock_basic_info_only(symbol)

            #Generate basic analysis reports
            fundamentals_data = self._generate_fundamentals_report(symbol, stock_basic_info)

            #Save to Cache
            self.cache.save_fundamentals_data(
                symbol=symbol,
                fundamentals_data=fundamentals_data,
                data_source="unified_analysis"  #Harmonization of data source analysis
            )

            logger.info(f"‚úÖ [Data Source: Generating Analysis Success] Unit A fundamental data generation success:{symbol}")
            return fundamentals_data

        except Exception as e:
            error_msg = f"Âü∫Êú¨Èù¢Êï∞ÊçÆÁîüÊàêÂ§±Ë¥•: {str(e)}"
            logger.error(f"‚ùå{error_msg}")
            logger.warning(f"‚ö†Ô∏è [Data source: backup data] Generate secondary base data:{symbol}")
            return self._generate_fallback_fundamentals(symbol, error_msg)

    def _get_stock_basic_info_only(self, symbol: str) -> str:
        """Access to basic stock information (for basic face analysis only)
No historical transaction data obtained, only basic information such as company name, current price, etc.
"""
        logger.debug(f" [basic optimization]{symbol}Basic information (excluding historical data)")

        try:
            #Obtain basic stock information from a unified interface
            from .interface import get_china_stock_info_unified
            stock_info = get_china_stock_info_unified(symbol)

            #If successful, directly return basic information
            if stock_info and "ËÇ°Á•®ÂêçÁß∞:" in stock_info:
                logger.debug(f"üìä [BASIC PERFECT]{symbol}Basic information, without historical data")
                return stock_info

            #If access to basic information fails, try to obtain the most basic information from the cache
            try:
                from tradingagents.config.runtime_settings import use_app_cache_enabled
                if use_app_cache_enabled(False):
                    from .cache.app_adapter import get_market_quote_dataframe
                    df_q = get_market_quote_dataframe(symbol)
                    if df_q is not None and not df_q.empty:
                        row_q = df_q.iloc[-1]
                        current_price = str(row_q.get('close', 'N/A'))
                        change_pct = f"{float(row_q.get('pct_chg', 0)):+.2f}%" if row_q.get('pct_chg') is not None else 'N/A'
                        volume = str(row_q.get('volume', 'N/A'))

                        #Construct Basic Information Format
                        basic_info = f"""ËÇ°Á•®‰ª£Á†Å: {symbol}
ËÇ°Á•®ÂêçÁß∞: Êú™Áü•ÂÖ¨Âè∏
ÂΩìÂâç‰ª∑Ê†º: {current_price}
Ê∂®Ë∑åÂπÖ: {change_pct}
Êàê‰∫§Èáè: {volume}"""
                        logger.debug(f"üìä [Basic Surface Optimization] from Cache Construction{symbol}Basic information")
                        return basic_info
            except Exception as e:
                logger.debug(f"üìä [basic optimization] Failed to access basic information from cache:{e}")

            #If you fail, return the most basic information.
            return f"ËÇ°Á•®‰ª£Á†Å: {symbol}\nËÇ°Á•®ÂêçÁß∞: Êú™Áü•ÂÖ¨Âè∏\nÂΩìÂâç‰ª∑Ê†º: N/A\nÊ∂®Ë∑åÂπÖ: N/A\nÊàê‰∫§Èáè: N/A"

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [basic optimization]{symbol}Could not close temporary folder: %s{e}")
            return f"ËÇ°Á•®‰ª£Á†Å: {symbol}\nËÇ°Á•®ÂêçÁß∞: Êú™Áü•ÂÖ¨Âè∏\nÂΩìÂâç‰ª∑Ê†º: N/A\nÊ∂®Ë∑åÂπÖ: N/A\nÊàê‰∫§Èáè: N/A"

    def _generate_fundamentals_report(self, symbol: str, stock_data: str, analysis_modules: str = "standard") -> str:
        """Generate real fundamental analysis based on equity data

Args:
symbol: stock code
Stock data: Stock data
Analysis modules: Analysis module level
"""

        #Add detailed stock code tracking log
        logger.debug(f"üîç [Securities Code Tracking]  generate fundamentals report received stock codes: '{symbol}' (type:{type(symbol)})")
        logger.debug(f"[Equal code tracking]{len(str(symbol))}")
        logger.debug(f"[Equal code tracking]{list(str(symbol))}")
        logger.debug(f"[Equal code tracking]{stock_data[:200] if stock_data else 'None'}")

        #Extracting information from stock data
        company_name = "Êú™Áü•ÂÖ¨Âè∏"
        current_price = "N/A"
        volume = "N/A"
        change_pct = "N/A"

        #First try to get basic stock information from a unified interface
        try:
            logger.debug(f"[Equal code tracking]{symbol}Basic information...")
            from .interface import get_china_stock_info_unified
            stock_info = get_china_stock_info_unified(symbol)
            logger.debug(f"[Equal code tracking]{stock_info}")

            if "ËÇ°Á•®ÂêçÁß∞:" in stock_info:
                lines = stock_info.split('\n')
                for line in lines:
                    if "ËÇ°Á•®ÂêçÁß∞:" in line:
                        company_name = line.split(':')[1].strip()
                        logger.debug(f"[Equal code tracking]{company_name}")
                        break
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è failed to access basic stock information:{e}")

        #If the current price/fall/offset is still missing and the app cache is enabled, read the market quotes pocket
        try:
            if (current_price == "N/A" or change_pct == "N/A" or volume == "N/A"):
                from tradingagents.config.runtime_settings import use_app_cache_enabled  # type: ignore
                if use_app_cache_enabled(False):
                    from .cache.app_adapter import get_market_quote_dataframe
                    df_q = get_market_quote_dataframe(symbol)
                    if df_q is not None and not df_q.empty:
                        row_q = df_q.iloc[-1]
                        if current_price == "N/A" and row_q.get('close') is not None:
                            current_price = str(row_q.get('close'))
                            logger.debug(f"[Equal code tracking]{current_price}")
                        if change_pct == "N/A" and row_q.get('pct_chg') is not None:
                            try:
                                change_pct = f"{float(row_q.get('pct_chg')):+.2f}%"
                            except Exception:
                                change_pct = str(row_q.get('pct_chg'))
                            logger.debug(f"[Equal code tracking]{change_pct}")
                        if volume == "N/A" and row_q.get('volume') is not None:
                            volume = str(row_q.get('volume'))
                            logger.debug(f"[Share code tracking]{volume}")
        except Exception as _qe:
            logger.debug(f"üîç [Securities Code Tracks] Reading market quotes failed (negative):{_qe}")

        #And then extract price information from stock data.
        if "ËÇ°Á•®ÂêçÁß∞:" in stock_data:
            lines = stock_data.split('\n')
            for line in lines:
                if "ËÇ°Á•®ÂêçÁß∞:" in line and company_name == "Êú™Áü•ÂÖ¨Âè∏":
                    company_name = line.split(':')[1].strip()
                elif "ÂΩìÂâç‰ª∑Ê†º:" in line:
                    current_price = line.split(':')[1].strip()
                elif "ÊúÄÊñ∞‰ª∑Ê†º:" in line or "üí∞ ÊúÄÊñ∞‰ª∑Ê†º:" in line:
                    #Compatible with another template output
                    try:
                        current_price = line.split(':', 1)[1].strip().lstrip('¬•').strip()
                    except Exception:
                        current_price = line.split(':')[-1].strip()
                elif "Ê∂®Ë∑åÂπÖ:" in line:
                    change_pct = line.split(':')[1].strip()
                elif "Êàê‰∫§Èáè:" in line:
                    volume = line.split(':')[1].strip()

        #Try to extract up-to-date price information from stock data tables
        if current_price == "N/A" and stock_data:
            try:
                lines = stock_data.split('\n')
                for i, line in enumerate(lines):
                    if "ÊúÄÊñ∞Êï∞ÊçÆ:" in line and i + 1 < len(lines):
                        #Find Data Lines
                        for j in range(i + 1, min(i + 5, len(lines))):
                            data_line = lines[j].strip()
                            if data_line and not data_line.startswith('Êó•Êúü') and not data_line.startswith('-'):
                                #Try parsing data lines
                                parts = data_line.split()
                                if len(parts) >= 4:
                                    try:
                                        #Assumptions format: Date, stock code, opening, closing, highest, lowest exchange, turnover...
                                        current_price = parts[3]  #Discount price
                                        logger.debug(f"[Equal code tracking]{current_price}")
                                        break
                                    except (IndexError, ValueError):
                                        continue
                        break
            except Exception as e:
                logger.debug(f"[Equal code tracking]{e}")

        #Profession and basic information based on stock code
        logger.debug(f"[Securities code tracking]{symbol}'")
        industry_info = self._get_industry_info(symbol)
        logger.debug(f"Get industry info returns:{industry_info}")

        #Try to obtain financial indicators and return the simplified basic report if it fails
        logger.debug(f"[Securities Code Tracking]{symbol}'")
        try:
            financial_estimates = self._estimate_financial_metrics(symbol, current_price)
            logger.debug(f"[Stock code tracking]{financial_estimates}")
        except Exception as e:
            logger.warning(f"Financial indicators are not available:{e}")
            logger.info(f"üìä [basic analysis] returns the simplified basic report (no financial indicators)")

            #Returns simplified base reports (excluding financial indicators)
            simplified_report = f"""# ‰∏≠ÂõΩAËÇ°Âü∫Êú¨Èù¢ÂàÜÊûêÊä•Âëä - {symbol} (ÁÆÄÂåñÁâà)

## üìä Âü∫Êú¨‰ø°ÊÅØ
- **ËÇ°Á•®‰ª£Á†Å**: {symbol}
- **ÂÖ¨Âè∏ÂêçÁß∞**: {company_name}
- **ÊâÄÂ±ûË°å‰∏ö**: {industry_info.get('industry', 'Êú™Áü•')}
- **ÂΩìÂâç‰ª∑Ê†º**: {current_price}
- **Ê∂®Ë∑åÂπÖ**: {change_pct}
- **Êàê‰∫§Èáè**: {volume}

## üìà Ë°å‰∏öÂàÜÊûê
{industry_info.get('analysis', 'ÊöÇÊó†Ë°å‰∏öÂàÜÊûê')}

## ‚ö†Ô∏è Êï∞ÊçÆËØ¥Êòé
Áî±‰∫éÊó†Ê≥ïËé∑ÂèñÂÆåÊï¥ÁöÑË¥¢Âä°Êï∞ÊçÆÔºåÊú¨Êä•Âëä‰ªÖÂåÖÂê´Âü∫Êú¨‰ª∑Ê†º‰ø°ÊÅØÂíåË°å‰∏öÂàÜÊûê„ÄÇ
Âª∫ËÆÆÔºö
1. Êü•ÁúãÂÖ¨Âè∏ÊúÄÊñ∞Ë¥¢Êä•Ëé∑ÂèñËØ¶ÁªÜË¥¢Âä°Êï∞ÊçÆ
2. ÂÖ≥Ê≥®Ë°å‰∏öÊï¥‰ΩìËµ∞Âäø
3. ÁªìÂêàÊäÄÊúØÂàÜÊûêËøõË°åÁªºÂêàÂà§Êñ≠

---
**ÁîüÊàêÊó∂Èó¥**: {datetime.now(ZoneInfo(get_timezone_name())).strftime('%Y-%m-%d %H:%M:%S')}
**Êï∞ÊçÆÊù•Ê∫ê**: Âü∫Á°ÄÂ∏ÇÂú∫Êï∞ÊçÆ
"""
            return simplified_report.strip()

        logger.debug(f"[Equal code tracking]{symbol}'")

        #Check data sources and generate instructions
        data_source_note = ""
        data_source = financial_estimates.get('data_source', '')

        if any("Ôºà‰º∞ÁÆóÂÄºÔºâ" in str(v) for v in financial_estimates.values() if isinstance(v, str)):
            data_source_note = "\n‚ö†Ô∏è **Êï∞ÊçÆËØ¥Êòé**: ÈÉ®ÂàÜË¥¢Âä°ÊåáÊ†á‰∏∫‰º∞ÁÆóÂÄºÔºåÂª∫ËÆÆÁªìÂêàÊúÄÊñ∞Ë¥¢Êä•Êï∞ÊçÆËøõË°åÂàÜÊûê"
        elif data_source == "AKShare":
            data_source_note = "\n‚úÖ **Êï∞ÊçÆËØ¥Êòé**: Ë¥¢Âä°ÊåáÊ†áÂü∫‰∫éAKShareÁúüÂÆûË¥¢Âä°Êï∞ÊçÆËÆ°ÁÆó"
        elif data_source == "Tushare":
            data_source_note = "\n‚úÖ **Êï∞ÊçÆËØ¥Êòé**: Ë¥¢Âä°ÊåáÊ†áÂü∫‰∫éTushareÁúüÂÆûË¥¢Âä°Êï∞ÊçÆËÆ°ÁÆó"
        else:
            data_source_note = "\n‚úÖ **Êï∞ÊçÆËØ¥Êòé**: Ë¥¢Âä°ÊåáÊ†áÂü∫‰∫éÁúüÂÆûË¥¢Âä°Êï∞ÊçÆËÆ°ÁÆó"

        #Align the content of the report to the analytical module level
        logger.debug(f"Use of analytical module levels:{analysis_modules}")
        
        if analysis_modules == "basic":
            #Foundation model: core financial indicators only
            report = f"""# ‰∏≠ÂõΩAËÇ°Âü∫Êú¨Èù¢ÂàÜÊûêÊä•Âëä - {symbol} (Âü∫Á°ÄÁâà)

## üìä ËÇ°Á•®Âü∫Êú¨‰ø°ÊÅØ
- **ËÇ°Á•®‰ª£Á†Å**: {symbol}
- **ËÇ°Á•®ÂêçÁß∞**: {company_name}
- **ÂΩìÂâçËÇ°‰ª∑**: {current_price}
- **Ê∂®Ë∑åÂπÖ**: {change_pct}
- **ÂàÜÊûêÊó•Êúü**: {datetime.now(ZoneInfo(get_timezone_name())).strftime('%YÂπ¥%mÊúà%dÊó•')}{data_source_note}

## üí∞ Ê†∏ÂøÉË¥¢Âä°ÊåáÊ†á
- **ÊÄªÂ∏ÇÂÄº**: {financial_estimates.get('total_mv', 'N/A')}
- **Â∏ÇÁõàÁéá(PE)**: {financial_estimates.get('pe', 'N/A')}
- **Â∏ÇÁõàÁéáTTM(PE_TTM)**: {financial_estimates.get('pe_ttm', 'N/A')}
- **Â∏ÇÂáÄÁéá(PB)**: {financial_estimates.get('pb', 'N/A')}
- **ÂáÄËµÑ‰∫ßÊî∂ÁõäÁéá(ROE)**: {financial_estimates.get('roe', 'N/A')}
- **ËµÑ‰∫ßË¥üÂÄ∫Áéá**: {financial_estimates.get('debt_ratio', 'N/A')}

## üí° Âü∫Á°ÄËØÑ‰º∞
- **Âü∫Êú¨Èù¢ËØÑÂàÜ**: {financial_estimates['fundamental_score']}/10
- **È£éÈô©Á≠âÁ∫ß**: {financial_estimates['risk_level']}

---
**ÈáçË¶ÅÂ£∞Êòé**: Êú¨Êä•ÂëäÂü∫‰∫éÂÖ¨ÂºÄÊï∞ÊçÆÂíåÊ®°Âûã‰º∞ÁÆóÁîüÊàêÔºå‰ªÖ‰æõÂèÇËÄÉÔºå‰∏çÊûÑÊàêÊäïËµÑÂª∫ËÆÆ„ÄÇ
**Êï∞ÊçÆÊù•Ê∫ê**: {data_source if data_source else "Â§öÊ∫êÊï∞ÊçÆ"}Êï∞ÊçÆÊé•Âè£
**ÁîüÊàêÊó∂Èó¥**: {datetime.now(ZoneInfo(get_timezone_name())).strftime('%Y-%m-%d %H:%M:%S')}
"""
        elif analysis_modules in ["standard", "full"]:
            #Standard/complete model: including detailed analysis
            report = f"""# ‰∏≠ÂõΩAËÇ°Âü∫Êú¨Èù¢ÂàÜÊûêÊä•Âëä - {symbol}

## üìä ËÇ°Á•®Âü∫Êú¨‰ø°ÊÅØ
- **ËÇ°Á•®‰ª£Á†Å**: {symbol}
- **ËÇ°Á•®ÂêçÁß∞**: {company_name}
- **ÊâÄÂ±ûË°å‰∏ö**: {industry_info['industry']}
- **Â∏ÇÂú∫ÊùøÂùó**: {industry_info['market']}
- **ÂΩìÂâçËÇ°‰ª∑**: {current_price}
- **Ê∂®Ë∑åÂπÖ**: {change_pct}
- **Êàê‰∫§Èáè**: {volume}
- **ÂàÜÊûêÊó•Êúü**: {datetime.now(ZoneInfo(get_timezone_name())).strftime('%YÂπ¥%mÊúà%dÊó•')}{data_source_note}

## üí∞ Ë¥¢Âä°Êï∞ÊçÆÂàÜÊûê

### ‰º∞ÂÄºÊåáÊ†á
- **ÊÄªÂ∏ÇÂÄº**: {financial_estimates.get('total_mv', 'N/A')}
- **Â∏ÇÁõàÁéá(PE)**: {financial_estimates.get('pe', 'N/A')}
- **Â∏ÇÁõàÁéáTTM(PE_TTM)**: {financial_estimates.get('pe_ttm', 'N/A')}
- **Â∏ÇÂáÄÁéá(PB)**: {financial_estimates.get('pb', 'N/A')}
- **Â∏ÇÈîÄÁéá(PS)**: {financial_estimates.get('ps', 'N/A')}
- **ËÇ°ÊÅØÊî∂ÁõäÁéá**: {financial_estimates.get('dividend_yield', 'N/A')}

### ÁõàÂà©ËÉΩÂäõÊåáÊ†á
- **ÂáÄËµÑ‰∫ßÊî∂ÁõäÁéá(ROE)**: {financial_estimates['roe']}
- **ÊÄªËµÑ‰∫ßÊî∂ÁõäÁéá(ROA)**: {financial_estimates['roa']}
- **ÊØõÂà©Áéá**: {financial_estimates['gross_margin']}
- **ÂáÄÂà©Áéá**: {financial_estimates['net_margin']}

### Ë¥¢Âä°ÂÅ•Â∫∑Â∫¶
- **ËµÑ‰∫ßË¥üÂÄ∫Áéá**: {financial_estimates['debt_ratio']}
- **ÊµÅÂä®ÊØîÁéá**: {financial_estimates['current_ratio']}
- **ÈÄüÂä®ÊØîÁéá**: {financial_estimates['quick_ratio']}
- **Áé∞ÈáëÊØîÁéá**: {financial_estimates['cash_ratio']}

## üìà Ë°å‰∏öÂàÜÊûê
{industry_info['analysis']}

## üéØ ÊäïËµÑ‰ª∑ÂÄºËØÑ‰º∞
### ‰º∞ÂÄºÊ∞¥Âπ≥ÂàÜÊûê
{self._analyze_valuation(financial_estimates)}

### ÊàêÈïøÊÄßÂàÜÊûê
{self._analyze_growth_potential(symbol, industry_info)}

## üí° ÊäïËµÑÂª∫ËÆÆ
- **Âü∫Êú¨Èù¢ËØÑÂàÜ**: {financial_estimates['fundamental_score']}/10
- **‰º∞ÂÄºÂê∏ÂºïÂäõ**: {financial_estimates['valuation_score']}/10
- **ÊàêÈïøÊΩúÂäõ**: {financial_estimates['growth_score']}/10
- **È£éÈô©Á≠âÁ∫ß**: {financial_estimates['risk_level']}

{self._generate_investment_advice(financial_estimates, industry_info)}

---
**ÈáçË¶ÅÂ£∞Êòé**: Êú¨Êä•ÂëäÂü∫‰∫éÂÖ¨ÂºÄÊï∞ÊçÆÂíåÊ®°Âûã‰º∞ÁÆóÁîüÊàêÔºå‰ªÖ‰æõÂèÇËÄÉÔºå‰∏çÊûÑÊàêÊäïËµÑÂª∫ËÆÆ„ÄÇ
**Êï∞ÊçÆÊù•Ê∫ê**: {data_source if data_source else "Â§öÊ∫êÊï∞ÊçÆ"}Êï∞ÊçÆÊé•Âè£
**ÁîüÊàêÊó∂Èó¥**: {datetime.now(ZoneInfo(get_timezone_name())).strftime('%Y-%m-%d %H:%M:%S')}
"""
        else:  # detailed, comprehensive
            #Detailed/comprehensive model: including the most complete analysis
            report = f"""# ‰∏≠ÂõΩAËÇ°Âü∫Êú¨Èù¢ÂàÜÊûêÊä•Âëä - {symbol} (ÂÖ®Èù¢Áâà)

## üìä ËÇ°Á•®Âü∫Êú¨‰ø°ÊÅØ
- **ËÇ°Á•®‰ª£Á†Å**: {symbol}
- **ËÇ°Á•®ÂêçÁß∞**: {company_name}
- **ÊâÄÂ±ûË°å‰∏ö**: {industry_info['industry']}
- **Â∏ÇÂú∫ÊùøÂùó**: {industry_info['market']}
- **ÂΩìÂâçËÇ°‰ª∑**: {current_price}
- **Ê∂®Ë∑åÂπÖ**: {change_pct}
- **Êàê‰∫§Èáè**: {volume}
- **ÂàÜÊûêÊó•Êúü**: {datetime.now(ZoneInfo(get_timezone_name())).strftime('%YÂπ¥%mÊúà%dÊó•')}{data_source_note}

## üí∞ Ë¥¢Âä°Êï∞ÊçÆÂàÜÊûê

### ‰º∞ÂÄºÊåáÊ†á
- **ÊÄªÂ∏ÇÂÄº**: {financial_estimates.get('total_mv', 'N/A')}
- **Â∏ÇÁõàÁéá(PE)**: {financial_estimates.get('pe', 'N/A')}
- **Â∏ÇÁõàÁéáTTM(PE_TTM)**: {financial_estimates.get('pe_ttm', 'N/A')}
- **Â∏ÇÂáÄÁéá(PB)**: {financial_estimates.get('pb', 'N/A')}
- **Â∏ÇÈîÄÁéá(PS)**: {financial_estimates.get('ps', 'N/A')}
- **ËÇ°ÊÅØÊî∂ÁõäÁéá**: {financial_estimates.get('dividend_yield', 'N/A')}

### ÁõàÂà©ËÉΩÂäõÊåáÊ†á
- **ÂáÄËµÑ‰∫ßÊî∂ÁõäÁéá(ROE)**: {financial_estimates.get('roe', 'N/A')}
- **ÊÄªËµÑ‰∫ßÊî∂ÁõäÁéá(ROA)**: {financial_estimates.get('roa', 'N/A')}
- **ÊØõÂà©Áéá**: {financial_estimates.get('gross_margin', 'N/A')}
- **ÂáÄÂà©Áéá**: {financial_estimates.get('net_margin', 'N/A')}

### Ë¥¢Âä°ÂÅ•Â∫∑Â∫¶
- **ËµÑ‰∫ßË¥üÂÄ∫Áéá**: {financial_estimates['debt_ratio']}
- **ÊµÅÂä®ÊØîÁéá**: {financial_estimates['current_ratio']}
- **ÈÄüÂä®ÊØîÁéá**: {financial_estimates['quick_ratio']}
- **Áé∞ÈáëÊØîÁéá**: {financial_estimates['cash_ratio']}

## üìà Ë°å‰∏öÂàÜÊûê

### Ë°å‰∏öÂú∞‰Ωç
{industry_info['analysis']}

### Á´û‰∫â‰ºòÂäø
- **Â∏ÇÂú∫‰ªΩÈ¢ù**: {industry_info['market_share']}
- **ÂìÅÁâå‰ª∑ÂÄº**: {industry_info['brand_value']}
- **ÊäÄÊúØ‰ºòÂäø**: {industry_info['tech_advantage']}

## üéØ ÊäïËµÑ‰ª∑ÂÄºËØÑ‰º∞

### ‰º∞ÂÄºÊ∞¥Âπ≥ÂàÜÊûê
{self._analyze_valuation(financial_estimates)}

### ÊàêÈïøÊÄßÂàÜÊûê
{self._analyze_growth_potential(symbol, industry_info)}

### È£éÈô©ËØÑ‰º∞
{self._analyze_risks(symbol, financial_estimates, industry_info)}

## üí° ÊäïËµÑÂª∫ËÆÆ

### ÁªºÂêàËØÑÂàÜ
- **Âü∫Êú¨Èù¢ËØÑÂàÜ**: {financial_estimates['fundamental_score']}/10
- **‰º∞ÂÄºÂê∏ÂºïÂäõ**: {financial_estimates['valuation_score']}/10
- **ÊàêÈïøÊΩúÂäõ**: {financial_estimates['growth_score']}/10
- **È£éÈô©Á≠âÁ∫ß**: {financial_estimates['risk_level']}

### Êìç‰ΩúÂª∫ËÆÆ
{self._generate_investment_advice(financial_estimates, industry_info)}

### ÁªùÂØπ‰º∞ÂÄº
- **DCF‰º∞ÂÄº**ÔºöÂü∫‰∫éÁé∞ÈáëÊµÅË¥¥Áé∞ÁöÑÂÜÖÂú®‰ª∑ÂÄº
- **ËµÑ‰∫ß‰ª∑ÂÄº**ÔºöÂáÄËµÑ‰∫ßÈáç‰º∞‰ª∑ÂÄº
- **ÂàÜÁ∫¢Êî∂ÁõäÁéá**ÔºöËÇ°ÊÅØÂõûÊä•ÂàÜÊûê

## È£éÈô©ÂàÜÊûê
### Á≥ªÁªüÊÄßÈ£éÈô©
- **ÂÆèËßÇÁªèÊµéÈ£éÈô©**ÔºöÁªèÊµéÂë®ÊúüÂØπÂÖ¨Âè∏ÁöÑÂΩ±Âìç
- **ÊîøÁ≠ñÈ£éÈô©**ÔºöË°å‰∏öÊîøÁ≠ñÂèòÂåñÁöÑÂΩ±Âìç
- **Â∏ÇÂú∫È£éÈô©**ÔºöËÇ°Â∏ÇÊ≥¢Âä®ÂØπ‰º∞ÂÄºÁöÑÂΩ±Âìç

### ÈùûÁ≥ªÁªüÊÄßÈ£éÈô©
- **ÁªèËê•È£éÈô©**ÔºöÂÖ¨Âè∏ÁâπÊúâÁöÑÁªèËê•È£éÈô©
- **Ë¥¢Âä°È£éÈô©**ÔºöÂÄ∫Âä°ÁªìÊûÑÂíåÂÅøÂÄ∫ËÉΩÂäõÈ£éÈô©
- **ÁÆ°ÁêÜÈ£éÈô©**ÔºöÁÆ°ÁêÜÂ±ÇÂèòÂä®ÂíåÂÜ≥Á≠ñÈ£éÈô©

## ÊäïËµÑÂª∫ËÆÆ
### ÁªºÂêàËØÑ‰ª∑
Âü∫‰∫é‰ª•‰∏äÂàÜÊûêÔºåËØ•ËÇ°Á•®ÁöÑÊäïËµÑ‰ª∑ÂÄºËØÑ‰º∞Ôºö

**‰ºòÂäøÔºö**
- AËÇ°Â∏ÇÂú∫‰∏äÂ∏ÇÂÖ¨Âè∏ÔºåÁõëÁÆ°Áõ∏ÂØπÂÆåÂñÑ
- ÂÖ∑Â§á‰∏ÄÂÆöÁöÑÂ∏ÇÂú∫Âú∞‰ΩçÂíåÂìÅÁâå‰ª∑ÂÄº
- Ë¥¢Âä°‰ø°ÊÅØÈÄèÊòéÂ∫¶ËæÉÈ´ò

**È£éÈô©Ôºö**
- ÈúÄË¶ÅÂÖ≥Ê≥®ÂÆèËßÇÁªèÊµéÁéØÂ¢ÉÂèòÂåñ
- Ë°å‰∏öÁ´û‰∫âÂä†ÂâßÁöÑÂΩ±Âìç
- ÊîøÁ≠ñË∞ÉÊï¥ÂØπ‰∏öÂä°ÁöÑÊΩúÂú®ÂΩ±Âìç

### Êìç‰ΩúÂª∫ËÆÆ
- **ÊäïËµÑÁ≠ñÁï•**ÔºöÂª∫ËÆÆÈááÁî®‰ª∑ÂÄºÊäïËµÑÁ≠ñÁï•ÔºåÂÖ≥Ê≥®ÈïøÊúüÂü∫Êú¨Èù¢
- **‰ªì‰ΩçÂª∫ËÆÆ**ÔºöÊ†πÊçÆÈ£éÈô©ÊâøÂèóËÉΩÂäõÂêàÁêÜÈÖçÁΩÆ‰ªì‰Ωç
- **ÂÖ≥Ê≥®ÊåáÊ†á**ÔºöÈáçÁÇπÂÖ≥Ê≥®ROE„ÄÅPE„ÄÅÁé∞ÈáëÊµÅÁ≠âÊ†∏ÂøÉÊåáÊ†á

---
**ÈáçË¶ÅÂ£∞Êòé**: Êú¨Êä•ÂëäÂü∫‰∫éÂÖ¨ÂºÄÊï∞ÊçÆÂíåÊ®°Âûã‰º∞ÁÆóÁîüÊàêÔºå‰ªÖ‰æõÂèÇËÄÉÔºå‰∏çÊûÑÊàêÊäïËµÑÂª∫ËÆÆ„ÄÇ
ÂÆûÈôÖÊäïËµÑÂÜ≥Á≠ñËØ∑ÁªìÂêàÊúÄÊñ∞Ë¥¢Êä•Êï∞ÊçÆÂíå‰∏ì‰∏öÂàÜÊûêÂ∏àÊÑèËßÅ„ÄÇ

**Êï∞ÊçÆÊù•Ê∫ê**: {data_source if data_source else "Â§öÊ∫êÊï∞ÊçÆ"}Êï∞ÊçÆÊé•Âè£ + Âü∫Êú¨Èù¢ÂàÜÊûêÊ®°Âûã
**ÁîüÊàêÊó∂Èó¥**: {datetime.now(ZoneInfo(get_timezone_name())).strftime('%Y-%m-%d %H:%M:%S')}
"""

        return report

    def _get_industry_info(self, symbol: str) -> dict:
        """Access to industry information according to the stock code (prioritize the use of real database data)"""

        #Add detailed stock code tracking log
        logger.debug(f"üîç [Securities Code Tracking]  get indistry info received stock codes: '{symbol}' (type:{type(symbol)})")
        logger.debug(f"[Equal code tracking]{len(str(symbol))}")
        logger.debug(f"[Equal code tracking]{list(str(symbol))}")

        #First try to get real industry information from the database.
        try:
            from .cache.app_adapter import get_basics_from_cache
            doc = get_basics_from_cache(symbol)
            if doc:
                #Record key fields only and avoid printing complete documents
                logger.debug(f"[Equal code tracking]{doc.get('code')}, name={doc.get('name')}, industry={doc.get('industry')}")

                #Regulating the industry and the plate (avoiding miscalculation of the value of the board, such as the "Small/Starboard" sector)
                board_labels = {'‰∏ªÊùø', '‰∏≠Â∞èÊùø', 'Âàõ‰∏öÊùø', 'ÁßëÂàõÊùø'}
                raw_industry = (doc.get('industry') or doc.get('industry_name') or '').strip()
                sec_or_cat = (doc.get('sec') or doc.get('category') or '').strip()
                market_val = (doc.get('market') or '').strip()
                industry_val = raw_industry or sec_or_cat or 'Êú™Áü•'

                #If the industry field is a plate name, it is used as a market; industry is changed to a more detailed classification (sec/category)
                if raw_industry in board_labels:
                    if not market_val:
                        market_val = raw_industry
                    if sec_or_cat:
                        industry_val = sec_or_cat
                    logger.debug(f"üîß{raw_industry}‚ô™ Industry ‚ô™{industry_val}', market/board ='{market_val}'")

                #Build industry information
                info = {
                    "industry": industry_val or 'Êú™Áü•',
                    "market": market_val or doc.get('market', 'Êú™Áü•'),
                    "type": self._get_market_type_by_code(symbol)
                }

                logger.debug(f"[Equal code tracking]{info}")

                #Add detailed analysis of special shares
                if symbol in self._get_special_stocks():
                    info.update(self._get_special_stocks()[symbol])
                else:
                    info.update({
                        "analysis": f"ËØ•ËÇ°Á•®Â±û‰∫é{info['industry']}Ë°å‰∏öÔºåÂú®{info['market']}‰∏äÂ∏Ç‰∫§Êòì„ÄÇ",
                        "market_share": "ÂæÖÂàÜÊûê",
                        "brand_value": "ÂæÖËØÑ‰º∞",
                        "tech_advantage": "ÂæÖÂàÜÊûê"
                    })

                return info

        except Exception as e:
            logger.warning(f"Access to industry information from databases failed:{e}")

        #Alternative scenario: use of code prefix (but modified industry/market map)
        logger.debug(f"[Equal code tracking]")
        code_prefix = symbol[:3]
        logger.debug(f"[Equal code tracking]{code_prefix}'")

        #Revised Map: Distinguishing Industry from Market Blocks
        market_map = {
            "000": {"market": "‰∏ªÊùø", "exchange": "Ê∑±Âú≥ËØÅÂà∏‰∫§ÊòìÊâÄ", "type": "ÁªºÂêà"},
            "001": {"market": "‰∏ªÊùø", "exchange": "Ê∑±Âú≥ËØÅÂà∏‰∫§ÊòìÊâÄ", "type": "ÁªºÂêà"},
            "002": {"market": "‰∏ªÊùø", "exchange": "Ê∑±Âú≥ËØÅÂà∏‰∫§ÊòìÊâÄ", "type": "ÊàêÈïøÂûã"},  #002 is the main panel now.
            "003": {"market": "Âàõ‰∏öÊùø", "exchange": "Ê∑±Âú≥ËØÅÂà∏‰∫§ÊòìÊâÄ", "type": "ÂàõÊñ∞Âûã"},
            "300": {"market": "Âàõ‰∏öÊùø", "exchange": "Ê∑±Âú≥ËØÅÂà∏‰∫§ÊòìÊâÄ", "type": "È´òÁßëÊäÄ"},
            "600": {"market": "‰∏ªÊùø", "exchange": "‰∏äÊµ∑ËØÅÂà∏‰∫§ÊòìÊâÄ", "type": "Â§ßÁõòËìùÁ≠π"},
            "601": {"market": "‰∏ªÊùø", "exchange": "‰∏äÊµ∑ËØÅÂà∏‰∫§ÊòìÊâÄ", "type": "Â§ßÁõòËìùÁ≠π"},
            "603": {"market": "‰∏ªÊùø", "exchange": "‰∏äÊµ∑ËØÅÂà∏‰∫§ÊòìÊâÄ", "type": "‰∏≠Â∞èÁõò"},
            "688": {"market": "ÁßëÂàõÊùø", "exchange": "‰∏äÊµ∑ËØÅÂà∏‰∫§ÊòìÊâÄ", "type": "ÁßëÊäÄÂàõÊñ∞"},
        }

        market_info = market_map.get(code_prefix, {
            "market": "Êú™Áü•Â∏ÇÂú∫",
            "exchange": "Êú™Áü•‰∫§ÊòìÊâÄ",
            "type": "ÁªºÂêà"
        })

        info = {
            "industry": "Êú™Áü•",  #It's not possible to determine the exact industry from the prefix.
            "market": market_info["market"],
            "type": market_info["type"]
        }

        #Details on special stocks
        special_stocks = self._get_special_stocks()
        if symbol in special_stocks:
            info.update(special_stocks[symbol])
        else:
            info.update({
                "analysis": f"ËØ•ËÇ°Á•®Âú®{info['market']}‰∏äÂ∏Ç‰∫§ÊòìÔºåÂÖ∑‰ΩìË°å‰∏ö‰ø°ÊÅØÈúÄË¶ÅËøõ‰∏ÄÊ≠•Êü•ËØ¢„ÄÇ",
                "market_share": "ÂæÖÂàÜÊûê",
                "brand_value": "ÂæÖËØÑ‰º∞",
                "tech_advantage": "ÂæÖÂàÜÊûê"
            })

        return info

    def _get_market_type_by_code(self, symbol: str) -> str:
        """Market type by stock code"""
        code_prefix = symbol[:3]
        type_map = {
            "000": "ÁªºÂêà", "001": "ÁªºÂêà", "002": "ÊàêÈïøÂûã", "003": "ÂàõÊñ∞Âûã",
            "300": "È´òÁßëÊäÄ", "600": "Â§ßÁõòËìùÁ≠π", "601": "Â§ßÁõòËìùÁ≠π",
            "603": "‰∏≠Â∞èÁõò", "688": "ÁßëÊäÄÂàõÊñ∞"
        }
        return type_map.get(code_prefix, "ÁªºÂêà")

    def _get_special_stocks(self) -> dict:
        """Get details on special stocks"""
        return {
            "000001": {
                "industry": "Èì∂Ë°å‰∏ö",
                "analysis": "Âπ≥ÂÆâÈì∂Ë°åÊòØ‰∏≠ÂõΩÈ¢ÜÂÖàÁöÑËÇ°‰ªΩÂà∂ÂïÜ‰∏öÈì∂Ë°åÔºåÂú®Èõ∂ÂîÆÈì∂Ë°å‰∏öÂä°ÊñπÈù¢ÂÖ∑ÊúâÊòæËëó‰ºòÂäø„ÄÇ",
                "market_share": "ËÇ°‰ªΩÂà∂Èì∂Ë°åÂâçÂàó",
                "brand_value": "Áü•ÂêçÈáëËûçÂìÅÁâå",
                "tech_advantage": "ÈáëËûçÁßëÊäÄÂàõÊñ∞È¢ÜÂÖà"
            },
            "600036": {
                "industry": "Èì∂Ë°å‰∏ö",
                "analysis": "ÊãõÂïÜÈì∂Ë°åÊòØ‰∏≠ÂõΩ‰ºòË¥®ÁöÑËÇ°‰ªΩÂà∂Èì∂Ë°åÔºåÈõ∂ÂîÆÈì∂Ë°å‰∏öÂä°ÂíåË¥¢ÂØåÁÆ°ÁêÜ‰∏öÂä°È¢ÜÂÖà„ÄÇ",
                "market_share": "ËÇ°‰ªΩÂà∂Èì∂Ë°åÈæôÂ§¥",
                "brand_value": "‰ºòË¥®Èì∂Ë°åÂìÅÁâå",
                "tech_advantage": "Êï∞Â≠óÂåñÈì∂Ë°åÂÖàÈîã"
            },
            "000002": {
                "industry": "ÊàøÂú∞‰∫ß",
                "analysis": "‰∏áÁßëAÊòØ‰∏≠ÂõΩÊàøÂú∞‰∫ßË°å‰∏öÈæôÂ§¥‰ºÅ‰∏öÔºåÂú®‰ΩèÂÆÖÂºÄÂèëÈ¢ÜÂüüÂÖ∑ÊúâÈ¢ÜÂÖàÂú∞‰Ωç„ÄÇ",
                "market_share": "ÊàøÂú∞‰∫ßË°å‰∏öÂâç‰∏â",
                "brand_value": "Áü•ÂêçÂú∞‰∫ßÂìÅÁâå",
                "tech_advantage": "ÁªøËâ≤Âª∫Á≠ëÊäÄÊúØ"
            },
            "002475": {
                "industry": "ÂÖÉÂô®‰ª∂",
                "analysis": "Á´ãËÆØÁ≤æÂØÜÊòØÂÖ®ÁêÉÈ¢ÜÂÖàÁöÑÁ≤æÂØÜÂà∂ÈÄ†ÊúçÂä°ÂïÜÔºå‰∏ªË¶Å‰ªé‰∫ãËøûÊé•Âô®„ÄÅÂ£∞Â≠¶„ÄÅÊó†Á∫øÂÖÖÁîµÁ≠â‰∫ßÂìÅÁöÑÁ†îÂèëÂà∂ÈÄ†„ÄÇ",
                "market_share": "Ê∂àË¥πÁîµÂ≠êËøûÊé•Âô®ÈæôÂ§¥",
                "brand_value": "Á≤æÂØÜÂà∂ÈÄ†Áü•ÂêçÂìÅÁâå",
                "tech_advantage": "Á≤æÂØÜÂà∂ÈÄ†ÊäÄÊúØÈ¢ÜÂÖà"
            }
        }

    def _estimate_financial_metrics(self, symbol: str, current_price: str) -> dict:
        """Obtaining real financial indicators (from MongoDB, AKshare, Tushare and failure to release anomalies)"""

        #Extract price value
        try:
            price_value = float(current_price.replace('¬•', '').replace(',', ''))
        except:
            price_value = 10.0  #Default value

        #Trying to get real financial data
        real_metrics = self._get_real_financial_metrics(symbol, price_value)
        if real_metrics:
            logger.info(f"Using real financial data:{symbol}")
            return real_metrics

        #If you can't get real data, throw out the anomaly.
        error_msg = f"Êó†Ê≥ïËé∑ÂèñËÇ°Á•® {symbol} ÁöÑË¥¢Âä°Êï∞ÊçÆ„ÄÇÂ∑≤Â∞ùËØïÊâÄÊúâÊï∞ÊçÆÊ∫êÔºàMongoDB„ÄÅAKShare„ÄÅTushareÔºâÂùáÂ§±Ë¥•„ÄÇ"
        logger.error(f"‚ùå {error_msg}")
        raise ValueError(error_msg)

    def _get_real_financial_metrics(self, symbol: str, price_value: float) -> dict:
        """Getting real financial indicators - Prioritize database caches to use API"""
        try:
            #üî• Prioritize real-time stock prices from market quotes to replace imported price value
            from tradingagents.config.database_manager import get_database_manager
            db_manager = get_database_manager()
            db_client = None

            if db_manager.is_mongodb_available():
                try:
                    db_client = db_manager.get_mongodb_client()
                    db = db_client['tradingagents']

                    #Standardised stock code is six.
                    code6 = symbol.replace('.SH', '').replace('.SZ', '').zfill(6)

                    #Get real-time share price from market quotes
                    quote = db.market_quotes.find_one({"code": code6})
                    if quote and quote.get("close"):
                        realtime_price = float(quote.get("close"))
                        logger.info(f"Get real-time stock prices from market quotes:{code6} = {realtime_price}(original price:{price_value}Dollars)")
                        price_value = realtime_price
                    else:
                        logger.info(f"Unfinished in market quotes{code6}real-time share price, using input price:{price_value}Dollar")
                except Exception as e:
                    logger.warning(f"@‚ö†Ô∏è > Failed to get real-time stock prices from market quotes:{e}, using imported prices:{price_value}Dollar")
            else:
                logger.info(f"MongoDB is not available, using input prices:{price_value}Dollar")

            #First priority: Obtain standardized financial data from the MongoDB stock financial data collection
            from tradingagents.config.runtime_settings import use_app_cache_enabled
            if use_app_cache_enabled(False):
                logger.info(f"Priority from MongoDB stock financial data{symbol}Financial data")

                #Obtain standardized financial data directly from MongoDB
                from tradingagents.dataflows.cache.mongodb_cache_adapter import get_mongodb_cache_adapter
                adapter = get_mongodb_cache_adapter()
                financial_data = adapter.get_financial_data(symbol)

                if financial_data:
                    logger.info(f"[Financial data]{symbol}Financial data")
                    #Parsing MongoDB standardized financial data
                    metrics = self._parse_mongodb_financial_data(financial_data, price_value)
                    if metrics:
                        logger.info(f"‚úÖMongoDB Financial Data Analysis Success, Return Indicator")
                        return metrics
                    else:
                        logger.warning(f"MongoDB financial data analysis failed")
                else:
                    logger.info(f"MongoDB not found{symbol}Financial data, try to get from AKShare API")
            else:
                logger.info(f"The database cache üîÑ is not enabled and is obtained directly from AKShare API{symbol}Financial data")

            #Second priority: from Akshare API
            from .providers.china.akshare import get_akshare_provider
            import asyncio

            akshare_provider = get_akshare_provider()

            if akshare_provider.connected:
                #AKShare's Get financial data is an anisyncio.
                loop = asyncio.get_event_loop()
                financial_data = loop.run_until_complete(akshare_provider.get_financial_data(symbol))

                if financial_data and any(not v.empty if hasattr(v, 'empty') else bool(v) for v in financial_data.values()):
                    logger.info(f"AKShare's financial data were obtained successfully:{symbol}")
                    #Access to basic information on stocks (also a stifling method)
                    stock_info = loop.run_until_complete(akshare_provider.get_stock_basic_info(symbol))

                    #Parsing AKShare Financial Data
                    logger.debug(f"Call AKShare parsing function, share price:{price_value}")
                    metrics = self._parse_akshare_financial_data(financial_data, stock_info, price_value)
                    logger.debug(f"AKShare's analysis:{metrics}")
                    if metrics:
                        logger.info(f"AKShare's successfully deciphered and returned.")
                        #Cache raw financial data to the database (rather than decomposition indicators)
                        self._cache_raw_financial_data(symbol, financial_data, stock_info)
                        return metrics
                    else:
                        logger.warning(f"AKShare's resolution failed, returning to the net")
                else:
                    logger.warning(f"AKShare is not available.{symbol}Financial data, try Tushare")
            else:
                logger.warning(f"AKShare is not connected. Try Tushare")

            #Third priority: Use Tushare data source
            logger.info(f"üîÑ with Tushare backup data source{symbol}Financial data")
            from .providers.china.tushare import get_tushare_provider
            import asyncio

            provider = get_tushare_provider()
            if not provider.connected:
                logger.debug(f"Tushare is not connected, not available{symbol}Real financial data")
                return None

            #Access to financial data (a different approach)
            loop = asyncio.get_event_loop()
            financial_data = loop.run_until_complete(provider.get_financial_data(symbol))
            if not financial_data:
                logger.debug(f"Not accessed{symbol}Financial data")
                return None

            #Access to basic information on equities (speech method)
            stock_info = loop.run_until_complete(provider.get_stock_basic_info(symbol))

            #Analysis of Tushare financial data
            metrics = self._parse_financial_data(financial_data, stock_info, price_value)
            if metrics:
                #Cache raw financial data to database
                self._cache_raw_financial_data(symbol, financial_data, stock_info)
                return metrics

        except Exception as e:
            logger.debug(f"Access{symbol}Real financial data failed:{e}")

        return None

    def _parse_mongodb_financial_data(self, financial_data: dict, price_value: float) -> dict:
        """Analysis of MongoDB standardized financial data as indicators"""
        try:
            logger.debug(f"üìä [financial data] Commence the analysis of MongoDB financial data, including fields:{list(financial_data.keys())}")

            metrics = {}

            #MongoDB's financial data is a flat structure that directly includes all financial indicators
            #No longer embedded   FT 0 structure

            #Draw indicator directly from financial data
            latest_indicators = financial_data

            #ROE - Rate of return on net assets (addition range validation)
            roe = latest_indicators.get('roe') or latest_indicators.get('roe_waa')
            if roe is not None and str(roe) != 'nan' and roe != '--':
                try:
                    roe_val = float(roe)
                    #ROE is usually between -100% and -100%, and extremes may exceed
                    if -200 <= roe_val <= 200:
                        metrics["roe"] = f"{roe_val:.1f}%"
                    else:
                        logger.warning(f"ROE data anomaly:{roe_val}, beyond reasonable range [200%, 200%], set to N/A")
                        metrics["roe"] = "N/A"
                except (ValueError, TypeError):
                    metrics["roe"] = "N/A"
            else:
                metrics["roe"] = "N/A"

            #ROA - Total Asset Rates of Return (addition range validation)
            roa = latest_indicators.get('roa') or latest_indicators.get('roa2')
            if roa is not None and str(roa) != 'nan' and roa != '--':
                try:
                    roa_val = float(roa)
                    #ROA is usually between -50 and 50%
                    if -100 <= roa_val <= 100:
                        metrics["roa"] = f"{roa_val:.1f}%"
                    else:
                        logger.warning(f"ROA data anomaly:{roa_val}, beyond reasonable range [-100%, 100%] set to N/A")
                        metrics["roa"] = "N/A"
                except (ValueError, TypeError):
                    metrics["roa"] = "N/A"
            else:
                metrics["roa"] = "N/A"

            #MƒÅori Rate - Add Range Validation
            gross_margin = latest_indicators.get('gross_margin')
            if gross_margin is not None and str(gross_margin) != 'nan' and gross_margin != '--':
                try:
                    gross_margin_val = float(gross_margin)
                    #Validation range: MƒÅori rates should range from -100% to -100%
                    #If out of scope, it could be a data error (e.g. stored in absolute amounts rather than percentages)
                    if -100 <= gross_margin_val <= 100:
                        metrics["gross_margin"] = f"{gross_margin_val:.1f}%"
                    else:
                        logger.warning(f"MƒÅori ratio data anomaly:{gross_margin_val}, beyond reasonable range [-100%, 100%] set to N/A")
                        metrics["gross_margin"] = "N/A"
                except (ValueError, TypeError):
                    metrics["gross_margin"] = "N/A"
            else:
                metrics["gross_margin"] = "N/A"

            #Net interest rate - Add range authentication
            net_margin = latest_indicators.get('netprofit_margin')
            if net_margin is not None and str(net_margin) != 'nan' and net_margin != '--':
                try:
                    net_margin_val = float(net_margin)
                    #Validation range: Net interest rate should be between -100% and -100%
                    if -100 <= net_margin_val <= 100:
                        metrics["net_margin"] = f"{net_margin_val:.1f}%"
                    else:
                        logger.warning(f"Net interest rate data anomalies:{net_margin_val}, beyond reasonable range [-100%, 100%] set to N/A")
                        metrics["net_margin"] = "N/A"
                except (ValueError, TypeError):
                    metrics["net_margin"] = "N/A"
            else:
                metrics["net_margin"] = "N/A"

            #Calculate PE/PB - Prefer real-time calculations, downgrade to static data
            #Fetch both PE and PE TTM indicators
            pe_value = None
            pe_ttm_value = None
            pb_value = None
            is_loss_stock = False  #Whether or not the tag is a loss unit

            try:
                #Prioritize real-time calculations
                from tradingagents.dataflows.realtime_metrics import get_pe_pb_with_fallback
                from tradingagents.config.database_manager import get_database_manager

                db_manager = get_database_manager()
                if db_manager.is_mongodb_available():
                    client = db_manager.get_mongodb_client()
                    #Extract stock code from symbol
                    stock_code = latest_indicators.get('code') or latest_indicators.get('symbol', '').replace('.SZ', '').replace('.SH', '')

                    logger.info(f"[PE Calculating]{stock_code}PE/PB")

                    if stock_code:
                        logger.info(f"üìä [PE Calculator - 1st Floor]{stock_code})")

                        #Access real time PE/PB
                        realtime_metrics = get_pe_pb_with_fallback(stock_code, client)

                        if realtime_metrics:
                            #Obtain market value data (prioritize saving)
                            market_cap = realtime_metrics.get('market_cap')
                            if market_cap is not None and market_cap > 0:
                                is_realtime = realtime_metrics.get('is_realtime', False)
                                realtime_tag = " (ÂÆûÊó∂)" if is_realtime else ""
                                metrics["total_mv"] = f"{market_cap:.2f}‰∫øÂÖÉ{realtime_tag}"
                                logger.info(f"‚úÖ [total market value obtained successfully]{market_cap:.2f}Billion dollars.{is_realtime}")

                            #Use real-time PE (dynamic gain-over)
                            pe_value = realtime_metrics.get('pe')
                            if pe_value is not None and pe_value > 0:
                                is_realtime = realtime_metrics.get('is_realtime', False)
                                realtime_tag = " (ÂÆûÊó∂)" if is_realtime else ""
                                metrics["pe"] = f"{pe_value:.1f}ÂÄç{realtime_tag}"

                                #Detailed Log
                                price = realtime_metrics.get('price', 'N/A')
                                market_cap_log = realtime_metrics.get('market_cap', 'N/A')
                                source = realtime_metrics.get('source', 'unknown')
                                updated_at = realtime_metrics.get('updated_at', 'N/A')

                                logger.info(f"[PE Calculator - 1st Floor Success]{pe_value:.2f}Source:{source}= Real time={is_realtime}")
                                logger.info(f"‚îî Calculated: Share ={price}dollar, market value ={market_cap_log}Billion dollars, update time ={updated_at}")
                            elif pe_value is None:
                                #PE is None. Check if it's a loss.
                                pe_ttm_check = latest_indicators.get('pe_ttm')
                                #Pe ttm is None, < = 0, 'nan', '-' which is considered to be a loss.
                                if pe_ttm_check is None or pe_ttm_check <= 0 or str(pe_ttm_check) == 'nan' or pe_ttm_check == '--':
                                    is_loss_stock = True
                                    logger.info(f"‚ö†Ô∏è [PE Calculates - 1st Floor]{pe_ttm_check}, recognized as a loss unit")

                            #Use real time PE TTM
                            pe_ttm_value = realtime_metrics.get('pe_ttm')
                            if pe_ttm_value is not None and pe_ttm_value > 0:
                                is_realtime = realtime_metrics.get('is_realtime', False)
                                realtime_tag = " (ÂÆûÊó∂)" if is_realtime else ""
                                metrics["pe_ttm"] = f"{pe_ttm_value:.1f}ÂÄç{realtime_tag}"
                                logger.info(f"[PE TTM Calculating - Level 1 Success]{pe_ttm_value:.2f}Source:{source}= Real time={is_realtime}")
                            elif pe_ttm_value is None and not is_loss_stock:
                                #PE TTM is None.
                                pe_ttm_check = latest_indicators.get('pe_ttm')
                                #Pe ttm is None, < = 0, 'nan', '-' which is considered to be a loss.
                                if pe_ttm_check is None or pe_ttm_check <= 0 or str(pe_ttm_check) == 'nan' or pe_ttm_check == '--':
                                    is_loss_stock = True
                                    logger.info(f"[PE TTM Calculating - 1st Floor]{pe_ttm_check}, recognized as a loss unit")

                            #Use Real Time PB
                            pb_value = realtime_metrics.get('pb')
                            if pb_value is not None and pb_value > 0:
                                is_realtime = realtime_metrics.get('is_realtime', False)
                                realtime_tag = " (ÂÆûÊó∂)" if is_realtime else ""
                                metrics["pb"] = f"{pb_value:.2f}ÂÄç{realtime_tag}"
                                logger.info(f"[PB Calculator - 1st Floor Success]{pb_value:.2f}Source:{realtime_metrics.get('source')}= Real time={is_realtime}")
                        else:
                            #üî•Check if the loss has led to the return of None
                            #Get p tm from stock basic info to determine loss
                            pe_ttm_static = latest_indicators.get('pe_ttm')
                            #Pe ttm is None, < = 0, 'nan', '-' which is considered to be a loss.
                            if pe_ttm_static is None or pe_ttm_static <= 0 or str(pe_ttm_static) == 'nan' or pe_ttm_static == '--':
                                is_loss_stock = True
                                logger.info(f"[PE Calculator - Failed Level 1]{pe_ttm_static}) Skip downgrade calculations")
                            else:
                                logger.warning(f"‚ö†Ô∏è [PE Calculator-Failure 1st Layer]")

            except Exception as e:
                logger.warning(f"The real-time calculation failed:{e}will try to downgrade")

            #If real-time calculations fail, try to get total market value from late indicators
            if "total_mv" not in metrics:
                logger.info(f"üìä [total market value -- 2nd floor]")
                total_mv_static = latest_indicators.get('total_mv')
                if total_mv_static is not None and total_mv_static > 0:
                    metrics["total_mv"] = f"{total_mv_static:.2f}‰∫øÂÖÉ"
                    logger.info(f"‚úÖ [total market value -- 2nd floor success]{total_mv_static:.2f}Billion dollars (source: stock basic info)")
                else:
                    #Try to calculate from money cap
                    money_cap = latest_indicators.get('money_cap')
                    if money_cap is not None and money_cap > 0:
                        total_mv_yi = money_cap / 10000
                        metrics["total_mv"] = f"{total_mv_yi:.2f}‰∫øÂÖÉ"
                        logger.info(f"‚úÖ [total market value - 3rd floor success]{total_mv_yi:.2f}Billion dollars (converted from money cap)")
                    else:
                        metrics["total_mv"] = "N/A"
                        logger.warning(f"No data on total market value available")

            #If real-time calculations fail, try traditional calculations
            if pe_value is None:
                #If a loss is confirmed, set PE as N/A and no attempt to downgrade
                if is_loss_stock:
                    metrics["pe"] = "N/A"
                    logger.info(f"‚ö†Ô∏è [PE Calculating-Deficit Unit] recognized as a loss unit, set to N/A, skips the 2nd floor calculation")
                else:
                    logger.info(f"üìä [PE Calculates - 2nd Floor]")

                    net_profit = latest_indicators.get('net_profit')

                    #üî• Critical repairs: check for positive net profits (losses do not account for PE)
                    if net_profit and net_profit > 0:
                        try:
                            #Calculation of PE using market value/net profit
                            money_cap = latest_indicators.get('money_cap')
                            if money_cap and money_cap > 0:
                                pe_calculated = money_cap / net_profit
                                metrics["pe"] = f"{pe_calculated:.1f}ÂÄç"
                                logger.info(f"[PE Calculator - 2nd Floor Success]{pe_calculated:.2f}Double")
                                logger.info(f"‚îî formula: market value{money_cap}Ten thousand dollars) / Net profit (%){net_profit}(In thousands of dollars)")
                            else:
                                logger.warning(f"Market value is invalid:{money_cap}Try the third floor.")

                                #Decline 3rd Layer: Directly use the pe field in the last indicators (in positive numbers only)
                                pe_static = latest_indicators.get('pe')
                                if pe_static is not None and str(pe_static) != 'nan' and pe_static != '--':
                                    try:
                                        pe_float = float(pe_static)
                                        #Only positive PEs
                                        if pe_float > 0:
                                            metrics["pe"] = f"{pe_float:.1f}ÂÄç"
                                            logger.info(f"‚úÖ [PE Calculating - 3rd Floor Success]{metrics['pe']}")
                                            logger.info(f"Data source: block basic info.pe")
                                        else:
                                            metrics["pe"] = "N/A"
                                            logger.info(f"‚ö†Ô∏è [PE Calculates - 3rd Floor Skips] Static PE is negative or zero (losses):{pe_float}")
                                    except (ValueError, TypeError):
                                        metrics["pe"] = "N/A"
                                        logger.error(f"‚ùå [PE Calculator-Failure Level 3] Static PE format error:{pe_static}")
                                else:
                                    metrics["pe"] = "N/A"
                                    logger.error(f"No PE data available")
                        except (ValueError, TypeError, ZeroDivisionError) as e:
                            metrics["pe"] = "N/A"
                            logger.error(f"The calculation failed:{e}")
                    elif net_profit and net_profit < 0:
                        #Loss Unit: PE set to N/A
                        metrics["pe"] = "N/A"
                        logger.info(f"The net profit is negative.{net_profit}Ten thousand dollars)")
                    else:
                        logger.warning(f"[PE Calculating - 2nd Floor Skipping]{net_profit}Try the third floor.")

                        #Decline 3rd Layer: Directly use the pe field in the last indicators (in positive numbers only)
                        pe_static = latest_indicators.get('pe')
                        if pe_static is not None and str(pe_static) != 'nan' and pe_static != '--':
                            try:
                                pe_float = float(pe_static)
                                #Only positive PEs
                                if pe_float > 0:
                                    metrics["pe"] = f"{pe_float:.1f}ÂÄç"
                                    logger.info(f"‚úÖ [PE Calculating - 3rd Floor Success]{metrics['pe']}")
                                    logger.info(f"Data source: block basic info.pe")
                                else:
                                    metrics["pe"] = "N/A"
                                    logger.info(f"‚ö†Ô∏è [PE Calculates - 3rd Floor Skips] Static PE is negative or zero (losses):{pe_float}")
                            except (ValueError, TypeError):
                                metrics["pe"] = "N/A"
                                logger.error(f"‚ùå [PE Calculator-Failure Level 3] Static PE format error:{pe_static}")
                        else:
                            metrics["pe"] = "N/A"
                            logger.error(f"No PE data available")

            #If PE TTM is not available, try to get from static data
            if pe_ttm_value is None:
                #If a loss is confirmed, set PE TTM as N/A
                if is_loss_stock:
                    metrics["pe_ttm"] = "N/A"
                    logger.info(f"‚ö†Ô∏è [PE TTM Calculated-Deficit Unit] recognized as a loss unit and PE TTM set to N/A")
                else:
                    logger.info(f"[PE TTM Calculating - Level 2]")
                    pe_ttm_static = latest_indicators.get('pe_ttm')
                    if pe_ttm_static is not None and str(pe_ttm_static) != 'nan' and pe_ttm_static != '--':
                        try:
                            pe_ttm_float = float(pe_ttm_static)
                            #Only positive PE TTM is accepted.
                            if pe_ttm_float > 0:
                                metrics["pe_ttm"] = f"{pe_ttm_float:.1f}ÂÄç"
                                logger.info(f"Use static PE TTM:{metrics['pe_ttm']}")
                                logger.info(f"‚îî - Data source: stock basic info.pe ttm")
                            else:
                                metrics["pe_ttm"] = "N/A"
                                logger.info(f"‚ö†Ô∏è [PE TTM Calculating - 2nd Floor Skipping] Static PE TTM is negative or zero (losses):{pe_ttm_float}")
                        except (ValueError, TypeError):
                            metrics["pe_ttm"] = "N/A"
                            logger.error(f"‚ùå [PE TTM Calculator - Failed Level 2] Static PE TTM format error:{pe_ttm_static}")
                    else:
                        metrics["pe_ttm"] = "N/A"
                        logger.warning(f"No PE TTM data available")

            if pb_value is None:
                total_equity = latest_indicators.get('total_hldr_eqy_exc_min_int')
                if total_equity and total_equity > 0:
                    try:
                        #Calculation of PB using market value/net assets
                        money_cap = latest_indicators.get('money_cap')
                        if money_cap and money_cap > 0:
                            #Note unit conversion: money cap is ten thousand dollars, total equity is one dollar
                            #PB = market value (millions of dollars) * 10000 / Net assets (dollars)
                            pb_calculated = (money_cap * 10000) / total_equity
                            metrics["pb"] = f"{pb_calculated:.2f}ÂÄç"
                            logger.info(f"[PB Calculator - 2nd Floor Success]{pb_calculated:.2f}Double")
                            logger.info(f"‚îî formula: Market value{money_cap}* 100 000 / Net assets{total_equity}Dollar ={metrics['pb']}")
                        else:
                            #Decline 3rd Layer: Directly use the pb field in last indicators
                            pb_static = latest_indicators.get('pb') or latest_indicators.get('pb_mrq')
                            if pb_static is not None and str(pb_static) != 'nan' and pb_static != '--':
                                try:
                                    metrics["pb"] = f"{float(pb_static):.2f}ÂÄç"
                                    logger.info(f"‚úÖ [PB Calculator - 3rd Level Success]{metrics['pb']}")
                                    logger.info(f"‚îî - Data source: stock basic info.pb")
                                except (ValueError, TypeError):
                                    metrics["pb"] = "N/A"
                            else:
                                metrics["pb"] = "N/A"
                    except (ValueError, TypeError, ZeroDivisionError) as e:
                        logger.error(f"The calculation failed:{e}")
                        metrics["pb"] = "N/A"
                else:
                    #Decline 3rd Layer: Directly use the pb field in last indicators
                    pb_static = latest_indicators.get('pb') or latest_indicators.get('pb_mrq')
                    if pb_static is not None and str(pb_static) != 'nan' and pb_static != '--':
                        try:
                            metrics["pb"] = f"{float(pb_static):.2f}ÂÄç"
                            logger.info(f"‚úÖ [PB Calculator - 3rd Level Success]{metrics['pb']}")
                            logger.info(f"‚îî - Data source: stock basic info.pb")
                        except (ValueError, TypeError):
                            metrics["pb"] = "N/A"
                    else:
                        metrics["pb"] = "N/A"

            #Assets and liabilities ratio
            debt_ratio = latest_indicators.get('debt_to_assets')
            if debt_ratio is not None and str(debt_ratio) != 'nan' and debt_ratio != '--':
                try:
                    metrics["debt_ratio"] = f"{float(debt_ratio):.1f}%"
                except (ValueError, TypeError):
                    metrics["debt_ratio"] = "N/A"
            else:
                metrics["debt_ratio"] = "N/A"

            #Calculation of PS - marketing rate (using TTM operating income)
            #Prioritize TTM operating income or, if not, single-stage operating income
            revenue_ttm = latest_indicators.get('revenue_ttm')
            revenue = latest_indicators.get('revenue')

            #Select which business income data to use
            revenue_for_ps = revenue_ttm if revenue_ttm and revenue_ttm > 0 else revenue
            revenue_type = "TTM" if revenue_ttm and revenue_ttm > 0 else "ÂçïÊúü"

            if revenue_for_ps and revenue_for_ps > 0:
                try:
                    #Calculate PS using market value/business income
                    money_cap = latest_indicators.get('money_cap')
                    if money_cap and money_cap > 0:
                        ps_calculated = money_cap / revenue_for_ps
                        metrics["ps"] = f"{ps_calculated:.2f}ÂÄç"
                        logger.debug(f"Compute PS (‚úÖ){revenue_type}Market value{money_cap}Ten thousand dollars / operating income{revenue_for_ps}Ten thousand dollars ={metrics['ps']}")
                    else:
                        metrics["ps"] = "N/A"
                except (ValueError, TypeError, ZeroDivisionError):
                    metrics["ps"] = "N/A"
            else:
                metrics["ps"] = "N/A"

            #Dividend rate of return - provisional N/A, required dividends data
            metrics["dividend_yield"] = "N/A"
            metrics["current_ratio"] = latest_indicators.get('current_ratio', 'N/A')
            metrics["quick_ratio"] = latest_indicators.get('quick_ratio', 'N/A')
            metrics["cash_ratio"] = latest_indicators.get('cash_ratio', 'N/A')

            #Add scoring fields (using default values)
            metrics["fundamental_score"] = 7.0  #Default rating based on real data
            metrics["valuation_score"] = 6.5
            metrics["growth_score"] = 7.0
            metrics["risk_level"] = "‰∏≠Á≠â"

            logger.info(f"MongoDB Financial Data Analysis Success: ROE={metrics.get('roe')}, ROA={metrics.get('roa')}, MƒÅori rate ={metrics.get('gross_margin')}, net interest rate ={metrics.get('net_margin')}")
            return metrics

        except Exception as e:
            logger.error(f"The analysis of MongoDB's financial data failed:{e}", exc_info=True)
            return None

    def _parse_akshare_financial_data(self, financial_data: dict, stock_info: dict, price_value: float) -> dict:
        """Analysis of AKShare financial data as indicator"""
        try:
            #Access to up-to-date financial data
            balance_sheet = financial_data.get('balance_sheet', [])
            income_statement = financial_data.get('income_statement', [])
            cash_flow = financial_data.get('cash_flow', [])
            main_indicators = financial_data.get('main_indicators')

            #Main indicators may be the result of DataFrame or list (to dicts)
            if main_indicators is None:
                logger.warning("AKShare ' s main financial indicators are empty")
                return None

            #Check if empty
            if isinstance(main_indicators, list):
                if not main_indicators:
                    logger.warning("AKShare list of key financial indicators is empty")
                    return None
                #List format: [  FMT 0 ,...]
                #Convert to DataFrame for uniform processing
                import pandas as pd
                main_indicators = pd.DataFrame(main_indicators)
            elif hasattr(main_indicators, 'empty') and main_indicators.empty:
                logger.warning("DataFrame, the main financial indicator for AKShare, is empty.")
                return None

            #Main indicators is DataFrame, which needs to be converted to dictionary format for easy search
            #Get the latest data column (column 3, index 2)
            latest_col = main_indicators.columns[2] if len(main_indicators.columns) > 2 else None
            if not latest_col:
                logger.warning("Lack of data columns for AKShare key financial indicators")
                return None

            logger.info(f"While using the latest data from AKShare:{latest_col}")

            #Create map of indicator name to value
            indicators_dict = {}
            for _, row in main_indicators.iterrows():
                indicator_name = row['ÊåáÊ†á']
                value = row[latest_col]
                indicators_dict[indicator_name] = value

            logger.debug(f"Number of key financial indicators for AKshare:{len(indicators_dict)}")

            #Calculation of financial indicators
            metrics = {}

            #üî• Preferably try to use real-time PE/PB calculations (in line with MongoDB resolution)
            pe_value = None
            pe_ttm_value = None
            pb_value = None

            try:
                #Get stock code
                stock_code = stock_info.get('code', '').replace('.SH', '').replace('.SZ', '').zfill(6)
                if stock_code:
                    logger.info(f"üìä [AKShare-PE Calculates - 1st Floor]{stock_code}")

                    from tradingagents.config.database_manager import get_database_manager
                    from tradingagents.dataflows.realtime_metrics import get_pe_pb_with_fallback

                    db_manager = get_database_manager()
                    if db_manager.is_mongodb_available():
                        client = db_manager.get_mongodb_client()

                        #Access real time PE/PB
                        realtime_metrics = get_pe_pb_with_fallback(stock_code, client)

                        if realtime_metrics:
                            #Acquisition of total market value
                            market_cap = realtime_metrics.get('market_cap')
                            if market_cap is not None and market_cap > 0:
                                is_realtime = realtime_metrics.get('is_realtime', False)
                                realtime_tag = " (ÂÆûÊó∂)" if is_realtime else ""
                                metrics["total_mv"] = f"{market_cap:.2f}‰∫øÂÖÉ{realtime_tag}"
                                logger.info(f"[AKShare - Total Market Value Successful]{market_cap:.2f}Billion dollars.{is_realtime}")

                            #Use Real Time PE
                            pe_value = realtime_metrics.get('pe')
                            if pe_value is not None and pe_value > 0:
                                is_realtime = realtime_metrics.get('is_realtime', False)
                                realtime_tag = " (ÂÆûÊó∂)" if is_realtime else ""
                                metrics["pe"] = f"{pe_value:.1f}ÂÄç{realtime_tag}"
                                logger.info(f"[Akshare-PE Calculator - Success Level 1]{pe_value:.2f}Source:{realtime_metrics.get('source')}= Real time={is_realtime}")

                            #Use real time PE TTM
                            pe_ttm_value = realtime_metrics.get('pe_ttm')
                            if pe_ttm_value is not None and pe_ttm_value > 0:
                                is_realtime = realtime_metrics.get('is_realtime', False)
                                realtime_tag = " (ÂÆûÊó∂)" if is_realtime else ""
                                metrics["pe_ttm"] = f"{pe_ttm_value:.1f}ÂÄç{realtime_tag}"
                                logger.info(f"PE TTM={pe_ttm_value:.2f}Double")

                            #Use Real Time PB
                            pb_value = realtime_metrics.get('pb')
                            if pb_value is not None and pb_value > 0:
                                is_realtime = realtime_metrics.get('is_realtime', False)
                                realtime_tag = " (ÂÆûÊó∂)" if is_realtime else ""
                                metrics["pb"] = f"{pb_value:.2f}ÂÄç{realtime_tag}"
                                logger.info(f"[AKshare-PB Calculator-Face 1 Success]{pb_value:.2f}Double")
                        else:
                            logger.warning(f"‚ö†Ô∏è [AKShare-PE Calculator - Failed 1st Floor] Real-time calculations of returns to empty results will attempt to downgrade")
            except Exception as e:
                logger.warning(f"The real-time calculation failed:{e}will try to downgrade")

            #Get ROE - Get directly from the indicator
            roe_value = indicators_dict.get('ÂáÄËµÑ‰∫ßÊî∂ÁõäÁéá(ROE)')
            if roe_value is not None and str(roe_value) != 'nan' and roe_value != '--':
                try:
                    roe_val = float(roe_value)
                    #ROE is usually in percentage form.
                    metrics["roe"] = f"{roe_val:.1f}%"
                    logger.debug(f"Get ROE:{metrics['roe']}")
                except (ValueError, TypeError):
                    metrics["roe"] = "N/A"
            else:
                metrics["roe"] = "N/A"

            #Try to obtain total market value from stock info if real-time calculations fail
            if "total_mv" not in metrics:
                logger.info(f"Try to get it from stock info")
                total_mv_static = stock_info.get('total_mv')
                if total_mv_static is not None and total_mv_static > 0:
                    metrics["total_mv"] = f"{total_mv_static:.2f}‰∫øÂÖÉ"
                    logger.info(f"‚úÖ [AKShare - Total Market Value - 2nd Floor Success]{total_mv_static:.2f}Billions.")
                else:
                    metrics["total_mv"] = "N/A"
                    logger.warning(f"‚ö†Ô∏è [AKShare - Total Market Value - All Failed] No data on total market value available")

            #If real-time calculations fail, downgrade to traditional calculations
            if pe_value is None:
                logger.info(f"üìä [AKShare-PE Calculates - 2nd Floor]")

                #Calculate PE - Prefer TTM data
                #Try to calculate TTM EPS frommain indicators DataFrame
                ttm_eps = None
                try:
                    #Main indicators is DataFrame with multiple periods of data
                    #Try to calculate TTM EPS
                    if 'Âü∫Êú¨ÊØèËÇ°Êî∂Áõä' in main_indicators['ÊåáÊ†á'].values:
                        #All period data extracted from basic per share of proceeds
                        eps_row = main_indicators[main_indicators['ÊåáÊ†á'] == 'Âü∫Êú¨ÊØèËÇ°Êî∂Áõä']
                        if not eps_row.empty:
                            #Get all value columns (exclusion 'indicator' columns)
                            value_cols = [col for col in eps_row.columns if col != 'ÊåáÊ†á']

                            #Build DataFrame for TTM calculations
                            import pandas as pd
                            eps_data = []
                            for col in value_cols:
                                eps_val = eps_row[col].iloc[0]
                                if eps_val is not None and str(eps_val) != 'nan' and eps_val != '--':
                                    eps_data.append({'Êä•ÂëäÊúü': col, 'Âü∫Êú¨ÊØèËÇ°Êî∂Áõä': eps_val})

                            if len(eps_data) >= 2:
                                eps_df = pd.DataFrame(eps_data)
                                #Calculate function using TTM
                                from scripts.sync_financial_data import _calculate_ttm_metric
                                ttm_eps = _calculate_ttm_metric(eps_df, 'Âü∫Êú¨ÊØèËÇ°Êî∂Áõä')
                                if ttm_eps:
                                    logger.info(f"TM EPS:{ttm_eps:.4f}Dollar")
                except Exception as e:
                    logger.debug(f"Could not close temporary folder: %s{e}")

                #Calculate PE using TM EPS or single-stage EPS
                eps_for_pe = ttm_eps if ttm_eps else None
                pe_type = "TTM" if ttm_eps else "ÂçïÊúü"

                if not eps_for_pe:
                    #Downgrade to single stage EPS
                    eps_value = indicators_dict.get('Âü∫Êú¨ÊØèËÇ°Êî∂Áõä')
                    if eps_value is not None and str(eps_value) != 'nan' and eps_value != '--':
                        try:
                            eps_for_pe = float(eps_value)
                        except (ValueError, TypeError):
                            pass

                if eps_for_pe and eps_for_pe > 0:
                    pe_val = price_value / eps_for_pe
                    metrics["pe"] = f"{pe_val:.1f}ÂÄç"
                    logger.info(f"‚úÖ [AKshare-PE Calculates - 2nd Floor Success] PE{pe_type}Share price{price_value} / EPS{eps_for_pe:.4f} = {metrics['pe']}")
                elif eps_for_pe and eps_for_pe <= 0:
                    metrics["pe"] = "N/AÔºà‰∫èÊçüÔºâ"
                    logger.warning(f"[AKshare-PE Calculator - Failed 2nd Floor]{eps_for_pe}")
                else:
                    metrics["pe"] = "N/A"
                    logger.error(f"No EPS data available")

            #If real-time PB calculations fail, downgrade to the traditional mode of calculation
            if pb_value is None:
                logger.info(f"üìä [AKshare-PB Calculates - 2nd Floor]")

                #Acquisition of net assets per share - used to calculate PB
                bps_value = indicators_dict.get('ÊØèËÇ°ÂáÄËµÑ‰∫ß_ÊúÄÊñ∞ËÇ°Êï∞')
                if bps_value is not None and str(bps_value) != 'nan' and bps_value != '--':
                    try:
                        bps_val = float(bps_value)
                        if bps_val > 0:
                            #Calculate PB = share price / net assets per share
                            pb_val = price_value / bps_val
                            metrics["pb"] = f"{pb_val:.2f}ÂÄç"
                            logger.info(f"PB: Stock price{price_value} / BPS{bps_val} = {metrics['pb']}")
                        else:
                            metrics["pb"] = "N/A"
                            logger.warning(f"BPS is invalid:{bps_val}")
                    except (ValueError, TypeError) as e:
                        metrics["pb"] = "N/A"
                        logger.error(f"[Akshare-PB Calculator - 2nd Level Aberrant]{e}")
                else:
                    metrics["pb"] = "N/A"
                    logger.error(f"No BPS data available")

            #Try to get other indicators
            #Total asset return (ROA)
            roa_value = indicators_dict.get('ÊÄªËµÑ‰∫ßÊä•ÈÖ¨Áéá')
            if roa_value is not None and str(roa_value) != 'nan' and roa_value != '--':
                try:
                    roa_val = float(roa_value)
                    metrics["roa"] = f"{roa_val:.1f}%"
                except (ValueError, TypeError):
                    metrics["roa"] = "N/A"
            else:
                metrics["roa"] = "N/A"

            #MƒÅori rate
            gross_margin_value = indicators_dict.get('ÊØõÂà©Áéá')
            if gross_margin_value is not None and str(gross_margin_value) != 'nan' and gross_margin_value != '--':
                try:
                    gross_margin_val = float(gross_margin_value)
                    metrics["gross_margin"] = f"{gross_margin_val:.1f}%"
                except (ValueError, TypeError):
                    metrics["gross_margin"] = "N/A"
            else:
                metrics["gross_margin"] = "N/A"

            #Net interest rate on sales
            net_margin_value = indicators_dict.get('ÈîÄÂîÆÂáÄÂà©Áéá')
            if net_margin_value is not None and str(net_margin_value) != 'nan' and net_margin_value != '--':
                try:
                    net_margin_val = float(net_margin_value)
                    metrics["net_margin"] = f"{net_margin_val:.1f}%"
                except (ValueError, TypeError):
                    metrics["net_margin"] = "N/A"
            else:
                metrics["net_margin"] = "N/A"

            #Assets and liabilities ratio
            debt_ratio_value = indicators_dict.get('ËµÑ‰∫ßË¥üÂÄ∫Áéá')
            if debt_ratio_value is not None and str(debt_ratio_value) != 'nan' and debt_ratio_value != '--':
                try:
                    debt_ratio_val = float(debt_ratio_value)
                    metrics["debt_ratio"] = f"{debt_ratio_val:.1f}%"
                except (ValueError, TypeError):
                    metrics["debt_ratio"] = "N/A"
            else:
                metrics["debt_ratio"] = "N/A"

            #Mobility ratio
            current_ratio_value = indicators_dict.get('ÊµÅÂä®ÊØîÁéá')
            if current_ratio_value is not None and str(current_ratio_value) != 'nan' and current_ratio_value != '--':
                try:
                    current_ratio_val = float(current_ratio_value)
                    metrics["current_ratio"] = f"{current_ratio_val:.2f}"
                except (ValueError, TypeError):
                    metrics["current_ratio"] = "N/A"
            else:
                metrics["current_ratio"] = "N/A"

            #Speed ratio
            quick_ratio_value = indicators_dict.get('ÈÄüÂä®ÊØîÁéá')
            if quick_ratio_value is not None and str(quick_ratio_value) != 'nan' and quick_ratio_value != '--':
                try:
                    quick_ratio_val = float(quick_ratio_value)
                    metrics["quick_ratio"] = f"{quick_ratio_val:.2f}"
                except (ValueError, TypeError):
                    metrics["quick_ratio"] = "N/A"
            else:
                metrics["quick_ratio"] = "N/A"

            #Calculate PS - Marketing Rate (Priority TTM Business Income)
            #Try to calculate TTM operating income from plain indicators DataFrame
            ttm_revenue = None
            try:
                if 'Ëê•‰∏öÊî∂ÂÖ•' in main_indicators['ÊåáÊ†á'].values:
                    revenue_row = main_indicators[main_indicators['ÊåáÊ†á'] == 'Ëê•‰∏öÊî∂ÂÖ•']
                    if not revenue_row.empty:
                        value_cols = [col for col in revenue_row.columns if col != 'ÊåáÊ†á']

                        import pandas as pd
                        revenue_data = []
                        for col in value_cols:
                            rev_val = revenue_row[col].iloc[0]
                            if rev_val is not None and str(rev_val) != 'nan' and rev_val != '--':
                                revenue_data.append({'Êä•ÂëäÊúü': col, 'Ëê•‰∏öÊî∂ÂÖ•': rev_val})

                        if len(revenue_data) >= 2:
                            revenue_df = pd.DataFrame(revenue_data)
                            from scripts.sync_financial_data import _calculate_ttm_metric
                            ttm_revenue = _calculate_ttm_metric(revenue_df, 'Ëê•‰∏öÊî∂ÂÖ•')
                            if ttm_revenue:
                                logger.info(f"‚úÖ Calculates TTM operating income:{ttm_revenue:.2f}Ten thousand dollars.")
            except Exception as e:
                logger.debug(f"Could not close temporary folder: %s{e}")

            #Calculate PS
            revenue_for_ps = ttm_revenue if ttm_revenue else None
            ps_type = "TTM" if ttm_revenue else "ÂçïÊúü"

            if not revenue_for_ps:
                #Downgrade to single-stage operating income
                revenue_value = indicators_dict.get('Ëê•‰∏öÊî∂ÂÖ•')
                if revenue_value is not None and str(revenue_value) != 'nan' and revenue_value != '--':
                    try:
                        revenue_for_ps = float(revenue_value)
                    except (ValueError, TypeError):
                        pass

            if revenue_for_ps and revenue_for_ps > 0:
                #Market value of gross equity acquisition
                total_share = stock_info.get('total_share') if stock_info else None
                if total_share and total_share > 0:
                    #Market value (thousands of United States dollars) = gross equity (millions of United States dollars)
                    market_cap = price_value * total_share
                    ps_val = market_cap / revenue_for_ps
                    metrics["ps"] = f"{ps_val:.2f}ÂÄç"
                    logger.info(f"Compute PS (‚úÖ){ps_type}Market value{market_cap:.2f}Ten thousand dollars / operating income{revenue_for_ps:.2f}Ten thousand dollars ={metrics['ps']}")
                else:
                    metrics["ps"] = "N/AÔºàÊó†ÊÄªËÇ°Êú¨Êï∞ÊçÆÔºâ"
                    logger.warning(f"Could not calculate PS: Lack of total equity data")
            else:
                metrics["ps"] = "N/A"

            #Default value to complement other indicators
            metrics.update({
                "dividend_yield": "ÂæÖÊü•ËØ¢",
                "cash_ratio": "ÂæÖÂàÜÊûê"
            })

            #Rating (simplified rating based on AKShare data)
            fundamental_score = self._calculate_fundamental_score(metrics, stock_info)
            valuation_score = self._calculate_valuation_score(metrics)
            growth_score = self._calculate_growth_score(metrics, stock_info)
            risk_level = self._calculate_risk_level(metrics, stock_info)

            metrics.update({
                "fundamental_score": fundamental_score,
                "valuation_score": valuation_score,
                "growth_score": growth_score,
                "risk_level": risk_level,
                "data_source": "AKShare"
            })

            logger.info(f"AKshare's financial data analysis was successful:{metrics['pe']}, PB={metrics['pb']}, ROE={metrics['roe']}")
            return metrics

        except Exception as e:
            logger.error(f"AKShare's financial data analysis failed:{e}")
            return None

    def _parse_financial_data(self, financial_data: dict, stock_info: dict, price_value: float) -> dict:
        """Parsing financial data as indicators"""
        try:
            #Access to up-to-date financial data
            balance_sheet = financial_data.get('balance_sheet', [])
            income_statement = financial_data.get('income_statement', [])
            cash_flow = financial_data.get('cash_flow', [])

            if not (balance_sheet or income_statement):
                return None

            latest_balance = balance_sheet[0] if balance_sheet else {}
            latest_income = income_statement[0] if income_statement else {}
            latest_cash = cash_flow[0] if cash_flow else {}

            #Calculation of financial indicators
            metrics = {}

            #Basic data
            total_assets = latest_balance.get('total_assets', 0) or 0
            total_liab = latest_balance.get('total_liab', 0) or 0
            total_equity = latest_balance.get('total_hldr_eqy_exc_min_int', 0) or 0

            #Calculation of TTM operating income and net profits
            #Tushare income statement data are cumulative values (from the beginning of the year to the reporting period)
            #Calculate using TTM formulae
            ttm_revenue = None
            ttm_net_income = None

            try:
                if len(income_statement) >= 2:
                    #Preparing data for TTM calculations
                    import pandas as pd

                    #Build Business Income DataFrame
                    revenue_data = []
                    for stmt in income_statement:
                        end_date = stmt.get('end_date')
                        revenue = stmt.get('total_revenue')
                        if end_date and revenue is not None:
                            revenue_data.append({'Êä•ÂëäÊúü': str(end_date), 'Ëê•‰∏öÊî∂ÂÖ•': float(revenue)})

                    if len(revenue_data) >= 2:
                        revenue_df = pd.DataFrame(revenue_data)
                        from scripts.sync_financial_data import _calculate_ttm_metric
                        ttm_revenue = _calculate_ttm_metric(revenue_df, 'Ëê•‰∏öÊî∂ÂÖ•')
                        if ttm_revenue:
                            logger.info(f"Tushare calculates TTM operating income:{ttm_revenue:.2f}Ten thousand dollars.")

                    #Build net profit DataFrame
                    profit_data = []
                    for stmt in income_statement:
                        end_date = stmt.get('end_date')
                        profit = stmt.get('n_income')
                        if end_date and profit is not None:
                            profit_data.append({'Êä•ÂëäÊúü': str(end_date), 'ÂáÄÂà©Ê∂¶': float(profit)})

                    if len(profit_data) >= 2:
                        profit_df = pd.DataFrame(profit_data)
                        ttm_net_income = _calculate_ttm_metric(profit_df, 'ÂáÄÂà©Ê∂¶')
                        if ttm_net_income:
                            logger.info(f"Tushare calculates TTM net profit:{ttm_net_income:.2f}Ten thousand dollars.")
            except Exception as e:
                logger.warning(f"Tushare TTM calculation failed:{e}")

            #Downgrade to single-stage data
            total_revenue = ttm_revenue if ttm_revenue else (latest_income.get('total_revenue', 0) or 0)
            net_income = ttm_net_income if ttm_net_income else (latest_income.get('n_income', 0) or 0)
            operate_profit = latest_income.get('operate_profit', 0) or 0

            revenue_type = "TTM" if ttm_revenue else "ÂçïÊúü"
            profit_type = "TTM" if ttm_net_income else "ÂçïÊúü"

            #Market value for actual gross equity
            #Prefer from stock info, if not accurate valuation indicators cannot be calculated
            total_share = stock_info.get('total_share') if stock_info else None

            if total_share and total_share > 0:
                #Market value (dollars) = share price (dollars) x gross equity (millions) x 10000
                market_cap = price_value * total_share * 10000
                market_cap_yi = market_cap / 100000000  #Convert to Billion Dollars
                metrics["total_mv"] = f"{market_cap_yi:.2f}‰∫øÂÖÉ"
                logger.info(f"[Tushare - total market value calculated successfully]{market_cap_yi:.2f}Billions{price_value}Total equity{total_share}1 000 shares)")
            else:
                logger.error(f"‚ùå {stock_info.get('code', 'Unknown')}Total equity is not available and accurate valuation indicators cannot be calculated")
                market_cap = None
                metrics["total_mv"] = "N/A"

            #Calculated indicators (only when an accurate market value exists)
            if market_cap:
                #PE ratio (priority for TTM net profit)
                if net_income > 0:
                    pe_ratio = market_cap / (net_income * 10000)  #Convert Unit
                    metrics["pe"] = f"{pe_ratio:.1f}ÂÄç"
                    logger.info(f"Tushare Calculating PE{profit_type}Market value{market_cap/100000000:.2f}Billions dollars / net profit{net_income:.2f}Ten thousand dollars ={pe_ratio:.1f}Double")
                else:
                    metrics["pe"] = "N/AÔºà‰∫èÊçüÔºâ"

                #PB ratio (net assets using latest available data, relative accuracy)
                if total_equity > 0:
                    pb_ratio = market_cap / (total_equity * 10000)
                    metrics["pb"] = f"{pb_ratio:.2f}ÂÄç"
                else:
                    metrics["pb"] = "N/A"

                #PS ratio (priority TTM operating income)
                if total_revenue > 0:
                    ps_ratio = market_cap / (total_revenue * 10000)
                    metrics["ps"] = f"{ps_ratio:.1f}ÂÄç"
                    logger.info(f"Tushare Calculating PS(){revenue_type}Market value{market_cap/100000000:.2f}Billion dollars / Business income{total_revenue:.2f}Ten thousand dollars ={ps_ratio:.1f}Double")
                else:
                    metrics["ps"] = "N/A"
            else:
                #Total equity not available, valuation indicator not possible
                metrics["pe"] = "N/AÔºàÊó†ÊÄªËÇ°Êú¨Êï∞ÊçÆÔºâ"
                metrics["pb"] = "N/AÔºàÊó†ÊÄªËÇ°Êú¨Êï∞ÊçÆÔºâ"
                metrics["ps"] = "N/AÔºàÊó†ÊÄªËÇ°Êú¨Êï∞ÊçÆÔºâ"

            # ROE
            if total_equity > 0 and net_income > 0:
                roe = (net_income / total_equity) * 100
                metrics["roe"] = f"{roe:.1f}%"
            else:
                metrics["roe"] = "N/A"

            # ROA
            if total_assets > 0 and net_income > 0:
                roa = (net_income / total_assets) * 100
                metrics["roa"] = f"{roa:.1f}%"
            else:
                metrics["roa"] = "N/A"

            #Net interest rate
            if total_revenue > 0 and net_income > 0:
                net_margin = (net_income / total_revenue) * 100
                metrics["net_margin"] = f"{net_margin:.1f}%"
            else:
                metrics["net_margin"] = "N/A"

            #Assets and liabilities ratio
            if total_assets > 0:
                debt_ratio = (total_liab / total_assets) * 100
                metrics["debt_ratio"] = f"{debt_ratio:.1f}%"
            else:
                metrics["debt_ratio"] = "N/A"

            #Set other indicators as default values
            metrics.update({
                "dividend_yield": "ÂæÖÊü•ËØ¢",
                "gross_margin": "ÂæÖËÆ°ÁÆó",
                "current_ratio": "ÂæÖËÆ°ÁÆó",
                "quick_ratio": "ÂæÖËÆ°ÁÆó",
                "cash_ratio": "ÂæÖÂàÜÊûê"
            })

            #Rating (simplified rating based on real data)
            fundamental_score = self._calculate_fundamental_score(metrics, stock_info)
            valuation_score = self._calculate_valuation_score(metrics)
            growth_score = self._calculate_growth_score(metrics, stock_info)
            risk_level = self._calculate_risk_level(metrics, stock_info)

            metrics.update({
                "fundamental_score": fundamental_score,
                "valuation_score": valuation_score,
                "growth_score": growth_score,
                "risk_level": risk_level
            })

            return metrics

        except Exception as e:
            logger.error(f"Can not open message{e}")
            return None

    def _calculate_fundamental_score(self, metrics: dict, stock_info: dict) -> float:
        """Calculate basic profile score"""
        score = 5.0  #Base Score

        #ROE Rating
        roe_str = metrics.get("roe", "N/A")
        if roe_str != "N/A":
            try:
                roe = float(roe_str.replace("%", ""))
                if roe > 15:
                    score += 1.5
                elif roe > 10:
                    score += 1.0
                elif roe > 5:
                    score += 0.5
            except:
                pass

        #Net rate rating
        net_margin_str = metrics.get("net_margin", "N/A")
        if net_margin_str != "N/A":
            try:
                net_margin = float(net_margin_str.replace("%", ""))
                if net_margin > 20:
                    score += 1.0
                elif net_margin > 10:
                    score += 0.5
            except:
                pass

        return min(score, 10.0)

    def _calculate_valuation_score(self, metrics: dict) -> float:
        """Calculation of valuation ratings"""
        score = 5.0  #Base Score

        #PE rating
        pe_str = metrics.get("pe", "N/A")
        if pe_str != "N/A" and "‰∫èÊçü" not in pe_str:
            try:
                pe = float(pe_str.replace("ÂÄç", ""))
                if pe < 15:
                    score += 2.0
                elif pe < 25:
                    score += 1.0
                elif pe > 50:
                    score -= 1.0
            except:
                pass

        #PB rating
        pb_str = metrics.get("pb", "N/A")
        if pb_str != "N/A":
            try:
                pb = float(pb_str.replace("ÂÄç", ""))
                if pb < 1.5:
                    score += 1.0
                elif pb < 3:
                    score += 0.5
                elif pb > 5:
                    score -= 0.5
            except:
                pass

        return min(max(score, 1.0), 10.0)

    def _calculate_growth_score(self, metrics: dict, stock_info: dict) -> float:
        """Calculate growth scores"""
        score = 6.0  #Base Score

        #Adjustment by industry
        industry = stock_info.get('industry', '')
        if 'ÁßëÊäÄ' in industry or 'ËΩØ‰ª∂' in industry or '‰∫íËÅîÁΩë' in industry:
            score += 1.0
        elif 'Èì∂Ë°å' in industry or '‰øùÈô©' in industry:
            score -= 0.5

        return min(max(score, 1.0), 10.0)

    def _calculate_risk_level(self, metrics: dict, stock_info: dict) -> str:
        """Calculate risk level"""
        #Assets and liabilities ratio
        debt_ratio_str = metrics.get("debt_ratio", "N/A")
        if debt_ratio_str != "N/A":
            try:
                debt_ratio = float(debt_ratio_str.replace("%", ""))
                if debt_ratio > 70:
                    return "ËæÉÈ´ò"
                elif debt_ratio > 50:
                    return "‰∏≠Á≠â"
                else:
                    return "ËæÉ‰Ωé"
            except:
                pass

        #By industry
        industry = stock_info.get('industry', '')
        if 'Èì∂Ë°å' in industry:
            return "‰∏≠Á≠â"
        elif 'ÁßëÊäÄ' in industry or 'Âàõ‰∏öÊùø' in industry:
            return "ËæÉÈ´ò"

        return "‰∏≠Á≠â"



    def _analyze_valuation(self, financial_estimates: dict) -> str:
        """Analysis of valuation levels"""
        valuation_score = financial_estimates['valuation_score']

        if valuation_score >= 8:
            return "ÂΩìÂâç‰º∞ÂÄºÊ∞¥Âπ≥ËæÉ‰∏∫ÂêàÁêÜÔºåÂÖ∑Êúâ‰∏ÄÂÆöÁöÑÊäïËµÑ‰ª∑ÂÄº„ÄÇÂ∏ÇÁõàÁéáÂíåÂ∏ÇÂáÄÁéáÁõ∏ÂØπËæÉ‰ΩéÔºåÂÆâÂÖ®ËæπÈôÖËæÉÈ´ò„ÄÇ"
        elif valuation_score >= 6:
            return "‰º∞ÂÄºÊ∞¥Âπ≥ÈÄÇ‰∏≠ÔºåÈúÄË¶ÅÁªìÂêàÂü∫Êú¨Èù¢ÂíåÊàêÈïøÊÄßÁªºÂêàÂà§Êñ≠ÊäïËµÑ‰ª∑ÂÄº„ÄÇ"
        else:
            return "ÂΩìÂâç‰º∞ÂÄºÂÅèÈ´òÔºåÊäïËµÑÈúÄË∞®ÊÖé„ÄÇÂª∫ËÆÆÁ≠âÂæÖÊõ¥Â•ΩÁöÑ‰π∞ÂÖ•Êó∂Êú∫„ÄÇ"

    def _analyze_growth_potential(self, symbol: str, industry_info: dict) -> str:
        """Analysis of growth potential"""
        if symbol.startswith(('000001', '600036')):
            return "Èì∂Ë°å‰∏öÊï¥‰ΩìÂ¢ûÈïøÁ®≥ÂÆöÔºåÂèóÁõä‰∫éÁªèÊµéÂèëÂ±ïÂíåÈáëËûçÊ∑±Âåñ„ÄÇÊï∞Â≠óÂåñËΩ¨ÂûãÂíåË¥¢ÂØåÁÆ°ÁêÜ‰∏öÂä°ÊòØ‰∏ªË¶ÅÂ¢ûÈïøÁÇπ„ÄÇ"
        elif symbol.startswith('300'):
            return "Âàõ‰∏öÊùøÂÖ¨Âè∏ÈÄöÂ∏∏ÂÖ∑ÊúâËæÉÈ´òÁöÑÊàêÈïøÊΩúÂäõÔºå‰ΩÜ‰πü‰º¥ÈöèÁùÄËæÉÈ´òÁöÑÈ£éÈô©„ÄÇÈúÄË¶ÅÂÖ≥Ê≥®ÊäÄÊúØÂàõÊñ∞ÂíåÂ∏ÇÂú∫ÊãìÂ±ïËÉΩÂäõ„ÄÇ"
        else:
            return "ÊàêÈïøÊΩúÂäõÈúÄË¶ÅÁªìÂêàÂÖ∑‰ΩìË°å‰∏öÂíåÂÖ¨Âè∏Âü∫Êú¨Èù¢ÂàÜÊûê„ÄÇÂª∫ËÆÆÂÖ≥Ê≥®Ë°å‰∏öÂèëÂ±ïË∂ãÂäøÂíåÂÖ¨Âè∏Á´û‰∫â‰ºòÂäø„ÄÇ"

    def _analyze_risks(self, symbol: str, financial_estimates: dict, industry_info: dict) -> str:
        """Investment risk analysis"""
        risk_level = financial_estimates['risk_level']

        risk_analysis = f"**È£éÈô©Á≠âÁ∫ß**: {risk_level}\n\n"

        if symbol.startswith(('000001', '600036')):
            risk_analysis += """**‰∏ªË¶ÅÈ£éÈô©**:
- Âà©ÁéáÁéØÂ¢ÉÂèòÂåñÂØπÂáÄÊÅØÂ∑ÆÁöÑÂΩ±Âìç
- ‰ø°Ë¥∑ËµÑ‰∫ßË¥®ÈáèÈ£éÈô©
- ÁõëÁÆ°ÊîøÁ≠ñÂèòÂåñÈ£éÈô©
- ÂÆèËßÇÁªèÊµé‰∏ãË°åÂØπÈì∂Ë°å‰∏öÁöÑÂΩ±Âìç"""
        elif symbol.startswith('300'):
            risk_analysis += """**‰∏ªË¶ÅÈ£éÈô©**:
- ÊäÄÊúØÊõ¥Êñ∞Êç¢‰ª£È£éÈô©
- Â∏ÇÂú∫Á´û‰∫âÂä†ÂâßÈ£éÈô©
- ‰º∞ÂÄºÊ≥¢Âä®ËæÉÂ§ß
- ‰∏öÁª©‰∏çÁ°ÆÂÆöÊÄßËæÉÈ´ò"""
        else:
            risk_analysis += """**‰∏ªË¶ÅÈ£éÈô©**:
- Ë°å‰∏öÂë®ÊúüÊÄßÈ£éÈô©
- ÂÆèËßÇÁªèÊµéÁéØÂ¢ÉÂèòÂåñ
- Â∏ÇÂú∫Á´û‰∫âÈ£éÈô©
- ÊîøÁ≠ñË∞ÉÊï¥È£éÈô©"""

        return risk_analysis

    def _generate_investment_advice(self, financial_estimates: dict, industry_info: dict) -> str:
        """Generate investment recommendations"""
        fundamental_score = financial_estimates['fundamental_score']
        valuation_score = financial_estimates['valuation_score']
        growth_score = financial_estimates['growth_score']

        total_score = (fundamental_score + valuation_score + growth_score) / 3

        if total_score >= 7.5:
            return """**ÊäïËµÑÂª∫ËÆÆ**: üü¢ **‰π∞ÂÖ•**
- Âü∫Êú¨Èù¢ËâØÂ•ΩÔºå‰º∞ÂÄºÂêàÁêÜÔºåÂÖ∑ÊúâËæÉÂ•ΩÁöÑÊäïËµÑ‰ª∑ÂÄº
- Âª∫ËÆÆÂàÜÊâπÂª∫‰ªìÔºåÈïøÊúüÊåÅÊúâ
- ÈÄÇÂêà‰ª∑ÂÄºÊäïËµÑËÄÖÂíåÁ®≥ÂÅ•ÂûãÊäïËµÑËÄÖ"""
        elif total_score >= 6.0:
            return """**ÊäïËµÑÂª∫ËÆÆ**: üü° **ËßÇÊúõ**
- Âü∫Êú¨Èù¢‰∏ÄËà¨ÔºåÈúÄË¶ÅËøõ‰∏ÄÊ≠•ËßÇÂØü
- ÂèØ‰ª•Â∞è‰ªì‰ΩçËØïÊé¢ÔºåÁ≠âÂæÖÊõ¥Â•ΩÊó∂Êú∫
- ÈÄÇÂêàÊúâÁªèÈ™åÁöÑÊäïËµÑËÄÖ"""
        else:
            return """**ÊäïËµÑÂª∫ËÆÆ**: üî¥ **ÂõûÈÅø**
- ÂΩìÂâçÈ£éÈô©ËæÉÈ´òÔºå‰∏çÂª∫ËÆÆÊäïËµÑ
- Âª∫ËÆÆÁ≠âÂæÖÂü∫Êú¨Èù¢ÊîπÂñÑÊàñ‰º∞ÂÄºÂõûËêΩ
- È£éÈô©ÊâøÂèóËÉΩÂäõËæÉ‰ΩéÁöÑÊäïËµÑËÄÖÂ∫îÈÅøÂÖç"""

    def _try_get_old_cache(self, symbol: str, start_date: str, end_date: str) -> Optional[str]:
        """Try to obtain expired cache data as backup"""
        try:
            #Find any associated caches without TTL
            for metadata_file in self.cache.metadata_dir.glob(f"*_meta.json"):
                try:
                    import json

                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)

                    if (metadata.get('symbol') == symbol and
                        metadata.get('data_type') == 'stock_data' and
                        metadata.get('market_type') == 'china'):

                        cache_key = metadata_file.stem.replace('_meta', '')
                        cached_data = self.cache.load_stock_data(cache_key)
                        if cached_data:
                            return cached_data + "\n\n‚ö†Ô∏è Ê≥®ÊÑè: ‰ΩøÁî®ÁöÑÊòØËøáÊúüÁºìÂ≠òÊï∞ÊçÆ"
                except Exception:
                    continue
        except Exception:
            pass

        return None

    def _generate_fallback_data(self, symbol: str, start_date: str, end_date: str, error_msg: str) -> str:
        """Generate backup data"""
        return f"""# {symbol} AËÇ°Êï∞ÊçÆËé∑ÂèñÂ§±Ë¥•

## ‚ùå ÈîôËØØ‰ø°ÊÅØ
{error_msg}

## üìä Ê®°ÊãüÊï∞ÊçÆÔºà‰ªÖ‰æõÊºîÁ§∫Ôºâ
- ËÇ°Á•®‰ª£Á†Å: {symbol}
- ËÇ°Á•®ÂêçÁß∞: Ê®°ÊãüÂÖ¨Âè∏
- Êï∞ÊçÆÊúüÈó¥: {start_date} Ëá≥ {end_date}
- Ê®°Êãü‰ª∑Ê†º: ¬•{random.uniform(10, 50):.2f}
- Ê®°ÊãüÊ∂®Ë∑å: {random.uniform(-5, 5):+.2f}%

## ‚ö†Ô∏è ÈáçË¶ÅÊèêÁ§∫
Áî±‰∫éÊï∞ÊçÆÊé•Âè£ÈôêÂà∂ÊàñÁΩëÁªúÈóÆÈ¢òÔºåÊó†Ê≥ïËé∑ÂèñÂÆûÊó∂Êï∞ÊçÆ„ÄÇ
Âª∫ËÆÆÁ®çÂêéÈáçËØïÊàñÊ£ÄÊü•ÁΩëÁªúËøûÊé•„ÄÇ

ÁîüÊàêÊó∂Èó¥: {datetime.now(ZoneInfo(get_timezone_name())).strftime('%Y-%m-%d %H:%M:%S')}
"""

    def _generate_fallback_fundamentals(self, symbol: str, error_msg: str) -> str:
        """Generate backup base surface data"""
        return f"""# {symbol} AËÇ°Âü∫Êú¨Èù¢ÂàÜÊûêÂ§±Ë¥•

## ‚ùå ÈîôËØØ‰ø°ÊÅØ
{error_msg}

## üìä Âü∫Êú¨‰ø°ÊÅØ
- ËÇ°Á•®‰ª£Á†Å: {symbol}
- ÂàÜÊûêÁä∂ÊÄÅ: Êï∞ÊçÆËé∑ÂèñÂ§±Ë¥•
- Âª∫ËÆÆ: Á®çÂêéÈáçËØïÊàñÊ£ÄÊü•ÁΩëÁªúËøûÊé•

ÁîüÊàêÊó∂Èó¥: {datetime.now(ZoneInfo(get_timezone_name())).strftime('%Y-%m-%d %H:%M:%S')}
"""


#Global Examples
_china_data_provider = None

def get_optimized_china_data_provider() -> OptimizedChinaDataProvider:
    """Example of access to global unit A data provider"""
    global _china_data_provider
    if _china_data_provider is None:
        _china_data_provider = OptimizedChinaDataProvider()
    return _china_data_provider


def get_china_stock_data_cached(symbol: str, start_date: str, end_date: str,
                               force_refresh: bool = False) -> str:
    """An easy function to access A share data

Args:
symbol: stock code (6-digit)
Start date: Start date (YYYYY-MM-DD)
End date: End Date (YYYYY-MM-DD)
source refresh: whether to forcibly refresh the cache

Returns:
Formatted stock data string
"""
    provider = get_optimized_china_data_provider()
    return provider.get_stock_data(symbol, start_date, end_date, force_refresh)


def get_china_fundamentals_cached(symbol: str, force_refresh: bool = False) -> str:
    """An easy function to access fundamental A data

Args:
symbol: stock code (6-digit)
source refresh: whether to forcibly refresh the cache

Returns:
Formatting Basic Data Strings
"""
    provider = get_optimized_china_data_provider()
    return provider.get_fundamentals_data(symbol, force_refresh)


#Add Cache Method to Optimized ChinaDataProvider Category
def _add_financial_cache_methods():
    """Add Financial Data Cache Method to Optimize ChinaDataProvider"""

    def _get_cached_raw_financial_data(self, symbol: str) -> dict:
        """Obtain raw financial data from database cache"""
        try:
            from .cache.app_adapter import get_mongodb_client
            client = get_mongodb_client()
            if not client:
                logger.debug(f"[financial cache] MongoDB client not available")
                return None

            db = client.get_database('tradingagents')

            #First priority: read from stock financial data collection (termination data for scheduled task sync)
            stock_financial_collection = db.stock_financial_data

            #Try symbol or code field query (compatible with different sync services)
            financial_doc = stock_financial_collection.find_one({
                '$or': [
                    {'symbol': symbol},
                    {'code': symbol}
                ]
            }, sort=[('updated_at', -1)])

            if financial_doc:
                logger.info(f"[Financial data]{symbol}Financial data")
                #Convert database documents into financial data formats
                financial_data = {}

                #Extracting various financial data
                #First Priority: Check the Raw data field (structure used by the Tushare Sync Service)
                if 'raw_data' in financial_doc and isinstance(financial_doc['raw_data'], dict):
                    raw_data = financial_doc['raw_data']
                    #Map field name: Raw data uses Cashflow statement, we need Cash Flow
                    if 'balance_sheet' in raw_data and raw_data['balance_sheet']:
                        financial_data['balance_sheet'] = raw_data['balance_sheet']
                    if 'income_statement' in raw_data and raw_data['income_statement']:
                        financial_data['income_statement'] = raw_data['income_statement']
                    if 'cashflow_statement' in raw_data and raw_data['cashflow_statement']:
                        financial_data['cash_flow'] = raw_data['cashflow_statement']  #Note field name map
                    if 'financial_indicators' in raw_data and raw_data['financial_indicators']:
                        financial_data['main_indicators'] = raw_data['financial_indicators']  #Note field name map
                    if 'main_business' in raw_data and raw_data['main_business']:
                        financial_data['main_business'] = raw_data['main_business']

                #Priority 2: Check financial data embedded fields
                elif 'financial_data' in financial_doc and isinstance(financial_doc['financial_data'], dict):
                    nested_data = financial_doc['financial_data']
                    if 'balance_sheet' in nested_data:
                        financial_data['balance_sheet'] = nested_data['balance_sheet']
                    if 'income_statement' in nested_data:
                        financial_data['income_statement'] = nested_data['income_statement']
                    if 'cash_flow' in nested_data:
                        financial_data['cash_flow'] = nested_data['cash_flow']
                    if 'main_indicators' in nested_data:
                        financial_data['main_indicators'] = nested_data['main_indicators']

                #Priority 3: Read directly from the root level of the document
                else:
                    if 'balance_sheet' in financial_doc and financial_doc['balance_sheet']:
                        financial_data['balance_sheet'] = financial_doc['balance_sheet']
                    if 'income_statement' in financial_doc and financial_doc['income_statement']:
                        financial_data['income_statement'] = financial_doc['income_statement']
                    if 'cash_flow' in financial_doc and financial_doc['cash_flow']:
                        financial_data['cash_flow'] = financial_doc['cash_flow']
                    if 'main_indicators' in financial_doc and financial_doc['main_indicators']:
                        financial_data['main_indicators'] = financial_doc['main_indicators']

                if financial_data:
                    logger.info(f"üìä [Financial data] Successful extraction{symbol}, containing fields:{list(financial_data.keys())}")
                    return financial_data
                else:
                    logger.warning(f"[Financial data]{symbol}Stock financial data records exist but no valid financial data fields")
            else:
                logger.debug(f"[Financial data] Stock financial data collection not found{symbol}Records")

            #Second Priority: Read from Financial data cache (temporary cache)
            collection = db.financial_data_cache

            #Search for cached raw financial data
            cache_doc = collection.find_one({
                'symbol': symbol,
                'cache_type': 'raw_financial_data'
            }, sort=[('updated_at', -1)])

            if cache_doc:
                #Check if the cache is expired (24 hours)
                from datetime import datetime, timedelta
                cache_time = cache_doc.get('updated_at')
                if cache_time and datetime.now() - cache_time < timedelta(hours=24):
                    financial_data = cache_doc.get('financial_data', {})
                    if financial_data:
                        logger.info(f"[Financial cache]{symbol}Original financial data")
                        return financial_data
                else:
                    logger.debug(f"[financial cache]{symbol}Original financial data cache expired")
            else:
                logger.debug(f"[financial cache] Not found{symbol}Original financial data cache")

        except Exception as e:
            logger.debug(f"[financial cache]{symbol}Original financial data cache failed:{e}")

        return None

    def _get_cached_stock_info(self, symbol: str) -> dict:
        """Get basic stock information from the database cache"""
        try:
            from .cache.app_adapter import get_mongodb_client
            client = get_mongodb_client()
            if not client:
                return {}

            db = client.get_database('tradingagents')
            collection = db.stock_basic_info

            #Search for Basic Stock Information
            doc = collection.find_one({'code': symbol})
            if doc:
                return {
                    'symbol': symbol,
                    'name': doc.get('name', ''),
                    'industry': doc.get('industry', ''),
                    'market': doc.get('market', ''),
                    'source': 'database_cache'
                }
        except Exception as e:
            logger.debug(f"Access{symbol}Basic information cache failed:{e}")

        return {}

    def _restore_financial_data_format(self, cached_data: dict) -> dict:
        """Restore cached financial data to DataFrame format"""
        try:
            import pandas as pd
            restored_data = {}

            for key, value in cached_data.items():
                if isinstance(value, list) and value:  #If it's in list format,
                    #Convert back to DataFrame
                    restored_data[key] = pd.DataFrame(value)
                else:
                    restored_data[key] = value

            return restored_data
        except Exception as e:
            logger.debug(f"The restoration of the financial data format failed:{e}")
            return cached_data

    def _cache_raw_financial_data(self, symbol: str, financial_data: dict, stock_info: dict):
        """Cache raw financial data to database"""
        try:
            from tradingagents.config.runtime_settings import use_app_cache_enabled
            if not use_app_cache_enabled(False):
                logger.debug(f"üìä [Financial Cache] Apply cache not enabled, skip cache save")
                return

            from .cache.app_adapter import get_mongodb_client
            client = get_mongodb_client()
            if not client:
                logger.debug(f"[financial cache] MongoDB client not available")
                return

            db = client.get_database('tradingagents')
            collection = db.financial_data_cache

            from datetime import datetime

            #Convert DataFrame into a sequenced format
            serializable_data = {}
            for key, value in financial_data.items():
                if hasattr(value, 'to_dict'):  # pandas DataFrame
                    serializable_data[key] = value.to_dict('records')
                else:
                    serializable_data[key] = value

            cache_doc = {
                'symbol': symbol,
                'cache_type': 'raw_financial_data',
                'financial_data': serializable_data,
                'stock_info': stock_info,
                'updated_at': datetime.now()
            }

            #Update or insert withupsert
            collection.replace_one(
                {'symbol': symbol, 'cache_type': 'raw_financial_data'},
                cache_doc,
                upsert=True
            )

            logger.info(f"[financial cache]{symbol}Original financial data cached to data Library")

        except Exception as e:
            logger.debug(f"[financial cache]{symbol}Original financial data failed:{e}")

    #Add method to class
    OptimizedChinaDataProvider._get_cached_raw_financial_data = _get_cached_raw_financial_data
    OptimizedChinaDataProvider._get_cached_stock_info = _get_cached_stock_info
    OptimizedChinaDataProvider._restore_financial_data_format = _restore_financial_data_format
    OptimizedChinaDataProvider._cache_raw_financial_data = _cache_raw_financial_data

#Other Organiser
_add_financial_cache_methods()
